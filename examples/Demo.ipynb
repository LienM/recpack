{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "prepared-afghanistan",
   "metadata": {},
   "source": [
    "# Demo Recpack\n",
    "\n",
    "This is an end to end demo of Recpack functionality.\n",
    "\n",
    "### Dataset\n",
    "\n",
    "We use the MovieLens 25M dataset, which contains user-item rating tuples, with timestamp information as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "liberal-cocktail",
   "metadata": {},
   "outputs": [],
   "source": [
    "from recpack.data.datasets import MovieLens25M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "palestinian-business",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess default set to false, so we can highlight the use of filters with datasets\n",
    "dataset = MovieLens25M(\"data/ml25.csv\", preprocess_default=False)\n",
    "# Download the dataset if not present on hard disk\n",
    "dataset.fetch_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "artistic-lobby",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all interactions as a pandas DataFrame\n",
    "df = dataset.load_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "oriented-subscriber",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "narrative-tablet",
   "metadata": {},
   "source": [
    "### Preprocessing\n",
    "\n",
    "When using a dataset the preprocessing happens when `load_interaction_matrix()` function is called.\n",
    "\n",
    "Datasets have default filters, to overwrite these (if you would want to) add the `preprocess_default=True` key word argument to the initialization.\n",
    "\n",
    "In this example we won't use the default ML25M filters, but instead use our own. \n",
    "\n",
    "* MinRating = 3 -> Anything 3 and above is considered a positive interaction\n",
    "* MinUsersPerItem = 30 -> Focussing on the most interacted items, otherwise will need too much RAM\n",
    "* MinItemsPerUser = 5 -> Users with enough interactions to allow for prediction\n",
    "\n",
    "The order in which these are added is important, as they are applied in order to the data.\n",
    "\n",
    "So first the rating filter will be applied, then the users per item and finally items per user.\n",
    "\n",
    "We usually first apply the strictest filters first. \n",
    "Otherwise we might count interactions with rating < 3 in our min user per item filter, but then throw them away again later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spanish-pipeline",
   "metadata": {},
   "outputs": [],
   "source": [
    "from recpack.preprocessing.filters import MinItemsPerUser, MinRating, MinUsersPerItem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceramic-combination",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.add_filter(MinRating(3, rating_ix=\"rating\"))\n",
    "dataset.add_filter(MinUsersPerItem(30, item_ix=\"movieId\", user_ix=\"userId\", count_duplicates=False))\n",
    "dataset.add_filter(MinItemsPerUser(5, item_ix=\"movieId\", user_ix=\"userId\", count_duplicates=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "understood-chile",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applies filters, and loads filtered data into an InteractionMatrix\n",
    "data = dataset.load_interaction_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "functioning-republican",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_users = df.userId.nunique()\n",
    "original_items = df.movieId.nunique()\n",
    "users, items = data.shape\n",
    "\n",
    "print(f\"We have {users} users and {items} items left\")\n",
    "print(f\"preprocessing removed {original_users - users} users\")\n",
    "print(f\"preprocessing removed {original_items - items} items\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "naked-innocent",
   "metadata": {},
   "source": [
    "### Scenario\n",
    "\n",
    "Scenarios are used to choose how we want to evaluate our algorithms. In literature and practice different scenarios are used for different use cases.\n",
    "\n",
    "We don't use validation data in this example, as we don't do any parameter optimisation.\n",
    "\n",
    "As scenario we choose Strong Generalization, so won't use the timestamp information for now.\n",
    "Strong Generalization splits users into two datasets, the training users' interactions are used for training.\n",
    "Test users' interactions are split, and part is used as history and the goal of the recommender is to recommend the held out dataset.\n",
    "\n",
    "As parameters this scenario allows selection of how much users to use for training data, and how much of a user's interactions to use as history during prediction.\n",
    "\n",
    "We will use 70% of users as training data, and for prediction we will use 80% of the test users' interactions as history, to predict the remaining 20%.\n",
    "validation is set to False, so we don't generate validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "temporal-trademark",
   "metadata": {},
   "outputs": [],
   "source": [
    "from recpack.splitters.scenarios import StrongGeneralization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bored-container",
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario = StrongGeneralization(frac_users_train=0.7, frac_interactions_in=0.8, validation=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "treated-balance",
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario.split(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "other-summit",
   "metadata": {},
   "source": [
    "### Algorithms\n",
    "\n",
    "We use 2 different algorithms to compute scores on.\n",
    "\n",
    "* Item KNN\n",
    "* Popularity \n",
    "\n",
    "You can also add EASE, but make sure to have enough RAM available, at least 32GB needed. \n",
    "\n",
    "Each algorithm has a set of parameters, so in practical settings, you would optimise them before comparison. \n",
    "Here we don't care as much about optimality, and so we just picked defaults that made some sense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "naughty-testing",
   "metadata": {},
   "outputs": [],
   "source": [
    "from recpack.algorithms import ItemKNN, Popularity, EASE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "preliminary-barrel",
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithms = [\n",
    "    ItemKNN(K=200),\n",
    "    Popularity(),\n",
    "#     EASE(l2=100)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "continental-breeding",
   "metadata": {},
   "source": [
    "### Metrics\n",
    "We select a couple metrics that will be evaluated on\n",
    " \n",
    "* CoverageK\n",
    "* CalibratedRecallK\n",
    "* NormalizedDiscountedCumulativeGainK\n",
    "* HitK\n",
    "* WeightedByInteractionsHitK\n",
    "\n",
    "As K value we will use 10 (as if we recommend a box of 10 items)\n",
    "\n",
    "We will allow the pipeline to construct the metrics, so we only need their names for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ready-interaction",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = [\n",
    "    'CoverageK',\n",
    "    'CalibratedRecallK',\n",
    "    'NormalizedDiscountedCumulativeGainK',\n",
    "    'HitK',\n",
    "    'WeightedByInteractionsHitK'\n",
    "]\n",
    "\n",
    "K_values = [10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alleged-jewel",
   "metadata": {},
   "source": [
    "### Pipeline\n",
    "\n",
    "We'll use a pipeline to do the heavy lifting for us.\n",
    "\n",
    "We provide it with the algorithms to compare, the metrics to compare on, and the K values to compute at.\n",
    "\n",
    "To `run` we give the training data, and the tuple of test data. The pipeline will train all models, and evaluate them on the test data.\n",
    "\n",
    "To get the results we use `pipeline.get()` which returns a nested dict, <metric_name, <algorithm, score>>.\n",
    "\n",
    "for easy representation, we render it using pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pharmaceutical-socket",
   "metadata": {},
   "outputs": [],
   "source": [
    "from recpack.pipeline import Pipeline\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "federal-linux",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(algorithms, metrics, K_values=K_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "computational-cross",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the pipeline, this can take a while.\n",
    "# Go grab a coffee, and enjoy :D\n",
    "pipeline.run(scenario.training_data, scenario.test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adjustable-series",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame.from_dict(pipeline.get())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "optimum-tunnel",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
