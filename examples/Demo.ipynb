{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "prepared-afghanistan",
   "metadata": {},
   "source": [
    "# Demo Recpack\n",
    "\n",
    "This is an end to end demo of Recpack functionality.\n",
    "\n",
    "### Dataset\n",
    "\n",
    "We use the MovieLens 25M dataset, which contains user-item rating tuples, with timestamp information as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "liberal-cocktail",
   "metadata": {},
   "outputs": [],
   "source": [
    "from recpack.data.datasets import MovieLens25M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "palestinian-business",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess default set to false, so we can highlight the use of filters with datasets\n",
    "dataset = MovieLens25M(\"data/ml25.csv\", preprocess_default=False)\n",
    "# Download the dataset if not present in the data module\n",
    "dataset.fetch_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "artistic-lobby",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dataset.load_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "oriented-subscriber",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "narrative-tablet",
   "metadata": {},
   "source": [
    "### Preprocessing\n",
    "\n",
    "In preprocessing we'll add filters to the dataset class\n",
    "\n",
    "* MinRating = 3 -> Anything 3 and above is considered a positive interaction\n",
    "* MinUsersPerItem = 30 -> Focussing on the most interacted items, otherwise will need too much RAM\n",
    "* MinItemsPerUser = 5 -> Users with enough interactions to allow for prediction\n",
    "\n",
    "The order in which they are added are important, the data is passed in order through them.\n",
    "\n",
    "So first the rating filter will be applied, then the users per item and finally items per user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spanish-pipeline",
   "metadata": {},
   "outputs": [],
   "source": [
    "from recpack.preprocessing.filters import MinItemsPerUser, MinRating, MinUsersPerItem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceramic-combination",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.add_filter(MinRating(3, rating_ix=\"rating\"))\n",
    "dataset.add_filter(MinUsersPerItem(30, item_ix=\"movieId\", user_ix=\"userId\", count_duplicates=False))\n",
    "dataset.add_filter(MinItemsPerUser(5, item_ix=\"movieId\", user_ix=\"userId\", count_duplicates=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "understood-chile",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load our data into an InteractionMatrix\n",
    "# This will apply the preprocessing filters as well\n",
    "data = dataset.load_interaction_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "functioning-republican",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_users = df.userId.nunique()\n",
    "original_items = df.movieId.nunique()\n",
    "users, items = data.shape\n",
    "\n",
    "print(f\"We have {users} users and {items} items left\")\n",
    "print(f\"preprocessing removed {original_users - users} users\")\n",
    "print(f\"preprocessing removed {original_items - items} items\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "naked-innocent",
   "metadata": {},
   "source": [
    "### Scenario\n",
    "\n",
    "We'll choose a scenario to generate training data and test data.\n",
    "We'll skip the validation data, because we won't do parameter optimisation in this example.\n",
    "\n",
    "As scenario we will use Strong Generalization, so won't use the timestamp information for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "temporal-trademark",
   "metadata": {},
   "outputs": [],
   "source": [
    "from recpack.splitters.scenarios import StrongGeneralization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bored-container",
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario = StrongGeneralization(frac_users_train=0.7, frac_interactions_in=0.8, validation=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "treated-balance",
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario.split(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "other-summit",
   "metadata": {},
   "source": [
    "### Algorithms\n",
    "\n",
    "We will use 2 different algorithms to compute scores on.\n",
    "\n",
    "* Item KNN\n",
    "* Popularity \n",
    "\n",
    "You can also add EASE, but make sure to have enough RAM available, at least 32GB needed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "naughty-testing",
   "metadata": {},
   "outputs": [],
   "source": [
    "from recpack.algorithms import ItemKNN, Popularity, EASE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "preliminary-barrel",
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithms = [\n",
    "    ItemKNN(K=200),\n",
    "    Popularity(),\n",
    "#     EASE(l2=100)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "continental-breeding",
   "metadata": {},
   "source": [
    "### Metrics\n",
    "We will select a couple metrics that will be evaluated on\n",
    " \n",
    "* CoverageK\n",
    "* CalibratedRecallK\n",
    "* NDCGK\n",
    "* HitK\n",
    "* WeightedHitK\n",
    "\n",
    "As K value we will use 10 (as if we recommend a box of 10 items)\n",
    "\n",
    "We will allow the pipeline to construct the metrics, so we only need their names for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ready-interaction",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = [\n",
    "    'CoverageK',\n",
    "    'CalibratedRecallK',\n",
    "    'NDCGK',\n",
    "    'HitK',\n",
    "    'WeightedHitK'\n",
    "]\n",
    "\n",
    "K_values = [10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alleged-jewel",
   "metadata": {},
   "source": [
    "### Pipeline\n",
    "\n",
    "We'll use a pipeline to do the heavy lifting for us"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pharmaceutical-socket",
   "metadata": {},
   "outputs": [],
   "source": [
    "from recpack.pipeline import Pipeline\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "federal-linux",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(algorithms, metrics, K_values=K_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "computational-cross",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.run(scenario.training_data, scenario.test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adjustable-series",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame.from_dict(pipeline.get())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opposite-numbers",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
