{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "local-bumper",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pytz import timezone\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "from recpack.algorithms import EASE, ItemKNN, Popularity, KUNN\n",
    "from recpack.preprocessing.preprocessors import DataFramePreprocessor\n",
    "from recpack.preprocessing.filters import MinItemsPerUser, MinUsersPerItem, NMostPopular\n",
    "from recpack.util import get_top_K_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "discrete-federal",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "backed-section",
   "metadata": {},
   "source": [
    "## Checking Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "southwest-portsmouth",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_fit():\n",
    "    values = [1, 1, 1, 1, 1, 1, 1]\n",
    "    users = [0, 0, 1, 1, 2, 2, 2]\n",
    "    items = [1, 2, 0, 2, 0, 1, 2]\n",
    "    X = csr_matrix((values, (users, items)))\n",
    "    \n",
    "    algo = KUNN()\n",
    "    algo.fit(X)\n",
    "    \n",
    "    # The fit should have stored an itemKNN model\n",
    "    assert algo.knn_i_.shape == (X.shape[1], X.shape[1])\n",
    "    \n",
    "    itemKNN = ItemKNN(K=1)\n",
    "    itemKNN.fit(X)\n",
    "    # The itemKNN model should be an itemKNN model\n",
    "    np.testing.assert_array_equal(itemKNN.similarity_matrix_.toarray(), algo.knn_i_.toarray())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "allied-thermal",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_predict_k_1():\n",
    "    kunn = KUNN(Ku=1, Ki=1)\n",
    "    \n",
    "    values = [1, 1, 1, 1, 1, 1, 1]\n",
    "    users = [0, 0, 1, 1, 2, 2, 2]\n",
    "    items = [1, 2, 0, 2, 0, 1, 2]\n",
    "    test_matrix = csr_matrix((values, (users, items)), shape=(5, 3))\n",
    "\n",
    "    kunn.fit(test_matrix)\n",
    "    \n",
    "    \n",
    "    values_pred = [1, 1, 1, 1]\n",
    "    users_pred = [3, 3, 4, 4]\n",
    "    items_pred = [0, 1, 1, 2]\n",
    "    pred_matrix = csr_matrix((values_pred, (users_pred, items_pred)), shape=test_matrix.shape)\n",
    "\n",
    "    prediction = kunn.predict(pred_matrix)\n",
    "    \n",
    "    # Manual computation of the formulas in the paper\n",
    "    # We'll compute similarity 3, 2\n",
    "    u = 3\n",
    "    i = 2\n",
    "\n",
    "    ## USER SIMILARITY ##\n",
    "\n",
    "    # use ItemKNN class to compute user neighbours\n",
    "    # By fitting it on the transpose of the combination of the test and pred matrices     \n",
    "    # In this case test_matrix and pred matrix are fully disjunct\n",
    "    # TODO: add a test with non fully disjunct test and pred matrices,\n",
    "    #       To make sure it can be used with the other splitters as well.    \n",
    "    userknn = ItemKNN(K=1)\n",
    "    userknn.fit((test_matrix + pred_matrix).T.tocsr())\n",
    "\n",
    "    # Get the one user similiar to user u\n",
    "    v = np.argmax(userknn.similarity_matrix_[u])\n",
    "    # We are \"lucky\", the most similar user is one from the training users,\n",
    "    # so don't need to do finicking to remove the unwanted similarities\n",
    "    assert v == 2\n",
    "    \n",
    "    # User 2 has seen item 2 we are trying to predict\n",
    "    # -> the R_v_i term in the formula is 1\n",
    "    # compute the c(v) value\n",
    "    c_v = test_matrix[v].nnz\n",
    "\n",
    "    # Second summation, over all items v and u have in common\n",
    "    # user 3 and user 2 have 2 items in common (0 and 1)\n",
    "    # u's interactions are not in the test_matrix,\n",
    "    # so we need increase the count of occurences + 1\n",
    "    c_j_0 = test_matrix[:,0].nnz + 1\n",
    "    c_j_1 = test_matrix[:,1].nnz + 1\n",
    "    \n",
    "    # Compute user similarity.\n",
    "    # 1/sqrt(cv) + sum(j in [0, 1] 1/sqrt(c(j)))\n",
    "    s_u = ( 1/c_v**0.5) * ((1/c_j_0**0.5) + (1/c_j_1**0.5) )\n",
    "    \n",
    "    ## ITEM SIMILARITY ## \n",
    "\n",
    "    # K = 1 -> argmax gives us the most similar item\n",
    "    j = np.argmax(itemKNN.similarity_matrix_[i])\n",
    "    assert j == 0\n",
    "    \n",
    "    # c(j) in paper, only need it for the one j\n",
    "    # User u has interacted with item 0 -> R_u_j = 1\n",
    "    c_j = test_matrix[:,j].nnz\n",
    "\n",
    "    # 2 users have seen both items 0 and 2 => user 1,2\n",
    "    np.testing.assert_array_equal(\n",
    "        test_matrix[:,j].multiply(test_matrix[:,i]).toarray().nonzero()[0],\n",
    "        np.array([1,2])\n",
    "    )\n",
    "    \n",
    "    # Compute history lengths of the two users\n",
    "    c_v_1 = test_matrix[1].nnz\n",
    "    c_v_2 = test_matrix[2].nnz\n",
    "    \n",
    "    # Compute item similarity\n",
    "    # 1/sqrt(c_j) * sum(v in [1,2]) 1/sqrt(c(v))\n",
    "    s_i = (1/c_j**0.5) * ((1/c_v_1**0.5) + (1/c_v_2)**0.5)\n",
    "    \n",
    "    # Compute similarity\n",
    "    # (s_u + s_i) / (sqrt(c(u)*c(i)))\n",
    "    s_u_i = (s_u + s_i) / (pred_matrix[u].nnz * test_matrix[i].nnz)**0.5\n",
    "    \n",
    "    np.testing.assert_almost_equal(prediction[3,2], s_u_i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intended-primary",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_predict_k_2():\n",
    "    kunn = KUNN(Ku=2, Ki=2)\n",
    "\n",
    "    values = [1, 1, 1, 1, 1, 1, 1]\n",
    "    users = [0, 0, 1, 1, 2, 2, 2]\n",
    "    items = [1, 2, 0, 2, 0, 1, 2]\n",
    "    test_matrix = csr_matrix((values, (users, items)), shape=(5, 3))\n",
    "\n",
    "    kunn.fit(test_matrix)\n",
    "\n",
    "    values_pred = [1, 1, 1, 1]\n",
    "    users_pred = [3, 3, 4, 4]\n",
    "    items_pred = [0, 1, 1, 2]\n",
    "    pred_matrix = csr_matrix((values_pred, (users_pred, items_pred)), shape=test_matrix.shape)\n",
    "\n",
    "    predictions = kunn.predict(pred_matrix)\n",
    "    \n",
    "    # Fit the KNN models\n",
    "    itemknn = ItemKNN(K=2)\n",
    "    userknn = ItemKNN(K=2)\n",
    "    itemknn.fit(test_matrix)\n",
    "    userknn.fit((test_matrix+pred_matrix).T.tocsr())\n",
    "    \n",
    "    # Predict score for user 3, item 2\n",
    "    u = 3\n",
    "    i = 2\n",
    "\n",
    "    # V is set of users that are neighbours of u\n",
    "    V = userknn.similarity_matrix_[u].nonzero()[1]\n",
    "    # We are 'lucky' our new users are not similar to the other new users \n",
    "    #     -> No leakage of info\n",
    "    np.testing.assert_array_equal(V, np.array([1,2]))\n",
    "\n",
    "    # J is set of items that are neighbours of i\n",
    "    J = itemknn.similarity_matrix_[i].nonzero()[1]\n",
    "    \n",
    "    # Compute 1/sqrt(c(v)) for each v\n",
    "    one_over_sqrt_v = {v: 1/test_matrix[v].nnz ** 0.5 for v in V}\n",
    "    # Compute 1/sqrt(c(j)) for each j\n",
    "    one_over_sqrt_j = {j: 1/test_matrix[j].nnz ** 0.5 for j in J}\n",
    "    \n",
    "    ## USER SIMILARITY ##\n",
    "    # Iteratively compute the user sim\n",
    "    score = 0\n",
    "    for v in V: # 1st sum : v in KNN(u)\n",
    "        if test_matrix[v, i] != 0: # R_v_i in the first sum.\n",
    "            # Compute transitive part\n",
    "            trans_sum = 0\n",
    "            for j in pred_matrix[u].nonzero()[1]: # Second sum, with R_u_i = 1\n",
    "\n",
    "                if test_matrix[v, j] != 0: # R_u_j = 1 clause in sum\n",
    "                    \n",
    "                    c_j = test_matrix[:, j].nnz\n",
    "                    \n",
    "                    # \"HACK\" To count the interaction of user u in the pred matrix\n",
    "                    if test_matrix[u,j] == 0: \n",
    "                        c_j += 1\n",
    "                    # End of \"HACK\"\n",
    "\n",
    "                    trans_sum += (1/c_j**0.5)\n",
    "\n",
    "            score += trans_sum * one_over_sqrt_v[v]\n",
    "\n",
    "    user_sim = score\n",
    "    \n",
    "    ## ITEM SIMILARITY ##\n",
    "    # Compute the item similarity iteratively\n",
    "    score = 0\n",
    "    for j in J: # 1st sum j in KNN(i)\n",
    "        if pred_matrix[u, j] != 0: # R_u_j value\n",
    "            trans_sum = 0\n",
    "            for v in test_matrix[:,j].nonzero()[0]: # Second sum, with R_v_j clause\n",
    "                if test_matrix[v,i] != 0: # R_v_i clause in second sum\n",
    "                    c_v = test_matrix[v,:].nnz\n",
    "                    trans_sum += 1/c_v**0.5\n",
    "\n",
    "            score += trans_sum * one_over_sqrt_j[j]\n",
    "\n",
    "    item_sim = score\n",
    "    \n",
    "    ## FINAL SCORE ##\n",
    "    final_score = (user_sim + item_sim) / (pred_matrix[u].nnz * test_matrix[:,i].nnz)**0.5\n",
    "    \n",
    "    np.testing.assert_almost_equal(prediction[u,i], final_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comparable-definition",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predict_k_2()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}