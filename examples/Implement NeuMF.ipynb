{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85c37828",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pytest\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "from typing import Callable, List, Optional, Union"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "649de821",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# RecPack: An Experimental Toolkit for Recommendation Algorithms\n",
    "\n",
    "by Lien Michiels and Robin Verachtert"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "478837d4",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## What is Recpack?\n",
    "- Python library for recommendation algorithm implementation and evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccf1660c",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## What is Recpack?\n",
    "- Python library for recommendation algorithm implementation and evaluation\n",
    "- Focus on being easily extendable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d8cbaac",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## What is Recpack?\n",
    "### Architecture\n",
    "![pipeline](RecpackPipeline.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "671379b0",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "TODO: include scenarios!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab307a0",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## This Demo\n",
    "- Demonstrate implementation of new algorithm using \"Neural Matrix Factorization (He et al. 2017)\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47c6c8a6",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## This Demo\n",
    "- Demonstrate implementation of new algorithm using \"Neural Matrix Factorization (He et al. 2017)\"\n",
    "- Run experiment to compare performance of new algorithm to baselines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d08a2c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Neural Matrix Factorization\n",
    "- Users and items are represented by embedding fectors\n",
    "- Similarity is modeled using an MLP network, rather than computing <u,i> as in traditional matrix factorization embedding techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c196de69",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Implementing MLP network\n",
    "\n",
    "![MLPArchitecture](MLPArchitecture.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "743b93a9",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    \"\"\"A multi-layer perceptron module.\n",
    "    This module is a sequence of linear layers plus activation functions.\n",
    "    The user can optionally add normalization and/or dropout to each of the layers.\n",
    "    \n",
    "    Code used from https://github.com/facebookresearch/multimodal/blob/5dec8a/torchmultimodal/modules/layers/mlp.py\n",
    "    \n",
    "    :param in_dim: Input dimension.\n",
    "    :type in_dim: int\n",
    "    :param out_dim: Output dimension.\n",
    "    :type out_dim: int\n",
    "    :param hidden_dims: Output dimension for each hidden layer.\n",
    "    :type hidden_dims: Optional[Union[int, List[int]]] \n",
    "    :param dropout: Probability for dropout layers between each hidden layer.\n",
    "    :type dropout: float\n",
    "    :param activation: Which activation function to use. \n",
    "        Supports module type or partial.\n",
    "    :type activation: Callable[..., nn.Module]\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self, \n",
    "        in_dim: int, \n",
    "        out_dim: int,\n",
    "        hidden_dims: Optional[Union[int, List[int]]] = None,\n",
    "        dropout: float = 0.5,\n",
    "        activation: Callable[..., nn.Module] = nn.ReLU,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        layers = nn.ModuleList()\n",
    "\n",
    "        if hidden_dims is None:\n",
    "            hidden_dims = []\n",
    "\n",
    "        if isinstance(hidden_dims, int):\n",
    "            hidden_dims = [hidden_dims]\n",
    "\n",
    "        for hidden_dim in hidden_dims:\n",
    "            layers.append(nn.Linear(in_dim, hidden_dim))\n",
    "            layers.append(activation())\n",
    "            layers.append(nn.Dropout(dropout))\n",
    "            in_dim = hidden_dim\n",
    "        layers.append(nn.Linear(in_dim, out_dim))\n",
    "        self.model = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "83fcd62d",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "EMBEDDING_SIZE = 3\n",
    "N_USERS = 5\n",
    "N_ITEMS = 10\n",
    "a = MLP(2*EMBEDDING_SIZE, N_ITEMS, [6, 4, 2], dropout=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea26454",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Implementing the Neural Architecture\n",
    "\n",
    "![Architecture](NeuMFArchitecture.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "34a78b55",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "class NMFModule(nn.Module):\n",
    "    \"\"\"Model that encodes the Neural Matrix Factorization Network.\n",
    "    \n",
    "    Implements the 3 tiered network defined in the He et al. paper.\n",
    "\n",
    "    :param predictive_powers: size of the last hidden layer in MLP.\n",
    "        Embedding sizes computed as 2 * predictive powers.\n",
    "    :type predictive_powers: int\n",
    "    :param n_users: number of users in the network\n",
    "    :type n_users: int\n",
    "    :param n_items: number of items in the network\n",
    "    :type n_items: int\n",
    "    :param hidden_dims: dimensions of the MLP hidden layers.\n",
    "    :type hidden_dims: Union[int, List[int]]\n",
    "    :param dropout: Dropout chance between layers of the MLP\n",
    "    :type dropout: float\n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "63e439d5",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "class NMFModule(NMFModule):\n",
    "    def __init__(\n",
    "        self, predictive_powers: int, n_users: int, n_items: int, dropout: float\n",
    "    ):\n",
    "        super().__init__()\n",
    "        num_components = 2 * predictive_powers\n",
    "        \n",
    "        self.user_embedding = nn.Embedding(n_users, num_components)\n",
    "        self.item_embedding = nn.Embedding(n_items, num_components)\n",
    "\n",
    "        # we use a three tiered MLP as described in the experiments of the paper.\n",
    "        hidden_dims = [\n",
    "            4 * predictive_powers, \n",
    "            2 * predictive_powers, \n",
    "            predictive_powers\n",
    "        ]\n",
    "\n",
    "        # Output is always 1, since we need a single score for u,i\n",
    "        self.mlp = MLP(4 * predictive_powers, 1, \n",
    "                       hidden_dims, dropout=dropout)\n",
    "\n",
    "        self.final = nn.Sigmoid()\n",
    "\n",
    "        # weight initialization\n",
    "        self.user_embedding.weight.data.normal_(0, \n",
    "            1.0 / self.user_embedding.embedding_dim)\n",
    "        self.item_embedding.weight.data.normal_(0, \n",
    "            1.0 / self.item_embedding.embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "551d5c5b",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "class NMFModule(NMFModule):\n",
    "    def forward(self, users: torch.LongTensor, items: torch.LongTensor) -> torch.FloatTensor:\n",
    "        \"\"\"Predict scores for the user item pairs obtained \n",
    "        by zipping together the two inputs\n",
    "\n",
    "        :param users: 1D tensor with user ids\n",
    "        :type users: torch.LongTensor\n",
    "        :param items: 1D tensor with item ids\n",
    "        :type items: torch.LongTensor\n",
    "        :return: 1D tensor with predicted similarities.\n",
    "            Position i is the similarity between \n",
    "            `users[i]` and `items[i]`\n",
    "        :rtype: torch.FloatTensor\n",
    "        \"\"\"\n",
    "\n",
    "        # Embedding lookups\n",
    "        user_emb = self.user_embedding(users)\n",
    "        item_emb = self.item_embedding(items)\n",
    "\n",
    "        # Pass concatenated through MLP and apply sigmoid\n",
    "        return self.final(\n",
    "            self.mlp(\n",
    "                torch.hstack([user_emb, item_emb])\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b8bcb491",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def test_output_shapes_NMF(\n",
    "    predictive_factors, num_users, num_items\n",
    "):\n",
    "    \"\"\"Check that no mather the inner settings of the network, the output is always correct\"\"\"\n",
    "    mod = NMFModule(predictive_factors, num_users, num_items, 0.0)\n",
    "    \n",
    "    user_tensor = torch.LongTensor([1, 2])\n",
    "    item_tensor = torch.LongTensor([1, 2])\n",
    "    \n",
    "    res = mod(user_tensor, item_tensor) # predict scores for items given the users\n",
    "    \n",
    "    assert res.shape == (2, 1)\n",
    "\n",
    "    assert (res.detach().numpy() <= 1).all()\n",
    "    assert (res.detach().numpy() >= 0).all()\n",
    "\n",
    "\n",
    "test_output_shapes_NMF(5, 10, 10)\n",
    "test_output_shapes_NMF(5, 3, 10)\n",
    "test_output_shapes_NMF(1, 3, 3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3c07d570",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from typing import List, Union, Optional\n",
    "\n",
    "import pandas as pd\n",
    "from recpack.algorithms.base import TorchMLAlgorithm\n",
    "from recpack.algorithms.samplers import PositiveNegativeSampler\n",
    "from recpack.algorithms.util import get_users\n",
    "from recpack.matrix import InteractionMatrix\n",
    "from scipy.sparse import csr_matrix, lil_matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "217f8d30",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Implementing the algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "689f9c7d",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Choosing the right baseclass\n",
    "`Algorithm`\n",
    "\n",
    "Follows the sklearn interface\n",
    "- `__init__(...)`: sets the (hyper)parameters of the algorithm\n",
    "- `fit(X)`: train the algorithm, and build a model that can be used for prediction\n",
    "- `predict(X)`: Given a matrix of user histories, recommend items for these users."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c86675d",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Choosing the right baseclass\n",
    "![algorithm baseclasses](AlgorithmBaseclasses.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d79dab",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Choosing the right baseclass\n",
    "`TorchMLAlgorithm`\n",
    "- `__init__`\n",
    "    - Adds standard parameters (learning rate, batch_size, num_epochs, keep_last, ...)\n",
    "- `fit(X, validation_data)`:\n",
    "    - Epoch loop -> Implement training single epoch\n",
    "    - Early stopping\n",
    "    - Keep best/last model\n",
    "    - Progress logs\n",
    "- `_predict`\n",
    "    - Batched prediction loop -> Implement prediction for single batch\n",
    "    - Prune recommendations \n",
    "- `save` + `load`\n",
    "\n",
    "TODO: Need a better way to indicate what remains to be implemented?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef306ba",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Choosing the right baseclass\n",
    "`TorchMLAlgorithm`\n",
    "\n",
    "We need to implement:\n",
    "\n",
    "- `__init__`: Add hyperparameters\n",
    "- `_init_model`: Initialise the model during training\n",
    "- `_train_epoch`: train for a single epoch\n",
    "- `_predict_batch`: predict for a batch of users\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e359a201",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "class NeuMF(TorchMLAlgorithm):\n",
    "    \"\"\"Implementation of Neural Matrix Factoration.\n",
    "\n",
    "    Neural Matrix Factorization based on MLP architecture\n",
    "    as presented in Figure 2 in He, Xiangnan, et al. \n",
    "    \"Neural collaborative filtering.\"\n",
    "    In Proceedings of the 26th international conference on world wide web. 2017.\n",
    "\n",
    "    Represents the users and items using an embedding, \n",
    "    similarity between the two is modelled using a neural network.\n",
    "\n",
    "    The network consists of an embedding for both users and items.\n",
    "    To compute similarity those two embeddings are \n",
    "    concatenated and passed through the MLP\n",
    "    Finally the similarity is transformed to the [0,1] domain\n",
    "    using a sigmoid function.\n",
    "\n",
    "    As in the paper, the sum of square errors is used as loss function.\n",
    "    Positive items should get a prediction close to 1, \n",
    "    while sampled negatives should get a value close to 0.\n",
    "\n",
    "    The MLP has 3 layers, as suggested in the experiments section.\n",
    "    Bottom layer has dimension `4 * predictive_powers`, \n",
    "    middle layer `2 * predictive_powers`\n",
    "    and the top layer has `predictive_powers`.\n",
    "\n",
    "    :param predictive_powers: Size of the last hidden layer in the MLP network.\n",
    "        Embedding size is 2 * predictive_powers\n",
    "    :type predictive_powers: int\n",
    "    :param batch_size: How many samples to use in each update step.\n",
    "        Higher batch sizes make each epoch more efficient,\n",
    "        but increases the amount of epochs needed to converge to the optimum,\n",
    "        by reducing the amount of updates per epoch.\n",
    "        Defaults to 512.\n",
    "    :type batch_size: Optional[int]\n",
    "    :param max_epochs: The max number of epochs to train.\n",
    "        If the stopping criterion uses early stopping, less epochs could be used.\n",
    "        Defaults to 10.\n",
    "    :type max_epochs: Optional[int]\n",
    "    :param learning_rate: How much to update the weights at each update. Defaults to 0.01\n",
    "    :type learning_rate: Optional[float]\n",
    "    :param stopping_criterion: Name of the stopping criterion to use for training.\n",
    "        For available values,\n",
    "        check :meth:`recpack.algorithms.stopping_criterion.StoppingCriterion.FUNCTIONS`\n",
    "        Defaults to 'ndcg'\n",
    "    :type stopping_criterion: Optional[str]\n",
    "    :param stop_early: If True, early stopping is enabled,\n",
    "        and after ``max_iter_no_change`` iterations where improvement of loss function\n",
    "        is below ``min_improvement`` the optimisation is stopped,\n",
    "        even if max_epochs is not reached.\n",
    "        Defaults to False\n",
    "    :type stop_early: bool, optional\n",
    "    :param max_iter_no_change: If early stopping is enabled,\n",
    "        stop after this amount of iterations without change.\n",
    "        Defaults to 5\n",
    "    :type max_iter_no_change: int, optional\n",
    "    :param min_improvement: If early stopping is enabled, no change is detected,\n",
    "        if the improvement is below this value.\n",
    "        Defaults to 0.01\n",
    "    :type min_improvement: float, optional\n",
    "    :param seed: Seed to the randomizers, useful for reproducible results,\n",
    "        defaults to None\n",
    "    :type seed: int, optional\n",
    "    :param save_best_to_file: If true, the best model will be saved after training,\n",
    "        defaults to False\n",
    "    :type save_best_to_file: bool, optional\n",
    "    :param keep_last: Retain last model, rather than best\n",
    "        (according to stopping criterion value on validation data), defaults to False\n",
    "    :type keep_last: bool, optional\n",
    "    :param predict_topK: The topK recommendations to keep per row in the matrix.\n",
    "        Use when the user x item output matrix would become too large for RAM.\n",
    "        Defaults to None, which results in no filtering.\n",
    "    :type predict_topK: int, optional\n",
    "    :param n_negatives_per_positive: Amount of negatives to sample for each positive example, defaults to 1\n",
    "    :type n_negatives_per_positive: int, optional\n",
    "    :param dropout: Dropout parameter used in MLP, defaults to 0.0\n",
    "    :type dropout: float, optional\n",
    "    :param exact_sampling: Enable or disable exact checks while sampling. \n",
    "        With exact sampling the sampled negatives are guaranteed to not have been visited by the user. \n",
    "        Non exact sampling assumes that the space for item selection is large enough, \n",
    "        such that most items are likely not seen before.\n",
    "        Defaults to False,\n",
    "    :type exact_sampling: bool, optional\n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f85a3147",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "class NeuMF(NeuMF):\n",
    "    def __init__(\n",
    "        self,\n",
    "        predictive_factors: int,\n",
    "        batch_size: Optional[int] = 512,\n",
    "        max_epochs: Optional[int] = 10,\n",
    "        learning_rate: Optional[float] = 0.01,\n",
    "        stopping_criterion: Optional[str] = \"ndcg\",\n",
    "        stop_early: Optional[bool] = False,\n",
    "        max_iter_no_change: Optional[int] = 5,\n",
    "        min_improvement: Optional[float] = 0.0,\n",
    "        seed: Optional[int] = None,\n",
    "        save_best_to_file: Optional[bool] = False,\n",
    "        keep_last: Optional[bool] = False,\n",
    "        predict_topK: Optional[int] = None,\n",
    "        n_negatives_per_positive: Optional[int] = 1,\n",
    "        exact_sampling: Optional[bool] = False,\n",
    "        dropout: Optional[float] = 0.0,\n",
    "    ):\n",
    "        print(batch_size, max_epochs, learning_rate, stopping_criterion)\n",
    "        super().__init__(batch_size, max_epochs, learning_rate,\n",
    "            stopping_criterion, stop_early, max_iter_no_change,\n",
    "            min_improvement, seed, save_best_to_file, keep_last,\n",
    "            predict_topK,\n",
    "        )\n",
    "\n",
    "        self.predictive_factors = predictive_factors\n",
    "\n",
    "        self.n_negatives_per_positive = n_negatives_per_positive\n",
    "        self.dropout = dropout\n",
    "        self.exact_sampling = exact_sampling\n",
    "\n",
    "        self.sampler = PositiveNegativeSampler(\n",
    "            U=self.n_negatives_per_positive, replace=False, exact=exact_sampling, \n",
    "            batch_size=self.batch_size\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a7002850",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "class NeuMF(NeuMF):\n",
    "    def _init_model(self, X: csr_matrix):\n",
    "        num_users, num_items = X.shape\n",
    "        self.model_ = NMFModule(\n",
    "            self.predictive_factors, num_users, num_items, self.dropout\n",
    "        ).to(self.device)\n",
    "\n",
    "        self.optimizer = torch.optim.Adam(\n",
    "            self.model_.parameters(), lr=self.learning_rate\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ee655a20",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "class NeuMF(NeuMF):\n",
    "    def _train_epoch(self, X: csr_matrix) -> List[int]:\n",
    "        losses = []\n",
    "        for users, positives, negatives in self.sampler.sample(X):\n",
    "\n",
    "            self.optimizer.zero_grad()\n",
    "\n",
    "            # Predict for the positives\n",
    "            positive_scores = self.model_(\n",
    "                users.to(self.device), positives.to(self.device))\n",
    "            # Predict for the negatives\n",
    "            negative_scores = self.model_(\n",
    "                *self._construct_negative_prediction_input(\n",
    "                    users.to(self.device), negatives.to(self.device))\n",
    "            )\n",
    "\n",
    "            loss = self._compute_loss(\n",
    "                positive_scores, negative_scores)\n",
    "\n",
    "            # Backwards propagation of the loss\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "\n",
    "            losses.append(loss.item())\n",
    "\n",
    "        return losses\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b0cda7c5",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "class NeuMF(NeuMF):\n",
    "    def _compute_loss(\n",
    "        self, positive_scores: torch.FloatTensor, negative_scores: torch.FloatTensor\n",
    "    ) -> torch.FloatTensor:\n",
    "        \"\"\"Compute the Square Error loss given recommendations \n",
    "        for positive items, and sampled negatives.\n",
    "        \"\"\"\n",
    "\n",
    "        mse = nn.MSELoss(reduction=\"sum\")\n",
    "        return mse(positive_scores, torch.ones_like(positive_scores, dtype=torch.float)) + mse(\n",
    "            negative_scores, torch.zeros_like(negative_scores, dtype=torch.float)\n",
    "        )\n",
    "\n",
    "    def _construct_negative_prediction_input(self, users, negatives):\n",
    "        \"\"\"Construct the prediction input given a 1D user tensor and a 2D negatives tensor.\n",
    "        \n",
    "        Since negatives has shape |batch| x U, and users is a 1d vector,\n",
    "        these need to be turned into two 1D vectors of shape |batch| * U\n",
    "\n",
    "        First the users as a row are stacked U times and transposed,\n",
    "        so that this is also a batch x U tensor.\n",
    "        Then both are reshaped to remove the 2nd dimension, \n",
    "        resulting in a single long 1d vector.\n",
    "        \"\"\"\n",
    "        return (\n",
    "            users.repeat(self.n_negatives_per_positive, 1).T.reshape(-1), \n",
    "            negatives.reshape(-1)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b93dbaa3",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "class NeuMF(NeuMF):\n",
    "    def _batch_predict(\n",
    "        self, X: csr_matrix, users: List[int]\n",
    "    ) -> csr_matrix:\n",
    "        \"\"\"Generate recommendations for each of the users.\"\"\"\n",
    "\n",
    "        X_pred = lil_matrix(X.shape)\n",
    "        if users is None:\n",
    "            users = get_users(X)\n",
    "\n",
    "        _, n_items = X.shape\n",
    "        n_users = len(users)\n",
    "\n",
    "        # Create tensors such that each user, item pair gets a score.\n",
    "        # The user tensor contains the users in order \n",
    "        # (eg. [1, 1, 2, 2]), \n",
    "        # item indices are repeated (eg. [0, 1, 2, 0, 1, 2]).\n",
    "        user_tensor = torch.LongTensor(users).repeat(\n",
    "            n_items, 1).T.reshape(-1).to(self.device)\n",
    "        item_tensor = torch.arange(n_items).repeat(\n",
    "            n_users).to(self.device)\n",
    "\n",
    "        X_pred[users] = self.model_(\n",
    "            user_tensor, item_tensor\n",
    "        ).detach().cpu().numpy().reshape(n_users, n_items)\n",
    "        return X_pred.tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9ca8f574",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "TIMESTAMP_IX = 'ts'\n",
    "ITEM_IX = 'iid'\n",
    "USER_IX = 'uid'\n",
    "\n",
    "data = {\n",
    "    TIMESTAMP_IX: [3, 2, 1, 4, 0, 1, 2, 4, 0, 1, 2],\n",
    "    ITEM_IX: [0, 1, 2, 3, 0, 1, 2, 4, 0, 1, 2],\n",
    "    USER_IX: [0, 0, 1, 1, 2, 2, 3, 3, 4, 4, 5],\n",
    "}\n",
    "df = pd.DataFrame.from_dict(data)\n",
    "\n",
    "mat = InteractionMatrix(df, ITEM_IX, USER_IX, timestamp_ix=TIMESTAMP_IX)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1cf3329d",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512 10 0.01 ndcg\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [19]\u001b[0m, in \u001b[0;36m<cell line: 20>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m     params \u001b[38;5;241m=\u001b[39m [np \u001b[38;5;28;01mfor\u001b[39;00m np \u001b[38;5;129;01min\u001b[39;00m a\u001b[38;5;241m.\u001b[39mmodel_\u001b[38;5;241m.\u001b[39mnamed_parameters() \u001b[38;5;28;01mif\u001b[39;00m np[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mrequires_grad]\n\u001b[1;32m     18\u001b[0m     assert_changed(params_before, params, device)\n\u001b[0;32m---> 20\u001b[0m \u001b[43mtest_training_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbinary_values\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [19]\u001b[0m, in \u001b[0;36mtest_training_epoch\u001b[0;34m(X)\u001b[0m\n\u001b[1;32m     16\u001b[0m     a\u001b[38;5;241m.\u001b[39m_train_epoch(X)\n\u001b[1;32m     17\u001b[0m params \u001b[38;5;241m=\u001b[39m [np \u001b[38;5;28;01mfor\u001b[39;00m np \u001b[38;5;129;01min\u001b[39;00m a\u001b[38;5;241m.\u001b[39mmodel_\u001b[38;5;241m.\u001b[39mnamed_parameters() \u001b[38;5;28;01mif\u001b[39;00m np[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mrequires_grad]\n\u001b[0;32m---> 18\u001b[0m \u001b[43massert_changed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams_before\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/dist-env/lib/python3.8/site-packages/recpack/tests/test_algorithms/util.py:8\u001b[0m, in \u001b[0;36massert_changed\u001b[0;34m(params_before, params_after, device)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21massert_changed\u001b[39m(params_before, params_after, device):\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;66;03m# check if variables have changed\u001b[39;00m\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m (_, p0), (_, p1) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(params_before, params_after):\n\u001b[0;32m----> 8\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mequal(p0\u001b[38;5;241m.\u001b[39mto(device), p1\u001b[38;5;241m.\u001b[39mto(device))\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from recpack.tests.test_algorithms.util import assert_changed, assert_same\n",
    "\n",
    "def test_training_epoch(X):\n",
    "    a = NeuMF(\n",
    "        predictive_factors=2, \n",
    "        n_negatives_per_positive=2,\n",
    "        exact_sampling=True\n",
    "    )\n",
    "    device = a.device\n",
    "    a._init_model(X)\n",
    "\n",
    "    # Each training epoch should update the parameters\n",
    "    params = [np for np in a.model_.named_parameters() if np[1].requires_grad]\n",
    "    params_before = [(name, p.clone()) for (name, p) in params]\n",
    "    for _ in range(5):\n",
    "        a._train_epoch(X)\n",
    "    params = [np for np in a.model_.named_parameters() if np[1].requires_grad]\n",
    "    assert_changed(params_before, params, device)\n",
    "\n",
    "test_training_epoch(mat.binary_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "814b0473",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512 10 0.01 ndcg\n",
      "2022-06-22 19:26:39,625 - base - recpack - INFO - Processed epoch 0 in 0.01 s.Batch Training Loss = 10.4516\n",
      "2022-06-22 19:26:39,635 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.6405398473870061, which is better than previous iterations.\n",
      "2022-06-22 19:26:39,636 - base - recpack - INFO - Model improved. Storing better model.\n",
      "2022-06-22 19:26:39,641 - base - recpack - INFO - Evaluation at end of 0 took 0.02 s.\n",
      "2022-06-22 19:26:39,652 - base - recpack - INFO - Processed epoch 1 in 0.01 s.Batch Training Loss = 10.3924\n",
      "2022-06-22 19:26:39,658 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.6028241164651866, which is worse than previous iterations.\n",
      "2022-06-22 19:26:39,658 - base - recpack - INFO - Evaluation at end of 1 took 0.01 s.\n",
      "2022-06-22 19:26:39,671 - base - recpack - INFO - Processed epoch 2 in 0.01 s.Batch Training Loss = 10.3358\n",
      "2022-06-22 19:26:39,676 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.6028241164651866, which is worse than previous iterations.\n",
      "2022-06-22 19:26:39,676 - base - recpack - INFO - Evaluation at end of 2 took 0.01 s.\n",
      "2022-06-22 19:26:39,693 - base - recpack - INFO - Processed epoch 3 in 0.02 s.Batch Training Loss = 10.2785\n",
      "2022-06-22 19:26:39,698 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.6028241164651866, which is worse than previous iterations.\n",
      "2022-06-22 19:26:39,699 - base - recpack - INFO - Evaluation at end of 3 took 0.00 s.\n",
      "2022-06-22 19:26:39,713 - base - recpack - INFO - Processed epoch 4 in 0.01 s.Batch Training Loss = 10.2206\n",
      "2022-06-22 19:26:39,718 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.6028241164651866, which is worse than previous iterations.\n",
      "2022-06-22 19:26:39,719 - base - recpack - INFO - Evaluation at end of 4 took 0.00 s.\n",
      "2022-06-22 19:26:39,732 - base - recpack - INFO - Processed epoch 5 in 0.01 s.Batch Training Loss = 10.1621\n",
      "2022-06-22 19:26:39,736 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.6028241164651866, which is worse than previous iterations.\n",
      "2022-06-22 19:26:39,737 - base - recpack - INFO - Evaluation at end of 5 took 0.00 s.\n",
      "2022-06-22 19:26:39,752 - base - recpack - INFO - Processed epoch 6 in 0.01 s.Batch Training Loss = 10.1032\n",
      "2022-06-22 19:26:39,756 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.6028241164651866, which is worse than previous iterations.\n",
      "2022-06-22 19:26:39,757 - base - recpack - INFO - Evaluation at end of 6 took 0.00 s.\n",
      "2022-06-22 19:26:39,772 - base - recpack - INFO - Processed epoch 7 in 0.01 s.Batch Training Loss = 10.0437\n",
      "2022-06-22 19:26:39,777 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.6028241164651866, which is worse than previous iterations.\n",
      "2022-06-22 19:26:39,777 - base - recpack - INFO - Evaluation at end of 7 took 0.00 s.\n",
      "2022-06-22 19:26:39,788 - base - recpack - INFO - Processed epoch 8 in 0.01 s.Batch Training Loss = 9.9837\n",
      "2022-06-22 19:26:39,793 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.6028241164651866, which is worse than previous iterations.\n",
      "2022-06-22 19:26:39,794 - base - recpack - INFO - Evaluation at end of 8 took 0.00 s.\n",
      "2022-06-22 19:26:39,804 - base - recpack - INFO - Processed epoch 9 in 0.01 s.Batch Training Loss = 9.9233\n",
      "2022-06-22 19:26:39,808 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.6028241164651866, which is worse than previous iterations.\n",
      "2022-06-22 19:26:39,809 - base - recpack - INFO - Evaluation at end of 9 took 0.00 s.\n",
      "2022-06-22 19:26:39,813 - base - recpack - INFO - Fitting NeuMF complete - Took 0.208s\n",
      "512 10 0.01 ndcg\n",
      "2022-06-22 19:26:39,833 - base - recpack - INFO - Processed epoch 0 in 0.01 s.Batch Training Loss = 9.9468\n",
      "2022-06-22 19:26:39,838 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.7737582122087544, which is better than previous iterations.\n",
      "2022-06-22 19:26:39,838 - base - recpack - INFO - Model improved. Storing better model.\n",
      "2022-06-22 19:26:39,841 - base - recpack - INFO - Evaluation at end of 0 took 0.01 s.\n",
      "2022-06-22 19:26:39,857 - base - recpack - INFO - Processed epoch 1 in 0.02 s.Batch Training Loss = 9.8602\n",
      "2022-06-22 19:26:39,862 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.7372530491956414, which is worse than previous iterations.\n",
      "2022-06-22 19:26:39,863 - base - recpack - INFO - Evaluation at end of 1 took 0.00 s.\n",
      "2022-06-22 19:26:39,878 - base - recpack - INFO - Processed epoch 2 in 0.02 s.Batch Training Loss = 9.8002\n",
      "2022-06-22 19:26:39,884 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.7301688035606183, which is worse than previous iterations.\n",
      "2022-06-22 19:26:39,884 - base - recpack - INFO - Evaluation at end of 2 took 0.01 s.\n",
      "2022-06-22 19:26:39,896 - base - recpack - INFO - Processed epoch 3 in 0.01 s.Batch Training Loss = 9.7273\n",
      "2022-06-22 19:26:39,902 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.7301688035606183, which is worse than previous iterations.\n",
      "2022-06-22 19:26:39,902 - base - recpack - INFO - Evaluation at end of 3 took 0.01 s.\n",
      "2022-06-22 19:26:39,917 - base - recpack - INFO - Processed epoch 4 in 0.01 s.Batch Training Loss = 9.6632\n",
      "2022-06-22 19:26:39,922 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.7443372948306645, which is worse than previous iterations.\n",
      "2022-06-22 19:26:39,923 - base - recpack - INFO - Evaluation at end of 4 took 0.01 s.\n",
      "2022-06-22 19:26:39,935 - base - recpack - INFO - Processed epoch 5 in 0.01 s.Batch Training Loss = 9.5924\n",
      "2022-06-22 19:26:39,940 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.7372530491956414, which is worse than previous iterations.\n",
      "2022-06-22 19:26:39,941 - base - recpack - INFO - Evaluation at end of 5 took 0.01 s.\n",
      "2022-06-22 19:26:39,952 - base - recpack - INFO - Processed epoch 6 in 0.01 s.Batch Training Loss = 9.5142\n",
      "2022-06-22 19:26:39,957 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.7372530491956414, which is worse than previous iterations.\n",
      "2022-06-22 19:26:39,958 - base - recpack - INFO - Evaluation at end of 6 took 0.00 s.\n",
      "2022-06-22 19:26:39,970 - base - recpack - INFO - Processed epoch 7 in 0.01 s.Batch Training Loss = 9.4398\n",
      "2022-06-22 19:26:39,975 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.7372530491956414, which is worse than previous iterations.\n",
      "2022-06-22 19:26:39,976 - base - recpack - INFO - Evaluation at end of 7 took 0.01 s.\n",
      "2022-06-22 19:26:39,995 - base - recpack - INFO - Processed epoch 8 in 0.02 s.Batch Training Loss = 9.3403\n",
      "2022-06-22 19:26:40,001 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.7372530491956414, which is worse than previous iterations.\n",
      "2022-06-22 19:26:40,001 - base - recpack - INFO - Evaluation at end of 8 took 0.01 s.\n",
      "2022-06-22 19:26:40,015 - base - recpack - INFO - Processed epoch 9 in 0.01 s.Batch Training Loss = 9.2433\n",
      "2022-06-22 19:26:40,020 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.7372530491956414, which is worse than previous iterations.\n",
      "2022-06-22 19:26:40,021 - base - recpack - INFO - Evaluation at end of 9 took 0.01 s.\n",
      "2022-06-22 19:26:40,024 - base - recpack - INFO - Fitting NeuMF complete - Took 0.205s\n",
      "512 10 0.01 ndcg\n",
      "2022-06-22 19:26:40,043 - base - recpack - INFO - Processed epoch 0 in 0.01 s.Batch Training Loss = 9.6960\n",
      "2022-06-22 19:26:40,048 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.7837146108282446, which is better than previous iterations.\n",
      "2022-06-22 19:26:40,048 - base - recpack - INFO - Model improved. Storing better model.\n",
      "2022-06-22 19:26:40,051 - base - recpack - INFO - Evaluation at end of 0 took 0.01 s.\n",
      "2022-06-22 19:26:40,064 - base - recpack - INFO - Processed epoch 1 in 0.01 s.Batch Training Loss = 9.5650\n",
      "2022-06-22 19:26:40,069 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.7863204548293853, which is better than previous iterations.\n",
      "2022-06-22 19:26:40,069 - base - recpack - INFO - Model improved. Storing better model.\n",
      "2022-06-22 19:26:40,072 - base - recpack - INFO - Evaluation at end of 1 took 0.01 s.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-06-22 19:26:40,092 - base - recpack - INFO - Processed epoch 2 in 0.02 s.Batch Training Loss = 9.4404\n",
      "2022-06-22 19:26:40,097 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.7838062179781108, which is worse than previous iterations.\n",
      "2022-06-22 19:26:40,097 - base - recpack - INFO - Evaluation at end of 2 took 0.00 s.\n",
      "2022-06-22 19:26:40,107 - base - recpack - INFO - Processed epoch 3 in 0.01 s.Batch Training Loss = 9.3179\n",
      "2022-06-22 19:26:40,112 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.7659479478689263, which is worse than previous iterations.\n",
      "2022-06-22 19:26:40,112 - base - recpack - INFO - Evaluation at end of 3 took 0.00 s.\n",
      "2022-06-22 19:26:40,124 - base - recpack - INFO - Processed epoch 4 in 0.01 s.Batch Training Loss = 9.2018\n",
      "2022-06-22 19:26:40,129 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.8524021713512242, which is better than previous iterations.\n",
      "2022-06-22 19:26:40,130 - base - recpack - INFO - Model improved. Storing better model.\n",
      "2022-06-22 19:26:40,133 - base - recpack - INFO - Evaluation at end of 4 took 0.01 s.\n",
      "2022-06-22 19:26:40,151 - base - recpack - INFO - Processed epoch 5 in 0.02 s.Batch Training Loss = 9.0883\n",
      "2022-06-22 19:26:40,157 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.8319380572408991, which is worse than previous iterations.\n",
      "2022-06-22 19:26:40,157 - base - recpack - INFO - Evaluation at end of 5 took 0.01 s.\n",
      "2022-06-22 19:26:40,179 - base - recpack - INFO - Processed epoch 6 in 0.02 s.Batch Training Loss = 8.9781\n",
      "2022-06-22 19:26:40,184 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.6988666359953621, which is worse than previous iterations.\n",
      "2022-06-22 19:26:40,184 - base - recpack - INFO - Evaluation at end of 6 took 0.00 s.\n",
      "2022-06-22 19:26:40,198 - base - recpack - INFO - Processed epoch 7 in 0.01 s.Batch Training Loss = 8.8724\n",
      "2022-06-22 19:26:40,203 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.6610039614973312, which is worse than previous iterations.\n",
      "2022-06-22 19:26:40,203 - base - recpack - INFO - Evaluation at end of 7 took 0.00 s.\n",
      "2022-06-22 19:26:40,214 - base - recpack - INFO - Processed epoch 8 in 0.01 s.Batch Training Loss = 8.7675\n",
      "2022-06-22 19:26:40,218 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.6232882305755117, which is worse than previous iterations.\n",
      "2022-06-22 19:26:40,219 - base - recpack - INFO - Evaluation at end of 8 took 0.00 s.\n",
      "2022-06-22 19:26:40,233 - base - recpack - INFO - Processed epoch 9 in 0.01 s.Batch Training Loss = 8.6667\n",
      "2022-06-22 19:26:40,238 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.6246457420604296, which is worse than previous iterations.\n",
      "2022-06-22 19:26:40,238 - base - recpack - INFO - Evaluation at end of 9 took 0.00 s.\n",
      "2022-06-22 19:26:40,242 - base - recpack - INFO - Fitting NeuMF complete - Took 0.213s\n"
     ]
    }
   ],
   "source": [
    "def test_batch_predict(mat, users):\n",
    "    a = NeuMF(\n",
    "        predictive_factors=2, \n",
    "        n_negatives_per_positive=2,\n",
    "        exact_sampling=True\n",
    "    )\n",
    "    device = a.device\n",
    "    a.fit(mat, (mat, mat))\n",
    "    params = [np for np in a.model_.named_parameters() if np[1].requires_grad]\n",
    "    params_before = [(name, p.clone()) for (name, p) in params]\n",
    "\n",
    "    pred = a._batch_predict(mat.users_in(users), users=users)\n",
    "\n",
    "    assert pred.shape == mat.shape\n",
    "    np.testing.assert_array_equal(pred.sum(axis=1).nonzero()[0], users)\n",
    "\n",
    "    params = [np for np in a.model_.named_parameters() if np[1].requires_grad]\n",
    "    assert_same(params_before, params, device)\n",
    "\n",
    "    \n",
    "\n",
    "test_batch_predict(mat, [0, 1])\n",
    "test_batch_predict(mat, [0])\n",
    "test_batch_predict(mat, [0, 1, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ed4d2e7d",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512 10 0.01 ndcg\n",
      "512 10 0.01 ndcg\n"
     ]
    }
   ],
   "source": [
    "def test_negative_input_construction(users, negatives, U):\n",
    "    \n",
    "    a = NeuMF(\n",
    "        predictive_factors=8, \n",
    "        n_negatives_per_positive=U\n",
    "    )\n",
    "    \n",
    "    num_users = users.shape[0]\n",
    "    users_input, negatives_input = a._construct_negative_prediction_input(users, negatives)\n",
    "    assert users_input.shape == negatives_input.shape\n",
    "    assert len(users_input.shape) == 1 # 1d vectors\n",
    "    \n",
    "    # Check that both are in the right order (each user is repeated U times before the next user is present)\n",
    "    for ix in range(users_input.shape[0]):\n",
    "        assert users_input[ix] == users[ix // U]\n",
    "        assert negatives_input[ix] == negatives[ix // U, ix % U]\n",
    "\n",
    "test_negative_input_construction(torch.LongTensor([4, 5, 6]), torch.LongTensor([[1, 2], [1, 2], [1, 2]]), U=2)\n",
    "test_negative_input_construction(torch.LongTensor([4, 5, 6]), torch.LongTensor([[1], [1], [1]]), U=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7f31c898",
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 20 0.02 ndcg\n",
      "2022-06-22 19:26:42,899 - base - recpack - INFO - Processed epoch 0 in 0.05 s.Batch Training Loss = 0.5015\n",
      "2022-06-22 19:26:42,911 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.7633421038677857, which is better than previous iterations.\n",
      "2022-06-22 19:26:42,912 - base - recpack - INFO - Model improved. Storing better model.\n",
      "2022-06-22 19:26:42,915 - base - recpack - INFO - Evaluation at end of 0 took 0.01 s.\n",
      "2022-06-22 19:26:42,961 - base - recpack - INFO - Processed epoch 1 in 0.05 s.Batch Training Loss = 0.5001\n",
      "2022-06-22 19:26:42,973 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.7819889967717142, which is better than previous iterations.\n",
      "2022-06-22 19:26:42,974 - base - recpack - INFO - Model improved. Storing better model.\n",
      "2022-06-22 19:26:42,977 - base - recpack - INFO - Evaluation at end of 1 took 0.02 s.\n",
      "2022-06-22 19:26:43,024 - base - recpack - INFO - Processed epoch 2 in 0.05 s.Batch Training Loss = 0.4998\n",
      "2022-06-22 19:26:43,037 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.7908904636131339, which is better than previous iterations.\n",
      "2022-06-22 19:26:43,037 - base - recpack - INFO - Model improved. Storing better model.\n",
      "2022-06-22 19:26:43,040 - base - recpack - INFO - Evaluation at end of 2 took 0.01 s.\n",
      "2022-06-22 19:26:43,087 - base - recpack - INFO - Processed epoch 3 in 0.05 s.Batch Training Loss = 0.4977\n",
      "2022-06-22 19:26:43,099 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.7690688380178908, which is worse than previous iterations.\n",
      "2022-06-22 19:26:43,099 - base - recpack - INFO - Evaluation at end of 3 took 0.01 s.\n",
      "2022-06-22 19:26:43,143 - base - recpack - INFO - Processed epoch 4 in 0.04 s.Batch Training Loss = 0.4829\n",
      "2022-06-22 19:26:43,155 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.7690688380178909, which is worse than previous iterations.\n",
      "2022-06-22 19:26:43,155 - base - recpack - INFO - Evaluation at end of 4 took 0.01 s.\n",
      "2022-06-22 19:26:43,203 - base - recpack - INFO - Processed epoch 5 in 0.05 s.Batch Training Loss = 0.4504\n",
      "2022-06-22 19:26:43,216 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.7690688380178909, which is worse than previous iterations.\n",
      "2022-06-22 19:26:43,217 - base - recpack - INFO - Evaluation at end of 5 took 0.01 s.\n",
      "2022-06-22 19:26:43,266 - base - recpack - INFO - Processed epoch 6 in 0.05 s.Batch Training Loss = 0.4387\n",
      "2022-06-22 19:26:43,280 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.743126726921958, which is worse than previous iterations.\n",
      "2022-06-22 19:26:43,281 - base - recpack - INFO - Evaluation at end of 6 took 0.01 s.\n",
      "2022-06-22 19:26:43,332 - base - recpack - INFO - Processed epoch 7 in 0.05 s.Batch Training Loss = 0.3989\n",
      "2022-06-22 19:26:43,344 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.9545933701454672, which is better than previous iterations.\n",
      "2022-06-22 19:26:43,345 - base - recpack - INFO - Model improved. Storing better model.\n",
      "2022-06-22 19:26:43,348 - base - recpack - INFO - Evaluation at end of 7 took 0.02 s.\n",
      "2022-06-22 19:26:43,400 - base - recpack - INFO - Processed epoch 8 in 0.05 s.Batch Training Loss = 0.3235\n",
      "2022-06-22 19:26:43,413 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.9750574842557924, which is better than previous iterations.\n",
      "2022-06-22 19:26:43,413 - base - recpack - INFO - Model improved. Storing better model.\n",
      "2022-06-22 19:26:43,417 - base - recpack - INFO - Evaluation at end of 8 took 0.02 s.\n",
      "2022-06-22 19:26:43,469 - base - recpack - INFO - Processed epoch 9 in 0.05 s.Batch Training Loss = 0.3258\n",
      "2022-06-22 19:26:43,481 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.9999999999999999, which is better than previous iterations.\n",
      "2022-06-22 19:26:43,482 - base - recpack - INFO - Model improved. Storing better model.\n",
      "2022-06-22 19:26:43,486 - base - recpack - INFO - Evaluation at end of 9 took 0.02 s.\n",
      "2022-06-22 19:26:43,535 - base - recpack - INFO - Processed epoch 10 in 0.05 s.Batch Training Loss = 0.2526\n",
      "2022-06-22 19:26:43,548 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.9489044006028783, which is worse than previous iterations.\n",
      "2022-06-22 19:26:43,548 - base - recpack - INFO - Evaluation at end of 10 took 0.01 s.\n",
      "2022-06-22 19:26:43,596 - base - recpack - INFO - Processed epoch 11 in 0.05 s.Batch Training Loss = 0.1978\n",
      "2022-06-22 19:26:43,608 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.9355245321275762, which is worse than previous iterations.\n",
      "2022-06-22 19:26:43,609 - base - recpack - INFO - Evaluation at end of 11 took 0.01 s.\n",
      "2022-06-22 19:26:43,660 - base - recpack - INFO - Processed epoch 12 in 0.05 s.Batch Training Loss = 0.1661\n",
      "2022-06-22 19:26:43,673 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.9251084237866075, which is worse than previous iterations.\n",
      "2022-06-22 19:26:43,674 - base - recpack - INFO - Evaluation at end of 12 took 0.01 s.\n",
      "2022-06-22 19:26:43,721 - base - recpack - INFO - Processed epoch 13 in 0.05 s.Batch Training Loss = 0.2142\n",
      "2022-06-22 19:26:43,734 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.9866201315246979, which is worse than previous iterations.\n",
      "2022-06-22 19:26:43,734 - base - recpack - INFO - Evaluation at end of 13 took 0.01 s.\n",
      "2022-06-22 19:26:43,782 - base - recpack - INFO - Processed epoch 14 in 0.05 s.Batch Training Loss = 0.1242\n",
      "2022-06-22 19:26:43,795 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.9251084237866075, which is worse than previous iterations.\n",
      "2022-06-22 19:26:43,795 - base - recpack - INFO - Evaluation at end of 14 took 0.01 s.\n",
      "2022-06-22 19:26:43,844 - base - recpack - INFO - Processed epoch 15 in 0.05 s.Batch Training Loss = 0.0991\n",
      "2022-06-22 19:26:43,856 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.9866201315246979, which is worse than previous iterations.\n",
      "2022-06-22 19:26:43,857 - base - recpack - INFO - Evaluation at end of 15 took 0.01 s.\n",
      "2022-06-22 19:26:43,916 - base - recpack - INFO - Processed epoch 16 in 0.06 s.Batch Training Loss = 0.1188\n",
      "2022-06-22 19:26:43,929 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.9866201315246979, which is worse than previous iterations.\n",
      "2022-06-22 19:26:43,930 - base - recpack - INFO - Evaluation at end of 16 took 0.01 s.\n",
      "2022-06-22 19:26:43,978 - base - recpack - INFO - Processed epoch 17 in 0.05 s.Batch Training Loss = 0.1588\n",
      "2022-06-22 19:26:43,991 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.9489044006028784, which is worse than previous iterations.\n",
      "2022-06-22 19:26:43,991 - base - recpack - INFO - Evaluation at end of 17 took 0.01 s.\n",
      "2022-06-22 19:26:44,043 - base - recpack - INFO - Processed epoch 18 in 0.05 s.Batch Training Loss = 0.0280\n",
      "2022-06-22 19:26:44,055 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.9866201315246979, which is worse than previous iterations.\n",
      "2022-06-22 19:26:44,056 - base - recpack - INFO - Evaluation at end of 18 took 0.01 s.\n",
      "2022-06-22 19:26:44,102 - base - recpack - INFO - Processed epoch 19 in 0.05 s.Batch Training Loss = 0.0902\n",
      "2022-06-22 19:26:44,115 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.9866201315246979, which is worse than previous iterations.\n",
      "2022-06-22 19:26:44,115 - base - recpack - INFO - Evaluation at end of 19 took 0.01 s.\n",
      "2022-06-22 19:26:44,119 - base - recpack - INFO - Fitting NeuMF complete - Took 1.27s\n"
     ]
    }
   ],
   "source": [
    "def test_overfit(mat):\n",
    "    m = NeuMF(\n",
    "        predictive_factors=5,\n",
    "        batch_size=1,\n",
    "        max_epochs=20,\n",
    "        learning_rate=0.02,\n",
    "        stopping_criterion=\"ndcg\",\n",
    "        n_negatives_per_positive=1,\n",
    "    )\n",
    "\n",
    "    # set sampler to exact sampling\n",
    "    m.sampler.exact = True\n",
    "    m.fit(mat, (mat, mat))\n",
    "    bin_mat = mat.binary_values\n",
    "    pred = m.predict(mat.binary_values).toarray()\n",
    "    for user in mat.active_users:\n",
    "        # The model should have overfitted, so that the visited items have the highest similarities\n",
    "        positives = bin_mat[user].nonzero()[1]\n",
    "        negatives = list(set(range(mat.shape[1])) - set(positives))\n",
    "\n",
    "        for item in positives:\n",
    "            assert (pred[user][negatives] < pred[user, item]).all()\n",
    "            \n",
    "test_overfit(mat)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b414610",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Experiment\n",
    "\n",
    "Use RecPack Pipeline to compare the newly implemented algorithm to frequently used baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f3225456",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from recpack.pipelines import PipelineBuilder\n",
    "from recpack.datasets import MovieLens25M\n",
    "from recpack.scenarios import WeakGeneralization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8bb256ed",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "DATASET_PATH = '/home/robinverachtert/datasets'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "345019f0",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "902bdc7c7f584ef6a958d9d84c460a62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12415224 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cd05c1547ee4b9fae9a177ac4e4df5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12415224 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = MovieLens25M(\n",
    "    path=DATASET_PATH\n",
    ")\n",
    "data = dataset.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "47169d75",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# Subsample to 1000 users to make it faster\n",
    "# import numpy as np\n",
    "\n",
    "# users = np.random.choice(list(data.active_users), 1000)\n",
    "# data = data.users_in(users)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0452e6d",
   "metadata": {},
   "source": [
    "### Choosing the right scenario\n",
    "\n",
    "- LastItemPrediction\n",
    "- StrongGeneralization\n",
    "- StrongGeneralizationTimed\n",
    "- StrongGeneralizationTimedMostRecent\n",
    "- Timed\n",
    "- WeakGeneralization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a5a8b9ab",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b60c748c292f46f9b1f4b88483b936c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "403e41b3b91e46a0a90c663fd66ca7a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scenario = WeakGeneralization(frac_data_in=0.8, validation=True)\n",
    "scenario.split(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ba6aa1bc",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from recpack.pipelines import ALGORITHM_REGISTRY\n",
    "ALGORITHM_REGISTRY.register('NeuMF', NeuMF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2c46caa2",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "builder = PipelineBuilder()\n",
    "builder.set_data_from_scenario(scenario)\n",
    "\n",
    "builder.add_metric('NDCGK', K=10)\n",
    "builder.add_metric('CoverageK', K=10)\n",
    "\n",
    "builder.add_algorithm(\n",
    "    algorithm = 'NeuMF', \n",
    "    params = {\n",
    "        'batch_size': 128,\n",
    "        'max_epochs': 10,\n",
    "        'learning_rate': 0.01,\n",
    "        'stopping_criterion': 'ndcg',\n",
    "        'predict_topK': 20,\n",
    "        'n_negatives_per_positive': 3,\n",
    "        'dropout': 0.01\n",
    "    },\n",
    "    grid = {\n",
    "        'predictive_factors': [8, 16, 32],\n",
    "    }\n",
    ")\n",
    "\n",
    "builder.add_algorithm('Popularity', params={'K': 20})\n",
    "builder.add_algorithm(\n",
    "    'ItemKNN', \n",
    "    grid={'similarity': ['conditional_probability', 'cosine']}\n",
    ")\n",
    "builder.set_optimisation_metric('NDCGK', K=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "05c0a518",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "pipeline = builder.build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3314c304",
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3f8117d364d4e119d4bcce17acfb868",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128 10 0.01 ndcg\n",
      "2022-06-22 19:34:27,322 - base - recpack - INFO - Processed epoch 0 in 245.66 s.Batch Training Loss = 39.9801\n",
      "2022-06-22 20:03:52,854 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.0807752474141612, which is better than previous iterations.\n",
      "2022-06-22 20:03:52,855 - base - recpack - INFO - Model improved. Storing better model.\n",
      "2022-06-22 20:03:52,876 - base - recpack - INFO - Evaluation at end of 0 took 1765.55 s.\n",
      "2022-06-22 20:07:56,205 - base - recpack - INFO - Processed epoch 1 in 243.32 s.Batch Training Loss = 33.0413\n",
      "2022-06-22 20:37:07,710 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.08761402269236272, which is better than previous iterations.\n",
      "2022-06-22 20:37:07,711 - base - recpack - INFO - Model improved. Storing better model.\n",
      "2022-06-22 20:37:07,733 - base - recpack - INFO - Evaluation at end of 1 took 1751.53 s.\n",
      "2022-06-22 20:41:10,411 - base - recpack - INFO - Processed epoch 2 in 242.67 s.Batch Training Loss = 31.0265\n",
      "2022-06-22 21:08:58,321 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.09020461206240907, which is better than previous iterations.\n",
      "2022-06-22 21:08:58,322 - base - recpack - INFO - Model improved. Storing better model.\n",
      "2022-06-22 21:08:58,342 - base - recpack - INFO - Evaluation at end of 2 took 1667.93 s.\n",
      "2022-06-22 21:12:56,631 - base - recpack - INFO - Processed epoch 3 in 238.28 s.Batch Training Loss = 30.0155\n",
      "2022-06-22 21:40:06,768 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.09515308926992498, which is better than previous iterations.\n",
      "2022-06-22 21:40:06,769 - base - recpack - INFO - Model improved. Storing better model.\n",
      "2022-06-22 21:40:06,789 - base - recpack - INFO - Evaluation at end of 3 took 1630.16 s.\n",
      "2022-06-22 21:44:04,325 - base - recpack - INFO - Processed epoch 4 in 237.53 s.Batch Training Loss = 29.1366\n",
      "2022-06-22 22:11:55,894 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.09116380007015186, which is worse than previous iterations.\n",
      "2022-06-22 22:11:55,896 - base - recpack - INFO - Evaluation at end of 4 took 1671.57 s.\n",
      "2022-06-22 22:16:02,100 - base - recpack - INFO - Processed epoch 5 in 246.20 s.Batch Training Loss = 28.5276\n",
      "2022-06-22 22:46:10,269 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.0969775874251478, which is better than previous iterations.\n",
      "2022-06-22 22:46:10,270 - base - recpack - INFO - Model improved. Storing better model.\n",
      "2022-06-22 22:46:10,291 - base - recpack - INFO - Evaluation at end of 5 took 1808.19 s.\n",
      "2022-06-22 22:50:17,526 - base - recpack - INFO - Processed epoch 6 in 247.23 s.Batch Training Loss = 28.0716\n",
      "2022-06-22 23:20:03,414 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.09724975037252163, which is better than previous iterations.\n",
      "2022-06-22 23:20:03,415 - base - recpack - INFO - Model improved. Storing better model.\n",
      "2022-06-22 23:20:03,436 - base - recpack - INFO - Evaluation at end of 6 took 1785.91 s.\n",
      "2022-06-22 23:24:07,652 - base - recpack - INFO - Processed epoch 7 in 244.21 s.Batch Training Loss = 27.7030\n",
      "2022-06-22 23:52:35,934 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.09861493778883344, which is better than previous iterations.\n",
      "2022-06-22 23:52:35,936 - base - recpack - INFO - Model improved. Storing better model.\n",
      "2022-06-22 23:52:35,956 - base - recpack - INFO - Evaluation at end of 7 took 1708.30 s.\n",
      "2022-06-22 23:56:32,927 - base - recpack - INFO - Processed epoch 8 in 236.97 s.Batch Training Loss = 27.3997\n",
      "2022-06-23 00:23:58,193 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.09459366063534502, which is worse than previous iterations.\n",
      "2022-06-23 00:23:58,196 - base - recpack - INFO - Evaluation at end of 8 took 1645.27 s.\n",
      "2022-06-23 00:27:54,936 - base - recpack - INFO - Processed epoch 9 in 236.74 s.Batch Training Loss = 27.1639\n",
      "2022-06-23 00:55:03,867 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.09953214052288922, which is better than previous iterations.\n",
      "2022-06-23 00:55:03,869 - base - recpack - INFO - Model improved. Storing better model.\n",
      "2022-06-23 00:55:03,893 - base - recpack - INFO - Evaluation at end of 9 took 1628.96 s.\n",
      "2022-06-23 00:55:03,904 - base - recpack - INFO - Fitting NeuMF complete - Took 1.95e+04s\n",
      "128 10 0.01 ndcg\n",
      "2022-06-23 01:30:04,548 - base - recpack - INFO - Processed epoch 0 in 328.21 s.Batch Training Loss = 38.9921\n",
      "2022-06-23 02:00:32,234 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.08503753709991231, which is better than previous iterations.\n",
      "2022-06-23 02:00:32,235 - base - recpack - INFO - Model improved. Storing better model.\n",
      "2022-06-23 02:00:32,279 - base - recpack - INFO - Evaluation at end of 0 took 1827.73 s.\n",
      "2022-06-23 02:05:57,837 - base - recpack - INFO - Processed epoch 1 in 325.55 s.Batch Training Loss = 32.5183\n",
      "2022-06-23 02:35:37,037 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.0876874728901237, which is better than previous iterations.\n",
      "2022-06-23 02:35:37,038 - base - recpack - INFO - Model improved. Storing better model.\n",
      "2022-06-23 02:35:37,081 - base - recpack - INFO - Evaluation at end of 1 took 1779.24 s.\n",
      "2022-06-23 02:40:58,152 - base - recpack - INFO - Processed epoch 2 in 321.07 s.Batch Training Loss = 30.4448\n",
      "2022-06-23 03:07:08,261 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.09376696992773687, which is better than previous iterations.\n",
      "2022-06-23 03:07:08,262 - base - recpack - INFO - Model improved. Storing better model.\n",
      "2022-06-23 03:07:08,305 - base - recpack - INFO - Evaluation at end of 2 took 1570.15 s.\n",
      "2022-06-23 03:12:27,845 - base - recpack - INFO - Processed epoch 3 in 319.54 s.Batch Training Loss = 29.2488\n",
      "2022-06-23 03:40:12,298 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.09785262253730144, which is better than previous iterations.\n",
      "2022-06-23 03:40:12,299 - base - recpack - INFO - Model improved. Storing better model.\n",
      "2022-06-23 03:40:12,335 - base - recpack - INFO - Evaluation at end of 3 took 1664.49 s.\n",
      "2022-06-23 03:45:31,027 - base - recpack - INFO - Processed epoch 4 in 318.69 s.Batch Training Loss = 28.4492\n",
      "2022-06-23 04:14:16,928 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.09534398466632851, which is worse than previous iterations.\n",
      "2022-06-23 04:14:16,929 - base - recpack - INFO - Evaluation at end of 4 took 1725.90 s.\n",
      "2022-06-23 04:19:47,100 - base - recpack - INFO - Processed epoch 5 in 330.17 s.Batch Training Loss = 27.9003\n",
      "2022-06-23 04:49:28,499 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.09994501514677542, which is better than previous iterations.\n",
      "2022-06-23 04:49:28,500 - base - recpack - INFO - Model improved. Storing better model.\n",
      "2022-06-23 04:49:28,539 - base - recpack - INFO - Evaluation at end of 5 took 1781.44 s.\n",
      "2022-06-23 04:54:54,511 - base - recpack - INFO - Processed epoch 6 in 325.97 s.Batch Training Loss = 27.4033\n",
      "2022-06-23 05:24:27,834 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.10456761059909804, which is better than previous iterations.\n",
      "2022-06-23 05:24:27,835 - base - recpack - INFO - Model improved. Storing better model.\n",
      "2022-06-23 05:24:27,875 - base - recpack - INFO - Evaluation at end of 6 took 1773.36 s.\n",
      "2022-06-23 05:29:52,889 - base - recpack - INFO - Processed epoch 7 in 325.01 s.Batch Training Loss = 26.9981\n",
      "2022-06-23 05:58:26,231 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.10423341988925663, which is worse than previous iterations.\n",
      "2022-06-23 05:58:26,232 - base - recpack - INFO - Evaluation at end of 7 took 1713.34 s.\n",
      "2022-06-23 06:03:48,270 - base - recpack - INFO - Processed epoch 8 in 322.03 s.Batch Training Loss = 27.2013\n",
      "2022-06-23 06:32:38,761 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.029343878599265686, which is worse than previous iterations.\n",
      "2022-06-23 06:32:38,762 - base - recpack - INFO - Evaluation at end of 8 took 1730.49 s.\n",
      "2022-06-23 06:38:00,630 - base - recpack - INFO - Processed epoch 9 in 321.86 s.Batch Training Loss = 32.6222\n",
      "2022-06-23 07:01:36,644 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.02108832435436341, which is worse than previous iterations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-06-23 07:01:36,645 - base - recpack - INFO - Evaluation at end of 9 took 1416.01 s.\n",
      "2022-06-23 07:01:36,665 - base - recpack - INFO - Fitting NeuMF complete - Took 2.02e+04s\n",
      "128 10 0.01 ndcg\n",
      "2022-06-23 07:40:50,696 - base - recpack - INFO - Processed epoch 0 in 509.58 s.Batch Training Loss = 38.9571\n",
      "2022-06-23 08:12:34,783 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.08408753015707665, which is better than previous iterations.\n",
      "2022-06-23 08:12:34,784 - base - recpack - INFO - Model improved. Storing better model.\n",
      "2022-06-23 08:12:34,861 - base - recpack - INFO - Evaluation at end of 0 took 1904.16 s.\n",
      "2022-06-23 08:21:03,305 - base - recpack - INFO - Processed epoch 1 in 508.44 s.Batch Training Loss = 32.6848\n",
      "2022-06-23 08:48:31,171 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.0898314980420112, which is better than previous iterations.\n",
      "2022-06-23 08:48:31,172 - base - recpack - INFO - Model improved. Storing better model.\n",
      "2022-06-23 08:48:31,257 - base - recpack - INFO - Evaluation at end of 1 took 1647.95 s.\n",
      "2022-06-23 08:56:57,651 - base - recpack - INFO - Processed epoch 2 in 506.39 s.Batch Training Loss = 32.1921\n",
      "2022-06-23 09:22:22,394 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.09901336060470675, which is better than previous iterations.\n",
      "2022-06-23 09:22:22,395 - base - recpack - INFO - Model improved. Storing better model.\n",
      "2022-06-23 09:22:22,482 - base - recpack - INFO - Evaluation at end of 2 took 1524.83 s.\n",
      "2022-06-23 09:30:49,982 - base - recpack - INFO - Processed epoch 3 in 507.50 s.Batch Training Loss = 37.1867\n",
      "2022-06-23 09:55:51,330 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.014172773438036794, which is worse than previous iterations.\n",
      "2022-06-23 09:55:51,331 - base - recpack - INFO - Evaluation at end of 3 took 1501.35 s.\n",
      "2022-06-23 10:04:11,969 - base - recpack - INFO - Processed epoch 4 in 500.63 s.Batch Training Loss = 40.0429\n",
      "2022-06-23 10:28:56,195 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.009715459199457818, which is worse than previous iterations.\n",
      "2022-06-23 10:28:56,197 - base - recpack - INFO - Evaluation at end of 4 took 1484.23 s.\n",
      "2022-06-23 10:37:17,523 - base - recpack - INFO - Processed epoch 5 in 501.32 s.Batch Training Loss = 40.8707\n",
      "2022-06-23 11:02:34,938 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.009117473940428476, which is worse than previous iterations.\n",
      "2022-06-23 11:02:34,940 - base - recpack - INFO - Evaluation at end of 5 took 1517.42 s.\n",
      "2022-06-23 11:11:09,419 - base - recpack - INFO - Processed epoch 6 in 514.47 s.Batch Training Loss = 41.5459\n",
      "2022-06-23 11:37:32,146 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.01108954018010079, which is worse than previous iterations.\n",
      "2022-06-23 11:37:32,147 - base - recpack - INFO - Evaluation at end of 6 took 1582.73 s.\n",
      "2022-06-23 11:46:05,304 - base - recpack - INFO - Processed epoch 7 in 513.15 s.Batch Training Loss = 40.8286\n",
      "2022-06-23 12:12:31,054 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.011325359132667596, which is worse than previous iterations.\n",
      "2022-06-23 12:12:31,055 - base - recpack - INFO - Evaluation at end of 7 took 1585.75 s.\n",
      "2022-06-23 12:21:06,111 - base - recpack - INFO - Processed epoch 8 in 515.05 s.Batch Training Loss = 40.2088\n",
      "2022-06-23 12:47:25,952 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.007727047050919747, which is worse than previous iterations.\n",
      "2022-06-23 12:47:25,954 - base - recpack - INFO - Evaluation at end of 8 took 1579.84 s.\n",
      "2022-06-23 12:55:47,621 - base - recpack - INFO - Processed epoch 9 in 501.66 s.Batch Training Loss = 41.8032\n",
      "2022-06-23 13:21:09,693 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.012638527761507708, which is worse than previous iterations.\n",
      "2022-06-23 13:21:09,694 - base - recpack - INFO - Evaluation at end of 9 took 1522.07 s.\n",
      "2022-06-23 13:21:09,730 - base - recpack - INFO - Fitting NeuMF complete - Took 2.09e+04s\n",
      "128 10 0.01 ndcg\n",
      "2022-06-23 13:52:56,522 - base - recpack - INFO - Processed epoch 0 in 330.45 s.Batch Training Loss = 39.8566\n",
      "2022-06-23 14:23:55,765 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.0831714927494918, which is better than previous iterations.\n",
      "2022-06-23 14:23:55,766 - base - recpack - INFO - Model improved. Storing better model.\n",
      "2022-06-23 14:23:55,801 - base - recpack - INFO - Evaluation at end of 0 took 1859.28 s.\n",
      "2022-06-23 14:29:21,252 - base - recpack - INFO - Processed epoch 1 in 325.45 s.Batch Training Loss = 33.0599\n",
      "2022-06-23 14:59:34,534 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.094375020540076, which is better than previous iterations.\n",
      "2022-06-23 14:59:34,535 - base - recpack - INFO - Model improved. Storing better model.\n",
      "2022-06-23 14:59:34,573 - base - recpack - INFO - Evaluation at end of 1 took 1813.32 s.\n",
      "2022-06-23 15:04:59,677 - base - recpack - INFO - Processed epoch 2 in 325.10 s.Batch Training Loss = 31.1564\n",
      "2022-06-23 15:35:39,205 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.09799131604644282, which is better than previous iterations.\n",
      "2022-06-23 15:35:39,206 - base - recpack - INFO - Model improved. Storing better model.\n",
      "2022-06-23 15:35:39,244 - base - recpack - INFO - Evaluation at end of 2 took 1839.57 s.\n",
      "2022-06-23 15:41:04,033 - base - recpack - INFO - Processed epoch 3 in 324.78 s.Batch Training Loss = 29.8762\n",
      "2022-06-23 16:11:09,505 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.09760060687109678, which is worse than previous iterations.\n",
      "2022-06-23 16:11:09,506 - base - recpack - INFO - Evaluation at end of 3 took 1805.47 s.\n",
      "2022-06-23 16:16:33,221 - base - recpack - INFO - Processed epoch 4 in 323.71 s.Batch Training Loss = 28.8791\n",
      "2022-06-23 16:46:01,753 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.09933050429957442, which is better than previous iterations.\n",
      "2022-06-23 16:46:01,755 - base - recpack - INFO - Model improved. Storing better model.\n",
      "2022-06-23 16:46:01,792 - base - recpack - INFO - Evaluation at end of 4 took 1768.57 s.\n",
      "2022-06-23 16:51:24,714 - base - recpack - INFO - Processed epoch 5 in 322.92 s.Batch Training Loss = 28.1065\n",
      "2022-06-23 17:20:24,621 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.10359780023920352, which is better than previous iterations.\n",
      "2022-06-23 17:20:24,622 - base - recpack - INFO - Model improved. Storing better model.\n",
      "2022-06-23 17:20:24,660 - base - recpack - INFO - Evaluation at end of 5 took 1739.95 s.\n",
      "2022-06-23 17:25:47,549 - base - recpack - INFO - Processed epoch 6 in 322.88 s.Batch Training Loss = 27.6001\n",
      "2022-06-23 17:55:09,341 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.10393113937071141, which is better than previous iterations.\n",
      "2022-06-23 17:55:09,342 - base - recpack - INFO - Model improved. Storing better model.\n",
      "2022-06-23 17:55:09,380 - base - recpack - INFO - Evaluation at end of 6 took 1761.83 s.\n",
      "2022-06-23 18:00:32,645 - base - recpack - INFO - Processed epoch 7 in 323.26 s.Batch Training Loss = 27.1415\n",
      "2022-06-23 18:29:24,673 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.1027690961025639, which is worse than previous iterations.\n",
      "2022-06-23 18:29:24,674 - base - recpack - INFO - Evaluation at end of 7 took 1732.03 s.\n",
      "2022-06-23 18:34:47,231 - base - recpack - INFO - Processed epoch 8 in 322.55 s.Batch Training Loss = 26.8028\n",
      "2022-06-23 19:03:27,439 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.10629352624714494, which is better than previous iterations.\n",
      "2022-06-23 19:03:27,440 - base - recpack - INFO - Model improved. Storing better model.\n",
      "2022-06-23 19:03:27,479 - base - recpack - INFO - Evaluation at end of 8 took 1720.25 s.\n",
      "2022-06-23 19:08:48,994 - base - recpack - INFO - Processed epoch 9 in 321.51 s.Batch Training Loss = 26.5110\n",
      "2022-06-23 19:37:32,079 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.10920286993810616, which is better than previous iterations.\n",
      "2022-06-23 19:37:32,080 - base - recpack - INFO - Model improved. Storing better model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-06-23 19:37:32,117 - base - recpack - INFO - Evaluation at end of 9 took 1723.12 s.\n",
      "2022-06-23 19:37:32,134 - base - recpack - INFO - Fitting NeuMF complete - Took 2.1e+04s\n",
      "2022-06-23 20:06:31,710 - base - recpack - INFO - Fitting Popularity complete - Took 2.55s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/robinverachtert/dist-env/lib/python3.8/site-packages/scipy/sparse/_index.py:146: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_arrayXarray(i, j, x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-06-23 20:06:58,574 - base - recpack - INFO - Fitting ItemKNN complete - Took 17.5s\n",
      "2022-06-23 20:07:33,150 - base - recpack - INFO - Fitting ItemKNN complete - Took 15.6s\n",
      "2022-06-23 20:08:26,023 - base - recpack - INFO - Fitting ItemKNN complete - Took 15.6s\n"
     ]
    }
   ],
   "source": [
    "pipeline.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3a36b1d0",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ndcgk_10</th>\n",
       "      <th>coveragek_10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NeuMF(batch_size=128,dropout=0.01,exact_sampling=False,keep_last=False,learning_rate=0.01,max_epochs=10,max_iter_no_change=5,min_improvement=0.0,n_negatives_per_positive=3,predict_topK=20,predictive_factors=16,save_best_to_file=False,seed=3337940912,stop_early=False,stopping_criterion=&lt;recpack.algorithms.stopping_criterion.StoppingCriterion object at 0x7feb478a0340&gt;)</th>\n",
       "      <td>0.104866</td>\n",
       "      <td>0.122034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Popularity(K=20)</th>\n",
       "      <td>0.085165</td>\n",
       "      <td>0.000502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ItemKNN(K=200,normalize=False,normalize_X=False,normalize_sim=False,pop_discount=None,similarity=cosine)</th>\n",
       "      <td>0.162156</td>\n",
       "      <td>0.147565</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    ndcgk_10  coveragek_10\n",
       "NeuMF(batch_size=128,dropout=0.01,exact_samplin...  0.104866      0.122034\n",
       "Popularity(K=20)                                    0.085165      0.000502\n",
       "ItemKNN(K=200,normalize=False,normalize_X=False...  0.162156      0.147565"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.get_metrics_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bbf22a9c",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>identifier</th>\n",
       "      <th>params</th>\n",
       "      <th>NDCGK</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NeuMF(batch_size=128,dropout=0.01,exact_sampli...</td>\n",
       "      <td>{'predictive_factors': 8, 'batch_size': 128, '...</td>\n",
       "      <td>0.083669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NeuMF(batch_size=128,dropout=0.01,exact_sampli...</td>\n",
       "      <td>{'predictive_factors': 16, 'batch_size': 128, ...</td>\n",
       "      <td>0.087949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NeuMF(batch_size=128,dropout=0.01,exact_sampli...</td>\n",
       "      <td>{'predictive_factors': 32, 'batch_size': 128, ...</td>\n",
       "      <td>0.082559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ItemKNN(K=200,normalize=False,normalize_X=Fals...</td>\n",
       "      <td>{'similarity': 'conditional_probability'}</td>\n",
       "      <td>0.103835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ItemKNN(K=200,normalize=False,normalize_X=Fals...</td>\n",
       "      <td>{'similarity': 'cosine'}</td>\n",
       "      <td>0.138635</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          identifier  \\\n",
       "0  NeuMF(batch_size=128,dropout=0.01,exact_sampli...   \n",
       "1  NeuMF(batch_size=128,dropout=0.01,exact_sampli...   \n",
       "2  NeuMF(batch_size=128,dropout=0.01,exact_sampli...   \n",
       "3  ItemKNN(K=200,normalize=False,normalize_X=Fals...   \n",
       "4  ItemKNN(K=200,normalize=False,normalize_X=Fals...   \n",
       "\n",
       "                                              params     NDCGK  \n",
       "0  {'predictive_factors': 8, 'batch_size': 128, '...  0.083669  \n",
       "1  {'predictive_factors': 16, 'batch_size': 128, ...  0.087949  \n",
       "2  {'predictive_factors': 32, 'batch_size': 128, ...  0.082559  \n",
       "3          {'similarity': 'conditional_probability'}  0.103835  \n",
       "4                           {'similarity': 'cosine'}  0.138635  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.optimisation_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "720b3479",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ndcgk_10</th>\n",
       "      <th>coveragek_10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NeuMF</th>\n",
       "      <td>0.104866</td>\n",
       "      <td>0.122034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Popularity</th>\n",
       "      <td>0.085165</td>\n",
       "      <td>0.000502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ItemKNN</th>\n",
       "      <td>0.162156</td>\n",
       "      <td>0.147565</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            ndcgk_10  coveragek_10\n",
       "NeuMF       0.104866      0.122034\n",
       "Popularity  0.085165      0.000502\n",
       "ItemKNN     0.162156      0.147565"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.get_metrics_dataframe(short=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b2d607",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Check it out!\n",
    "\n",
    "__gitlab : TODO URL__\n",
    "\n",
    "__documentation: TODO URL__\n",
    "\n",
    "## Reach out to us\n",
    "\n",
    "lien.michiels@froomle.com \n",
    "\n",
    "robin.verachtert@froomle.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7e332e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
