{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85c37828",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pytest\n",
    "import torch\n",
    "from torch import nn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "471f8043",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable, List, Optional, Union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "353239bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code used from https://github.com/facebookresearch/multimodal/blob/5dec8a/torchmultimodal/modules/layers/mlp.py\n",
    "# Another option is to use torchvision.ops.MLP \n",
    "# which is nearly identical in implementation, but is in torchvision and not in base torch\n",
    "class MLP(nn.Module):\n",
    "    \"\"\"A multi-layer perceptron module.\n",
    "    This module is a sequence of linear layers plus activation functions.\n",
    "    The user can optionally add normalization and/or dropout to each of the layers.\n",
    "    \n",
    "    Code used from https://github.com/facebookresearch/multimodal/blob/5dec8a/torchmultimodal/modules/layers/mlp.py\n",
    "    Args:\n",
    "        in_dim (int): Input dimension.\n",
    "        out_dim (int): Output dimension.\n",
    "        hidden_dims (Optional[List[int]]): Output dimension for each hidden layer.\n",
    "        dropout (float): Probability for dropout layer.\n",
    "        activation (Callable[..., nn.Module]): Which activation\n",
    "            function to use. Supports module type or partial.\n",
    "        normalization (Optional[Callable[..., nn.Module]]): Which\n",
    "            normalization layer to use (None for no normalization).\n",
    "            Supports module type or partial.\n",
    "    Inputs:\n",
    "        x (Tensor): Tensor containing a batch of input sequences.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_dim: int,\n",
    "        out_dim: int,\n",
    "        hidden_dims: Optional[Union[int, List[int]]] = None,\n",
    "        dropout: float = 0.5,\n",
    "        activation: Callable[..., nn.Module] = nn.ReLU,\n",
    "        normalization: Optional[Callable[..., nn.Module]] = None,\n",
    "        **kwargs,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        layers = nn.ModuleList()\n",
    "\n",
    "        if hidden_dims is None:\n",
    "            hidden_dims = []\n",
    "\n",
    "        if isinstance(hidden_dims, int):\n",
    "            hidden_dims = [hidden_dims]\n",
    "\n",
    "        for hidden_dim in hidden_dims:\n",
    "            layers.append(nn.Linear(in_dim, hidden_dim))\n",
    "            if normalization:\n",
    "                layers.append(normalization(hidden_dim))\n",
    "            layers.append(activation())\n",
    "            layers.append(nn.Dropout(dropout))\n",
    "            in_dim = hidden_dim\n",
    "        layers.append(nn.Linear(in_dim, out_dim))\n",
    "        self.model = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.model(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "83fcd62d",
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_SIZE = 3\n",
    "N_USERS = 5\n",
    "N_ITEMS = 10\n",
    "a = MLP(2*EMBEDDING_SIZE, N_ITEMS, [6, 4, 2], dropout=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb2a3f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: add tests that check that the MLP works as expected.\n",
    "def test_MLP_shapes():\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "551d5c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NMFModule(nn.Module):\n",
    "    \"\"\"Model that encodes the Neural Matrix Factorization Network.\n",
    "\n",
    "    :param num_components: size of the embeddings\n",
    "    :type num_components: int\n",
    "    :param n_users: number of users in the network\n",
    "    :type n_users: int\n",
    "    :param n_items: number of items in the network\n",
    "    :type n_items: int\n",
    "    :param hidden_dims: dimensions of the MLP hidden layers.\n",
    "    :type hidden_dims: Union[int, List[int]]\n",
    "    :param dropout: Dropout chance between layers of the MLP\n",
    "    :type dropout: float\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, num_components: int, n_users: int, n_items: int, hidden_dims: Union[int, List[int]], dropout: float\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.user_embedding = nn.Embedding(n_users, num_components)\n",
    "        self.item_embedding = nn.Embedding(n_items, num_components)\n",
    "\n",
    "        # 2 x embedding size as input, since the user and item embedding are concatenated.\n",
    "        # Output is always 1, since we need a single score for u,i\n",
    "        self.mlp = MLP(2 * num_components, 1, hidden_dims, dropout=dropout)\n",
    "\n",
    "        # In order to interpret the output as a probability, the score should be between 0 and 1\n",
    "        # The papers mentions probit / logistic activation,\n",
    "        # but in pytorch sigmoid seems like the only one to give 0 to 1 values\n",
    "        self.final = nn.Sigmoid()\n",
    "\n",
    "        # weight initialization\n",
    "        self.user_embedding.weight.data.normal_(0, 1.0 / self.user_embedding.embedding_dim)\n",
    "        self.item_embedding.weight.data.normal_(0, 1.0 / self.item_embedding.embedding_dim)\n",
    "\n",
    "    def forward(self, users: torch.LongTensor, items: torch.LongTensor) -> torch.FloatTensor:\n",
    "        \"\"\"Predict scores for the user item pairs obtained when zipping together the two 1D tensors\n",
    "\n",
    "        :param users: 1D tensor with user ids\n",
    "        :type users: torch.LongTensor\n",
    "        :param items: 1D tensor with item ids\n",
    "        :type items: torch.LongTensor\n",
    "        :return: 1D tensor with on position i the prediction similarity between `users[i]` and `items[i]`\n",
    "        :rtype: torch.FloatTensor\n",
    "        \"\"\"\n",
    "\n",
    "        user_emb = self.user_embedding(users)\n",
    "        item_emb = self.item_embedding(items)\n",
    "\n",
    "        return self.final(self.mlp(torch.hstack([user_emb, item_emb])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b8bcb491",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_output_shapes_NMF(embedding_size, num_users, num_items, hidden_sizes):\n",
    "    \"\"\"Check that no mather the inner settings of the network, the output is always correct\"\"\"\n",
    "    mod = NMFModule(embedding_size, num_users, num_items, hidden_sizes)\n",
    "    \n",
    "    user_tensor = torch.LongTensor([1, 2])\n",
    "    item_tensor = torch.LongTensor([1, 2])\n",
    "    \n",
    "    res = mod(user_tensor, item_tensor) # predict scores for items given the users\n",
    "    \n",
    "    assert res.shape == (2, 1)\n",
    "\n",
    "    assert (res.detach().numpy() <= 1).all()\n",
    "    assert (res.detach().numpy() >= 0).all()\n",
    "\n",
    "\n",
    "test_output_shapes_NMF(5, 10, 10, [10])\n",
    "test_output_shapes_NMF(5, 10, 10, [10, 5, 3])\n",
    "test_output_shapes_NMF(5, 3, 10, [10])\n",
    "test_output_shapes_NMF(1, 3, 3, [10])\n",
    "\n",
    "\n",
    "def test_shape_input_check_NMF():\n",
    "    \"\"\"Check that no mather the inner settings of the network, the output is always correct\"\"\"\n",
    "    \n",
    "    mod = NMFModule(3, 3, 3, [10])\n",
    "    \n",
    "    user_tensor = torch.LongTensor([[1, 2]])\n",
    "    item_tensor = torch.LongTensor([[1, 2]])\n",
    "    \n",
    "    with pytest.raises(ValueError):\n",
    "        mod(user_tensor, item_tensor)\n",
    "        \n",
    "    user_tensor = torch.LongTensor([1, 2])\n",
    "    item_tensor = torch.LongTensor([1, 2, 0])\n",
    "    \n",
    "    with pytest.raises(ValueError):\n",
    "        mod(user_tensor, item_tensor)\n",
    "\n",
    "    user_tensor = torch.LongTensor([[1, 2]])\n",
    "    item_tensor = torch.LongTensor([1, 2])\n",
    "\n",
    "    with pytest.raises(ValueError):\n",
    "        mod(user_tensor, item_tensor)\n",
    "\n",
    "\n",
    "test_shape_input_check_NMF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3c07d570",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Union, Optional\n",
    "\n",
    "import pandas as pd\n",
    "from recpack.algorithms.base import TorchMLAlgorithm\n",
    "from recpack.algorithms.samplers import PositiveNegativeSampler\n",
    "from recpack.algorithms.util import get_users\n",
    "from recpack.data.matrix import InteractionMatrix\n",
    "from scipy.sparse import csr_matrix, lil_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b93dbaa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuMF(TorchMLAlgorithm):\n",
    "    \"\"\"Implementation of Neural Matrix Factoration.\n",
    "\n",
    "    Neural Matrix Factorization based on MLP architecture\n",
    "    as presented in Figure 2 in He, Xiangnan, et al. \"Neural collaborative filtering.\"\n",
    "    Proceedings of the 26th international conference on world wide web. 2017.\n",
    "\n",
    "    Represents the users and items using an embedding, and models similarity using a neural network.\n",
    "    An MLP is used with as input the concatenated embeddings of users and items.\n",
    "\n",
    "    As in the paper, the sum of square error is used as the loss function.\n",
    "    Positive items should get a prediction close to 1, while sampled negatives should get a value close to 0.\n",
    "    The MLP has 3 layers, whose dimensions are based on the `num_components` parameter.\n",
    "    Bottom layer has `num_components * 2`, middle layer `num_components`\n",
    "    and the top layer has `num_components / 2` dimensions.\n",
    "\n",
    "    :param num_components: Size of the embeddings, needs to be an even number.\n",
    "    :type num_components: int\n",
    "    :param batch_size: How many samples to use in each update step.\n",
    "        Higher batch sizes make each epoch more efficient,\n",
    "        but increases the amount of epochs needed to converge to the optimum,\n",
    "        by reducing the amount of updates per epoch.\n",
    "        Defaults to 512.\n",
    "    :type batch_size: Optional[int]\n",
    "    :param max_epochs: The max number of epochs to train.\n",
    "        If the stopping criterion uses early stopping, less epochs could be used.\n",
    "        Defaults to 10.\n",
    "    :type max_epochs: Optional[int]\n",
    "    :param learning_rate: How much to update the weights at each update. Defaults to 0.01\n",
    "    :type learning_rate: Optional[float]\n",
    "    :param stopping_criterion: Name of the stopping criterion to use for training.\n",
    "        For available values,\n",
    "        check :meth:`recpack.algorithms.stopping_criterion.StoppingCriterion.FUNCTIONS`\n",
    "        Defaults to 'ndcg'\n",
    "    :type stopping_criterion: Optional[str]\n",
    "    :param stop_early: If True, early stopping is enabled,\n",
    "        and after ``max_iter_no_change`` iterations where improvement of loss function\n",
    "        is below ``min_improvement`` the optimisation is stopped,\n",
    "        even if max_epochs is not reached.\n",
    "        Defaults to False\n",
    "    :type stop_early: bool, optional\n",
    "    :param max_iter_no_change: If early stopping is enabled,\n",
    "        stop after this amount of iterations without change.\n",
    "        Defaults to 5\n",
    "    :type max_iter_no_change: int, optional\n",
    "    :param min_improvement: If early stopping is enabled, no change is detected,\n",
    "        if the improvement is below this value.\n",
    "        Defaults to 0.01\n",
    "    :type min_improvement: float, optional\n",
    "    :param seed: Seed to the randomizers, useful for reproducible results,\n",
    "        defaults to None\n",
    "    :type seed: int, optional\n",
    "    :param save_best_to_file: If true, the best model will be saved after training,\n",
    "        defaults to False\n",
    "    :type save_best_to_file: bool, optional\n",
    "    :param keep_last: Retain last model, rather than best\n",
    "        (according to stopping criterion value on validation data), defaults to False\n",
    "    :type keep_last: bool, optional\n",
    "    :param predict_topK: The topK recommendations to keep per row in the matrix.\n",
    "        Use when the user x item output matrix would become too large for RAM.\n",
    "        Defaults to None, which results in no filtering.\n",
    "    :type predict_topK: int, optional\n",
    "    :param U: Amount of negatives to sample for each positive example, defaults to 1\n",
    "    :type U: int, optional\n",
    "    :param dropout: Dropout parameter used in MLP, defaults to 0.0\n",
    "    :type dropout: float, optional\n",
    "    :param exact_sampling: Enable or disable exact checks while sampling. \n",
    "        With exact sampling the sampled negatives are guaranteed to not have been visited by the user. \n",
    "        Non exact sampling assumes that the space for item selection is large enough, \n",
    "        such that most items are likely not seen before.\n",
    "        Defaults to False,\n",
    "    :type exact_sampling: bool, optional\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_components: int,\n",
    "        batch_size: Optional[int] = 512,\n",
    "        max_epochs: Optional[int] = 10,\n",
    "        learning_rate: Optional[float] = 0.01,\n",
    "        stopping_criterion: Optional[str] = \"ndcg\",\n",
    "        stop_early: Optional[bool] = False,\n",
    "        max_iter_no_change: Optional[int] = 5,\n",
    "        min_improvement: Optional[float] = 0.0,\n",
    "        seed: Optional[int] = None,\n",
    "        save_best_to_file: Optional[bool] = False,\n",
    "        keep_last: Optional[bool] = False,\n",
    "        predict_topK: Optional[int] = None,\n",
    "        U: Optional[int] = 1,\n",
    "        dropout: Optional[float] = 0.0,\n",
    "        exact_sampling: Optional[bool] = False,\n",
    "    ):\n",
    "        super().__init__(\n",
    "            batch_size,\n",
    "            max_epochs,\n",
    "            learning_rate,\n",
    "            stopping_criterion,\n",
    "            stop_early,\n",
    "            max_iter_no_change,\n",
    "            min_improvement,\n",
    "            seed,\n",
    "            save_best_to_file,\n",
    "            keep_last,\n",
    "            predict_topK,\n",
    "        )\n",
    "\n",
    "        self.num_components = num_components\n",
    "        if self.num_components % 2 != 0:\n",
    "            raise ValueError(\"Please use an even number of components for training the NeuMF model.\")\n",
    "\n",
    "        self.hidden_dims = [self.num_components * 2, self.num_components, self.num_components // 2]\n",
    "        self.U = U\n",
    "        self.dropout = dropout\n",
    "        self.exact_sampling = exact_sampling\n",
    "\n",
    "        self.sampler = PositiveNegativeSampler(\n",
    "            U=self.U, replace=False, exact=exact_sampling, batch_size=self.batch_size\n",
    "        )\n",
    "\n",
    "    def _init_model(self, X: csr_matrix):\n",
    "        num_users, num_items = X.shape\n",
    "        self.model_ = NMFModule(self.num_components, num_users, num_items, self.hidden_dims, self.dropout).to(\n",
    "            self.device\n",
    "        )\n",
    "        self.optimizer = torch.optim.Adam(self.model_.parameters(), lr=self.learning_rate)\n",
    "\n",
    "    def _compute_loss(\n",
    "        self, positive_scores: torch.FloatTensor, negative_scores: torch.FloatTensor\n",
    "    ) -> torch.FloatTensor:\n",
    "        \"\"\"Compute the Square Error loss given recommendations for positive items, and sampled negatives.\"\"\"\n",
    "        mse = nn.MSELoss(reduction=\"sum\")\n",
    "        return mse(positive_scores, torch.ones_like(positive_scores, dtype=torch.float)) + mse(\n",
    "            negative_scores, torch.zeros_like(negative_scores, dtype=torch.float)\n",
    "        )\n",
    "\n",
    "    def _train_epoch(self, X: csr_matrix) -> List[int]:\n",
    "        losses = []\n",
    "        for users, positives, negatives in self.sampler.sample(X):\n",
    "\n",
    "            self.optimizer.zero_grad()\n",
    "\n",
    "            # Predict for the positives\n",
    "            positive_scores = self.model_.forward(users, positives)\n",
    "            # Predict for the negatives\n",
    "            negative_scores = self.model_.forward(*self._construct_negative_prediction_input(users, negatives))\n",
    "\n",
    "            loss = self._compute_loss(positive_scores, negative_scores)\n",
    "\n",
    "            # Backwards propagation of the loss\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "\n",
    "            losses.append(loss.item())\n",
    "\n",
    "        return losses\n",
    "\n",
    "    def _construct_negative_prediction_input(self, users, negatives):\n",
    "        \"\"\"Since negatives has shape batch x U, and users is a 1d vector,\n",
    "        these need to be turned into two 1d vectors of size batch*U\n",
    "\n",
    "        First the users as a row are stacked U times and transposed,\n",
    "        so that this is also a batch x U tensor\n",
    "\n",
    "        then both are reshaped to remove the 2nd dimension, resulting in a single long 1d vector\n",
    "        \"\"\"\n",
    "        return users.repeat(self.U, 1).T.reshape(-1), negatives.reshape(-1)\n",
    "\n",
    "    def _batch_predict(self, X: csr_matrix, users: List[int]) -> csr_matrix:\n",
    "        X_pred = lil_matrix(X.shape)\n",
    "        if users is None:\n",
    "            users = get_users(X)\n",
    "\n",
    "        _, n_items = X.shape\n",
    "        n_users = len(users)\n",
    "\n",
    "        # Turn the np arrays and lists to torch tensors\n",
    "        user_tensor = torch.LongTensor(users).repeat(n_items, 1).T.reshape(-1).to(self.device)\n",
    "        item_tensor = torch.arange(n_items).repeat(n_users).to(self.device)\n",
    "\n",
    "        X_pred[users] = self.model_(user_tensor, item_tensor).detach().cpu().numpy().reshape(n_users, n_items)\n",
    "        return X_pred.tocsr()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9ca8f574",
   "metadata": {},
   "outputs": [],
   "source": [
    "TIMESTAMP_IX = 'ts'\n",
    "ITEM_IX = 'iid'\n",
    "USER_IX = 'uid'\n",
    "\n",
    "data = {\n",
    "    TIMESTAMP_IX: [3, 2, 1, 4, 0, 1, 2, 4, 0, 1, 2],\n",
    "    ITEM_IX: [0, 1, 2, 3, 0, 1, 2, 4, 0, 1, 2],\n",
    "    USER_IX: [0, 0, 1, 1, 2, 2, 3, 3, 4, 4, 5],\n",
    "}\n",
    "df = pd.DataFrame.from_dict(data)\n",
    "\n",
    "mat = InteractionMatrix(df, ITEM_IX, USER_IX, timestamp_ix=TIMESTAMP_IX)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1cf3329d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from recpack.tests.test_algorithms.util import assert_changed, assert_same\n",
    "\n",
    "def test_training_epoch(X):\n",
    "    a = NeuMF(\n",
    "        num_components=4, \n",
    "        U=2,\n",
    "        exact_sampling=True\n",
    "    )\n",
    "    device = a.device\n",
    "    a._init_model(X)\n",
    "\n",
    "    # Each training epoch should update the parameters\n",
    "    params = [np for np in a.model_.named_parameters() if np[1].requires_grad]\n",
    "    params_before = [(name, p.clone()) for (name, p) in params]\n",
    "    for _ in range(5):\n",
    "        a._train_epoch(X)\n",
    "    params = [np for np in a.model_.named_parameters() if np[1].requires_grad]\n",
    "    assert_changed(params_before, params, device)\n",
    "\n",
    "test_training_epoch(mat.binary_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "814b0473",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-06-14 10:26:01,023 - base - recpack - INFO - Processed epoch 0 in 0.02 s.Batch Training Loss = 8.0996\n",
      "2022-06-14 10:26:01,032 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.6654823631312136, which is better than previous iterations.\n",
      "2022-06-14 10:26:01,033 - base - recpack - INFO - Model improved. Storing better model.\n",
      "2022-06-14 10:26:01,038 - base - recpack - INFO - Evaluation at end of 0 took 0.01 s.\n",
      "2022-06-14 10:26:01,058 - base - recpack - INFO - Processed epoch 1 in 0.02 s.Batch Training Loss = 8.0385\n",
      "2022-06-14 10:26:01,066 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.6725666087662366, which is better than previous iterations.\n",
      "2022-06-14 10:26:01,067 - base - recpack - INFO - Model improved. Storing better model.\n",
      "2022-06-14 10:26:01,070 - base - recpack - INFO - Evaluation at end of 1 took 0.01 s.\n",
      "2022-06-14 10:26:01,086 - base - recpack - INFO - Processed epoch 2 in 0.02 s.Batch Training Loss = 7.9893\n",
      "2022-06-14 10:26:01,095 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.6788622316065157, which is better than previous iterations.\n",
      "2022-06-14 10:26:01,096 - base - recpack - INFO - Model improved. Storing better model.\n",
      "2022-06-14 10:26:01,105 - base - recpack - INFO - Evaluation at end of 2 took 0.02 s.\n",
      "2022-06-14 10:26:01,131 - base - recpack - INFO - Processed epoch 3 in 0.02 s.Batch Training Loss = 7.9437\n",
      "2022-06-14 10:26:01,140 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.7236622081633582, which is better than previous iterations.\n",
      "2022-06-14 10:26:01,142 - base - recpack - INFO - Model improved. Storing better model.\n",
      "2022-06-14 10:26:01,152 - base - recpack - INFO - Evaluation at end of 3 took 0.02 s.\n",
      "2022-06-14 10:26:01,170 - base - recpack - INFO - Processed epoch 4 in 0.02 s.Batch Training Loss = 7.8912\n",
      "2022-06-14 10:26:01,178 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.7704263495028087, which is better than previous iterations.\n",
      "2022-06-14 10:26:01,180 - base - recpack - INFO - Model improved. Storing better model.\n",
      "2022-06-14 10:26:01,185 - base - recpack - INFO - Evaluation at end of 4 took 0.01 s.\n",
      "2022-06-14 10:26:01,201 - base - recpack - INFO - Processed epoch 5 in 0.01 s.Batch Training Loss = 7.8486\n",
      "2022-06-14 10:26:01,208 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.7704263495028087, which is worse than previous iterations.\n",
      "2022-06-14 10:26:01,209 - base - recpack - INFO - Evaluation at end of 5 took 0.01 s.\n",
      "2022-06-14 10:26:01,236 - base - recpack - INFO - Processed epoch 6 in 0.03 s.Batch Training Loss = 7.8084\n",
      "2022-06-14 10:26:01,248 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.7704263495028087, which is worse than previous iterations.\n",
      "2022-06-14 10:26:01,249 - base - recpack - INFO - Evaluation at end of 6 took 0.01 s.\n",
      "2022-06-14 10:26:01,273 - base - recpack - INFO - Processed epoch 7 in 0.02 s.Batch Training Loss = 7.7712\n",
      "2022-06-14 10:26:01,289 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.7704263495028087, which is worse than previous iterations.\n",
      "2022-06-14 10:26:01,290 - base - recpack - INFO - Evaluation at end of 7 took 0.02 s.\n",
      "2022-06-14 10:26:01,314 - base - recpack - INFO - Processed epoch 8 in 0.02 s.Batch Training Loss = 7.7373\n",
      "2022-06-14 10:26:01,323 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.8319380572408991, which is better than previous iterations.\n",
      "2022-06-14 10:26:01,324 - base - recpack - INFO - Model improved. Storing better model.\n",
      "2022-06-14 10:26:01,328 - base - recpack - INFO - Evaluation at end of 8 took 0.01 s.\n",
      "2022-06-14 10:26:01,352 - base - recpack - INFO - Processed epoch 9 in 0.02 s.Batch Training Loss = 7.7028\n",
      "2022-06-14 10:26:01,358 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.9349178788298861, which is better than previous iterations.\n",
      "2022-06-14 10:26:01,358 - base - recpack - INFO - Model improved. Storing better model.\n",
      "2022-06-14 10:26:01,364 - base - recpack - INFO - Evaluation at end of 9 took 0.01 s.\n",
      "2022-06-14 10:26:01,369 - base - recpack - INFO - Fitting NeuMF complete - Took 0.375s\n",
      "2022-06-14 10:26:01,396 - base - recpack - INFO - Processed epoch 0 in 0.01 s.Batch Training Loss = 8.9428\n",
      "2022-06-14 10:26:01,403 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.7819889967717142, which is better than previous iterations.\n",
      "2022-06-14 10:26:01,404 - base - recpack - INFO - Model improved. Storing better model.\n",
      "2022-06-14 10:26:01,411 - base - recpack - INFO - Evaluation at end of 0 took 0.01 s.\n",
      "2022-06-14 10:26:01,430 - base - recpack - INFO - Processed epoch 1 in 0.02 s.Batch Training Loss = 8.8284\n",
      "2022-06-14 10:26:01,443 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.7819889967717142, which is worse than previous iterations.\n",
      "2022-06-14 10:26:01,444 - base - recpack - INFO - Evaluation at end of 1 took 0.01 s.\n",
      "2022-06-14 10:26:01,470 - base - recpack - INFO - Processed epoch 2 in 0.02 s.Batch Training Loss = 8.7157\n",
      "2022-06-14 10:26:01,482 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.8087487337223183, which is better than previous iterations.\n",
      "2022-06-14 10:26:01,483 - base - recpack - INFO - Model improved. Storing better model.\n",
      "2022-06-14 10:26:01,488 - base - recpack - INFO - Evaluation at end of 2 took 0.02 s.\n",
      "2022-06-14 10:26:01,509 - base - recpack - INFO - Processed epoch 3 in 0.02 s.Batch Training Loss = 8.6111\n",
      "2022-06-14 10:26:01,519 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.8176502005637379, which is better than previous iterations.\n",
      "2022-06-14 10:26:01,520 - base - recpack - INFO - Model improved. Storing better model.\n",
      "2022-06-14 10:26:01,524 - base - recpack - INFO - Evaluation at end of 3 took 0.01 s.\n",
      "2022-06-14 10:26:01,541 - base - recpack - INFO - Processed epoch 4 in 0.02 s.Batch Training Loss = 8.4970\n",
      "2022-06-14 10:26:01,552 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.8419860630102554, which is better than previous iterations.\n",
      "2022-06-14 10:26:01,553 - base - recpack - INFO - Model improved. Storing better model.\n",
      "2022-06-14 10:26:01,558 - base - recpack - INFO - Evaluation at end of 4 took 0.02 s.\n",
      "2022-06-14 10:26:01,574 - base - recpack - INFO - Processed epoch 5 in 0.02 s.Batch Training Loss = 8.3948\n",
      "2022-06-14 10:26:01,583 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.8419860630102554, which is worse than previous iterations.\n",
      "2022-06-14 10:26:01,584 - base - recpack - INFO - Evaluation at end of 5 took 0.01 s.\n",
      "2022-06-14 10:26:01,599 - base - recpack - INFO - Processed epoch 6 in 0.01 s.Batch Training Loss = 8.2874\n",
      "2022-06-14 10:26:01,610 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.8286061945349533, which is worse than previous iterations.\n",
      "2022-06-14 10:26:01,614 - base - recpack - INFO - Evaluation at end of 6 took 0.01 s.\n",
      "2022-06-14 10:26:01,642 - base - recpack - INFO - Processed epoch 7 in 0.03 s.Batch Training Loss = 8.2014\n",
      "2022-06-14 10:26:01,654 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.8286061945349533, which is worse than previous iterations.\n",
      "2022-06-14 10:26:01,655 - base - recpack - INFO - Evaluation at end of 7 took 0.01 s.\n",
      "2022-06-14 10:26:01,681 - base - recpack - INFO - Processed epoch 8 in 0.03 s.Batch Training Loss = 8.0962\n",
      "2022-06-14 10:26:01,687 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.8286061945349533, which is worse than previous iterations.\n",
      "2022-06-14 10:26:01,688 - base - recpack - INFO - Evaluation at end of 8 took 0.01 s.\n",
      "2022-06-14 10:26:01,709 - base - recpack - INFO - Processed epoch 9 in 0.02 s.Batch Training Loss = 8.0085\n",
      "2022-06-14 10:26:01,718 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.8286061945349533, which is worse than previous iterations.\n",
      "2022-06-14 10:26:01,719 - base - recpack - INFO - Evaluation at end of 9 took 0.01 s.\n",
      "2022-06-14 10:26:01,724 - base - recpack - INFO - Fitting NeuMF complete - Took 0.348s\n",
      "2022-06-14 10:26:01,757 - base - recpack - INFO - Processed epoch 0 in 0.02 s.Batch Training Loss = 7.3447\n",
      "2022-06-14 10:26:01,771 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.6028241164651866, which is better than previous iterations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-06-14 10:26:01,772 - base - recpack - INFO - Model improved. Storing better model.\n",
      "2022-06-14 10:26:01,781 - base - recpack - INFO - Evaluation at end of 0 took 0.02 s.\n",
      "2022-06-14 10:26:01,828 - base - recpack - INFO - Processed epoch 1 in 0.05 s.Batch Training Loss = 7.3421\n",
      "2022-06-14 10:26:01,839 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.6028241164651866, which is worse than previous iterations.\n",
      "2022-06-14 10:26:01,842 - base - recpack - INFO - Evaluation at end of 1 took 0.01 s.\n",
      "2022-06-14 10:26:01,859 - base - recpack - INFO - Processed epoch 2 in 0.02 s.Batch Training Loss = 7.3398\n",
      "2022-06-14 10:26:01,867 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.6028241164651866, which is worse than previous iterations.\n",
      "2022-06-14 10:26:01,868 - base - recpack - INFO - Evaluation at end of 2 took 0.01 s.\n",
      "2022-06-14 10:26:01,879 - base - recpack - INFO - Processed epoch 3 in 0.01 s.Batch Training Loss = 7.3379\n",
      "2022-06-14 10:26:01,886 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.6028241164651866, which is worse than previous iterations.\n",
      "2022-06-14 10:26:01,887 - base - recpack - INFO - Evaluation at end of 3 took 0.01 s.\n",
      "2022-06-14 10:26:01,907 - base - recpack - INFO - Processed epoch 4 in 0.02 s.Batch Training Loss = 7.3364\n",
      "2022-06-14 10:26:01,918 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.6028241164651866, which is worse than previous iterations.\n",
      "2022-06-14 10:26:01,919 - base - recpack - INFO - Evaluation at end of 4 took 0.01 s.\n",
      "2022-06-14 10:26:01,936 - base - recpack - INFO - Processed epoch 5 in 0.02 s.Batch Training Loss = 7.3352\n",
      "2022-06-14 10:26:01,942 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.6028241164651866, which is worse than previous iterations.\n",
      "2022-06-14 10:26:01,944 - base - recpack - INFO - Evaluation at end of 5 took 0.01 s.\n",
      "2022-06-14 10:26:01,968 - base - recpack - INFO - Processed epoch 6 in 0.02 s.Batch Training Loss = 7.3343\n",
      "2022-06-14 10:26:01,981 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.6028241164651866, which is worse than previous iterations.\n",
      "2022-06-14 10:26:01,981 - base - recpack - INFO - Evaluation at end of 6 took 0.01 s.\n",
      "2022-06-14 10:26:02,004 - base - recpack - INFO - Processed epoch 7 in 0.02 s.Batch Training Loss = 7.3337\n",
      "2022-06-14 10:26:02,014 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.6028241164651866, which is worse than previous iterations.\n",
      "2022-06-14 10:26:02,016 - base - recpack - INFO - Evaluation at end of 7 took 0.01 s.\n",
      "2022-06-14 10:26:02,038 - base - recpack - INFO - Processed epoch 8 in 0.02 s.Batch Training Loss = 7.3334\n",
      "2022-06-14 10:26:02,047 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.6028241164651866, which is worse than previous iterations.\n",
      "2022-06-14 10:26:02,048 - base - recpack - INFO - Evaluation at end of 8 took 0.01 s.\n",
      "2022-06-14 10:26:02,066 - base - recpack - INFO - Processed epoch 9 in 0.02 s.Batch Training Loss = 7.3333\n",
      "2022-06-14 10:26:02,073 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.6028241164651866, which is worse than previous iterations.\n",
      "2022-06-14 10:26:02,074 - base - recpack - INFO - Evaluation at end of 9 took 0.01 s.\n",
      "2022-06-14 10:26:02,078 - base - recpack - INFO - Fitting NeuMF complete - Took 0.346s\n"
     ]
    }
   ],
   "source": [
    "def test_batch_predict(mat, users):\n",
    "    a = NeuMF(\n",
    "        num_components=4, \n",
    "        U=2,\n",
    "        exact_sampling=True\n",
    "    )\n",
    "    device = a.device\n",
    "    a.fit(mat, (mat, mat))\n",
    "    params = [np for np in a.model_.named_parameters() if np[1].requires_grad]\n",
    "    params_before = [(name, p.clone()) for (name, p) in params]\n",
    "\n",
    "    pred = a._batch_predict(mat.users_in(users), users=users)\n",
    "\n",
    "    assert pred.shape == mat.shape\n",
    "    np.testing.assert_array_equal(pred.sum(axis=1).nonzero()[0], users)\n",
    "\n",
    "    params = [np for np in a.model_.named_parameters() if np[1].requires_grad]\n",
    "    assert_same(params_before, params, device)\n",
    "\n",
    "    \n",
    "\n",
    "test_batch_predict(mat, [0, 1])\n",
    "test_batch_predict(mat, [0])\n",
    "test_batch_predict(mat, [0, 1, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ed4d2e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_negative_input_construction(users, negatives, U):\n",
    "    \n",
    "    a = NeuMF(\n",
    "        num_components=8, \n",
    "        U=U\n",
    "    )\n",
    "    \n",
    "    num_users = users.shape[0]\n",
    "    users_input, negatives_input = a._construct_negative_prediction_input(users, negatives)\n",
    "    assert users_input.shape == negatives_input.shape\n",
    "    assert len(users_input.shape) == 1 # 1d vectors\n",
    "    \n",
    "    # Check that both are in the right order (each user is repeated U times before the next user is present)\n",
    "    for ix in range(users_input.shape[0]):\n",
    "        assert users_input[ix] == users[ix // U]\n",
    "        assert negatives_input[ix] == negatives[ix // U, ix % U]\n",
    "\n",
    "test_negative_input_construction(torch.LongTensor([4, 5, 6]), torch.LongTensor([[1, 2], [1, 2], [1, 2]]), U=2)\n",
    "test_negative_input_construction(torch.LongTensor([4, 5, 6]), torch.LongTensor([[1], [1], [1]]), U=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1a7cb45e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7f31c898",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-06-14 10:26:24,089 - base - recpack - INFO - Processed epoch 0 in 0.04 s.Batch Training Loss = 0.4999\n",
      "2022-06-14 10:26:24,104 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.8901179022730437, which is better than previous iterations.\n",
      "2022-06-14 10:26:24,105 - base - recpack - INFO - Model improved. Storing better model.\n",
      "2022-06-14 10:26:24,111 - base - recpack - INFO - Evaluation at end of 0 took 0.02 s.\n",
      "2022-06-14 10:26:24,161 - base - recpack - INFO - Processed epoch 1 in 0.05 s.Batch Training Loss = 0.4982\n",
      "2022-06-14 10:26:24,177 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.7635908410322833, which is worse than previous iterations.\n",
      "2022-06-14 10:26:24,177 - base - recpack - INFO - Evaluation at end of 1 took 0.02 s.\n",
      "2022-06-14 10:26:24,217 - base - recpack - INFO - Processed epoch 2 in 0.04 s.Batch Training Loss = 0.4791\n",
      "2022-06-14 10:26:24,235 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.9545933701454672, which is better than previous iterations.\n",
      "2022-06-14 10:26:24,236 - base - recpack - INFO - Model improved. Storing better model.\n",
      "2022-06-14 10:26:24,240 - base - recpack - INFO - Evaluation at end of 2 took 0.02 s.\n",
      "2022-06-14 10:26:24,292 - base - recpack - INFO - Processed epoch 3 in 0.05 s.Batch Training Loss = 0.4573\n",
      "2022-06-14 10:26:24,312 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.9545933701454672, which is worse than previous iterations.\n",
      "2022-06-14 10:26:24,312 - base - recpack - INFO - Evaluation at end of 3 took 0.02 s.\n",
      "2022-06-14 10:26:24,355 - base - recpack - INFO - Processed epoch 4 in 0.04 s.Batch Training Loss = 0.3902\n",
      "2022-06-14 10:26:24,375 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.9866201315246979, which is better than previous iterations.\n",
      "2022-06-14 10:26:24,376 - base - recpack - INFO - Model improved. Storing better model.\n",
      "2022-06-14 10:26:24,380 - base - recpack - INFO - Evaluation at end of 4 took 0.02 s.\n",
      "2022-06-14 10:26:24,429 - base - recpack - INFO - Processed epoch 5 in 0.05 s.Batch Training Loss = 0.3453\n",
      "2022-06-14 10:26:24,449 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.9866201315246979, which is worse than previous iterations.\n",
      "2022-06-14 10:26:24,450 - base - recpack - INFO - Evaluation at end of 5 took 0.02 s.\n",
      "2022-06-14 10:26:24,489 - base - recpack - INFO - Processed epoch 6 in 0.04 s.Batch Training Loss = 0.3077\n",
      "2022-06-14 10:26:24,502 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.9999999999999999, which is better than previous iterations.\n",
      "2022-06-14 10:26:24,503 - base - recpack - INFO - Model improved. Storing better model.\n",
      "2022-06-14 10:26:24,508 - base - recpack - INFO - Evaluation at end of 6 took 0.02 s.\n",
      "2022-06-14 10:26:24,554 - base - recpack - INFO - Processed epoch 7 in 0.04 s.Batch Training Loss = 0.2289\n",
      "2022-06-14 10:26:24,576 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.838811330318941, which is worse than previous iterations.\n",
      "2022-06-14 10:26:24,577 - base - recpack - INFO - Evaluation at end of 7 took 0.02 s.\n",
      "2022-06-14 10:26:24,630 - base - recpack - INFO - Processed epoch 8 in 0.05 s.Batch Training Loss = 0.3065\n",
      "2022-06-14 10:26:24,645 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.8333333333333333, which is worse than previous iterations.\n",
      "2022-06-14 10:26:24,645 - base - recpack - INFO - Evaluation at end of 8 took 0.01 s.\n",
      "2022-06-14 10:26:24,689 - base - recpack - INFO - Processed epoch 9 in 0.04 s.Batch Training Loss = 0.3797\n",
      "2022-06-14 10:26:24,707 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.8333333333333333, which is worse than previous iterations.\n",
      "2022-06-14 10:26:24,708 - base - recpack - INFO - Evaluation at end of 9 took 0.02 s.\n",
      "2022-06-14 10:26:24,760 - base - recpack - INFO - Processed epoch 10 in 0.05 s.Batch Training Loss = 0.2815\n",
      "2022-06-14 10:26:24,774 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.8333333333333333, which is worse than previous iterations.\n",
      "2022-06-14 10:26:24,774 - base - recpack - INFO - Evaluation at end of 10 took 0.01 s.\n",
      "2022-06-14 10:26:24,817 - base - recpack - INFO - Processed epoch 11 in 0.04 s.Batch Training Loss = 0.2847\n",
      "2022-06-14 10:26:24,834 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.8333333333333333, which is worse than previous iterations.\n",
      "2022-06-14 10:26:24,835 - base - recpack - INFO - Evaluation at end of 11 took 0.02 s.\n",
      "2022-06-14 10:26:24,886 - base - recpack - INFO - Processed epoch 12 in 0.05 s.Batch Training Loss = 0.0389\n",
      "2022-06-14 10:26:24,902 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.8333333333333333, which is worse than previous iterations.\n",
      "2022-06-14 10:26:24,903 - base - recpack - INFO - Evaluation at end of 12 took 0.02 s.\n",
      "2022-06-14 10:26:24,944 - base - recpack - INFO - Processed epoch 13 in 0.04 s.Batch Training Loss = 0.1517\n",
      "2022-06-14 10:26:24,961 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.8467132018086353, which is worse than previous iterations.\n",
      "2022-06-14 10:26:24,962 - base - recpack - INFO - Evaluation at end of 13 took 0.02 s.\n",
      "2022-06-14 10:26:25,013 - base - recpack - INFO - Processed epoch 14 in 0.05 s.Batch Training Loss = 0.3974\n",
      "2022-06-14 10:26:25,032 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.8333333333333333, which is worse than previous iterations.\n",
      "2022-06-14 10:26:25,032 - base - recpack - INFO - Evaluation at end of 14 took 0.02 s.\n",
      "2022-06-14 10:26:25,078 - base - recpack - INFO - Processed epoch 15 in 0.04 s.Batch Training Loss = 0.1455\n",
      "2022-06-14 10:26:25,096 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.8467132018086353, which is worse than previous iterations.\n",
      "2022-06-14 10:26:25,097 - base - recpack - INFO - Evaluation at end of 15 took 0.02 s.\n",
      "2022-06-14 10:26:25,149 - base - recpack - INFO - Processed epoch 16 in 0.05 s.Batch Training Loss = 0.3657\n",
      "2022-06-14 10:26:25,169 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.8467132018086353, which is worse than previous iterations.\n",
      "2022-06-14 10:26:25,171 - base - recpack - INFO - Evaluation at end of 16 took 0.02 s.\n",
      "2022-06-14 10:26:25,216 - base - recpack - INFO - Processed epoch 17 in 0.04 s.Batch Training Loss = 0.1408\n",
      "2022-06-14 10:26:25,230 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.8333333333333333, which is worse than previous iterations.\n",
      "2022-06-14 10:26:25,231 - base - recpack - INFO - Evaluation at end of 17 took 0.01 s.\n",
      "2022-06-14 10:26:25,277 - base - recpack - INFO - Processed epoch 18 in 0.05 s.Batch Training Loss = 0.1619\n",
      "2022-06-14 10:26:25,305 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.8333333333333333, which is worse than previous iterations.\n",
      "2022-06-14 10:26:25,306 - base - recpack - INFO - Evaluation at end of 18 took 0.03 s.\n",
      "2022-06-14 10:26:25,352 - base - recpack - INFO - Processed epoch 19 in 0.04 s.Batch Training Loss = 0.2926\n",
      "2022-06-14 10:26:25,369 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.8467132018086353, which is worse than previous iterations.\n",
      "2022-06-14 10:26:25,370 - base - recpack - INFO - Evaluation at end of 19 took 0.02 s.\n",
      "2022-06-14 10:26:25,376 - base - recpack - INFO - Fitting NeuMF complete - Took 1.33s\n"
     ]
    }
   ],
   "source": [
    "def test_overfit(mat):\n",
    "    m = NeuMF(\n",
    "        num_components=10,\n",
    "        batch_size=1,\n",
    "        max_epochs=20,\n",
    "        learning_rate=0.02,\n",
    "        stopping_criterion=\"ndcg\",\n",
    "        U=1,\n",
    "    )\n",
    "\n",
    "    # set sampler to exact sampling\n",
    "    m.sampler.exact = True\n",
    "    m.fit(mat, (mat, mat))\n",
    "    bin_mat = mat.binary_values\n",
    "    pred = m.predict(mat.binary_values).toarray()\n",
    "    for user in mat.active_users:\n",
    "        # The model should have overfitted, so that the visited items have the highest similarities\n",
    "        positives = bin_mat[user].nonzero()[1]\n",
    "        negatives = list(set(range(mat.shape[1])) - set(positives))\n",
    "\n",
    "        for item in positives:\n",
    "            assert (pred[user][negatives] < pred[user, item]).all()\n",
    "            \n",
    "test_overfit(mat)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b414610",
   "metadata": {},
   "source": [
    "## Running experiment using pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f3225456",
   "metadata": {},
   "outputs": [],
   "source": [
    "from recpack.pipelines import PipelineBuilder\n",
    "from recpack.data.datasets import AdressaOneWeek\n",
    "from recpack.splitters.scenarios import WeakGeneralization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "345019f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fcdd4e381254d81a102b4c7c9801ada",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2532729 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4300e35d5a044b86bc78d3b9369db380",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2532729 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = AdressaOneWeek(\n",
    "    path='/Users/robinverachtert/workspace/doctorate/datasets/',\n",
    "    filename='adressa_one_week.csv'\n",
    ")\n",
    "data = dataset.load_interaction_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "47169d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subsample to 1000 users to make it faster\n",
    "import numpy as np\n",
    "\n",
    "users = np.random.choice(list(data.active_users), 1000)\n",
    "data = data.users_in(users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a5a8b9ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbed90baf9b74ba3baefceace5575ceb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "266fbd7b75dd4168b3cf6a5e37498f12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scenario = WeakGeneralization(frac_data_in=0.8, validation=True)\n",
    "scenario.split(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ba6aa1bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from recpack.pipelines import ALGORITHM_REGISTRY\n",
    "ALGORITHM_REGISTRY.register('NeuMF', NeuMF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2c46caa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "builder = PipelineBuilder()\n",
    "builder.set_data_from_scenario(scenario)\n",
    "builder.set_optimisation_metric('NormalizedDiscountedCumulativeGainK', K=10)\n",
    "builder.add_metric('NormalizedDiscountedCumulativeGainK', K=10)\n",
    "builder.add_metric('CoverageK', K=10)\n",
    "\n",
    "builder.add_algorithm(\n",
    "    algorithm = 'NeuMF', \n",
    "    params = {\n",
    "        'batch_size': 512,\n",
    "        'max_epochs': 10,\n",
    "        'learning_rate': 0.01,\n",
    "        'stopping_criterion': 'ndcg',\n",
    "        'predict_topK': 20,\n",
    "        'U': 3,\n",
    "        'dropout': 0.01\n",
    "    },\n",
    "    grid = {\n",
    "        'num_components': [32, 64, 128],\n",
    "    }\n",
    ")\n",
    "\n",
    "builder.add_algorithm('Popularity', params={'K': 20})\n",
    "builder.add_algorithm('ItemKNN', params={'similarity': 'conditional_probability'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "05c0a518",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = builder.build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3314c304",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a408e2daf77425bb484e4c455834d3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-06-14 11:35:50,574 - base - recpack - INFO - Processed epoch 0 in 0.95 s.Batch Training Loss = 386.5929\n",
      "2022-06-14 11:35:55,193 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.09531884052449853, which is better than previous iterations.\n",
      "2022-06-14 11:35:55,194 - base - recpack - INFO - Model improved. Storing better model.\n",
      "2022-06-14 11:35:55,242 - base - recpack - INFO - Evaluation at end of 0 took 4.67 s.\n",
      "2022-06-14 11:35:56,391 - base - recpack - INFO - Processed epoch 1 in 1.15 s.Batch Training Loss = 215.8187\n",
      "2022-06-14 11:36:00,255 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.09616565142814695, which is better than previous iterations.\n",
      "2022-06-14 11:36:00,256 - base - recpack - INFO - Model improved. Storing better model.\n",
      "2022-06-14 11:36:00,318 - base - recpack - INFO - Evaluation at end of 1 took 3.93 s.\n",
      "2022-06-14 11:36:01,397 - base - recpack - INFO - Processed epoch 2 in 1.08 s.Batch Training Loss = 156.5306\n",
      "2022-06-14 11:36:05,531 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.10546144879206211, which is better than previous iterations.\n",
      "2022-06-14 11:36:05,532 - base - recpack - INFO - Model improved. Storing better model.\n",
      "2022-06-14 11:36:05,587 - base - recpack - INFO - Evaluation at end of 2 took 4.19 s.\n",
      "2022-06-14 11:36:06,495 - base - recpack - INFO - Processed epoch 3 in 0.91 s.Batch Training Loss = 141.0335\n",
      "2022-06-14 11:36:10,120 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.11345689418983992, which is better than previous iterations.\n",
      "2022-06-14 11:36:10,121 - base - recpack - INFO - Model improved. Storing better model.\n",
      "2022-06-14 11:36:10,178 - base - recpack - INFO - Evaluation at end of 3 took 3.68 s.\n",
      "2022-06-14 11:36:11,306 - base - recpack - INFO - Processed epoch 4 in 1.13 s.Batch Training Loss = 131.0031\n",
      "2022-06-14 11:36:14,993 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.11552711232878098, which is better than previous iterations.\n",
      "2022-06-14 11:36:14,994 - base - recpack - INFO - Model improved. Storing better model.\n",
      "2022-06-14 11:36:15,037 - base - recpack - INFO - Evaluation at end of 4 took 3.73 s.\n",
      "2022-06-14 11:36:16,150 - base - recpack - INFO - Processed epoch 5 in 1.11 s.Batch Training Loss = 127.8347\n",
      "2022-06-14 11:36:20,172 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.12266197146075067, which is better than previous iterations.\n",
      "2022-06-14 11:36:20,173 - base - recpack - INFO - Model improved. Storing better model.\n",
      "2022-06-14 11:36:20,220 - base - recpack - INFO - Evaluation at end of 5 took 4.07 s.\n",
      "2022-06-14 11:36:21,187 - base - recpack - INFO - Processed epoch 6 in 0.97 s.Batch Training Loss = 123.9171\n",
      "2022-06-14 11:36:25,434 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.12174562300784492, which is worse than previous iterations.\n",
      "2022-06-14 11:36:25,435 - base - recpack - INFO - Evaluation at end of 6 took 4.25 s.\n",
      "2022-06-14 11:36:26,513 - base - recpack - INFO - Processed epoch 7 in 1.08 s.Batch Training Loss = 121.5448\n",
      "2022-06-14 11:36:29,974 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.1263561808603172, which is better than previous iterations.\n",
      "2022-06-14 11:36:29,977 - base - recpack - INFO - Model improved. Storing better model.\n",
      "2022-06-14 11:36:30,030 - base - recpack - INFO - Evaluation at end of 7 took 3.52 s.\n",
      "2022-06-14 11:36:31,234 - base - recpack - INFO - Processed epoch 8 in 1.20 s.Batch Training Loss = 119.0906\n",
      "2022-06-14 11:36:34,823 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.12216633469327047, which is worse than previous iterations.\n",
      "2022-06-14 11:36:34,824 - base - recpack - INFO - Evaluation at end of 8 took 3.59 s.\n",
      "2022-06-14 11:36:35,997 - base - recpack - INFO - Processed epoch 9 in 1.17 s.Batch Training Loss = 117.0045\n",
      "2022-06-14 11:36:39,553 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.12054799880140503, which is worse than previous iterations.\n",
      "2022-06-14 11:36:39,553 - base - recpack - INFO - Evaluation at end of 9 took 3.56 s.\n",
      "2022-06-14 11:36:39,582 - base - recpack - INFO - Fitting NeuMF complete - Took 50.1s\n",
      "2022-06-14 11:36:45,530 - base - recpack - INFO - Processed epoch 0 in 2.06 s.Batch Training Loss = 361.7539\n",
      "2022-06-14 11:36:50,931 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.11393266506313778, which is better than previous iterations.\n",
      "2022-06-14 11:36:50,932 - base - recpack - INFO - Model improved. Storing better model.\n",
      "2022-06-14 11:36:51,025 - base - recpack - INFO - Evaluation at end of 0 took 5.49 s.\n",
      "2022-06-14 11:36:53,070 - base - recpack - INFO - Processed epoch 1 in 2.04 s.Batch Training Loss = 170.7790\n",
      "2022-06-14 11:36:58,929 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.11146416562654804, which is worse than previous iterations.\n",
      "2022-06-14 11:36:58,930 - base - recpack - INFO - Evaluation at end of 1 took 5.86 s.\n",
      "2022-06-14 11:37:01,007 - base - recpack - INFO - Processed epoch 2 in 2.08 s.Batch Training Loss = 144.6840\n",
      "2022-06-14 11:37:06,472 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.11766777663187439, which is better than previous iterations.\n",
      "2022-06-14 11:37:06,473 - base - recpack - INFO - Model improved. Storing better model.\n",
      "2022-06-14 11:37:06,570 - base - recpack - INFO - Evaluation at end of 2 took 5.56 s.\n",
      "2022-06-14 11:37:08,806 - base - recpack - INFO - Processed epoch 3 in 2.23 s.Batch Training Loss = 133.7592\n",
      "2022-06-14 11:37:14,353 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.1197901700807893, which is better than previous iterations.\n",
      "2022-06-14 11:37:14,353 - base - recpack - INFO - Model improved. Storing better model.\n",
      "2022-06-14 11:37:14,509 - base - recpack - INFO - Evaluation at end of 3 took 5.70 s.\n",
      "2022-06-14 11:37:16,891 - base - recpack - INFO - Processed epoch 4 in 2.38 s.Batch Training Loss = 130.7431\n",
      "2022-06-14 11:37:22,479 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.12230186859917087, which is better than previous iterations.\n",
      "2022-06-14 11:37:22,480 - base - recpack - INFO - Model improved. Storing better model.\n",
      "2022-06-14 11:37:22,560 - base - recpack - INFO - Evaluation at end of 4 took 5.67 s.\n",
      "2022-06-14 11:37:24,998 - base - recpack - INFO - Processed epoch 5 in 2.44 s.Batch Training Loss = 123.1936\n",
      "2022-06-14 11:37:31,121 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.12175978834667317, which is worse than previous iterations.\n",
      "2022-06-14 11:37:31,122 - base - recpack - INFO - Evaluation at end of 5 took 6.12 s.\n",
      "2022-06-14 11:37:33,333 - base - recpack - INFO - Processed epoch 6 in 2.21 s.Batch Training Loss = 123.4766\n",
      "2022-06-14 11:37:39,772 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.12499389052879742, which is better than previous iterations.\n",
      "2022-06-14 11:37:39,773 - base - recpack - INFO - Model improved. Storing better model.\n",
      "2022-06-14 11:37:39,860 - base - recpack - INFO - Evaluation at end of 6 took 6.53 s.\n",
      "2022-06-14 11:37:41,965 - base - recpack - INFO - Processed epoch 7 in 2.10 s.Batch Training Loss = 120.0088\n",
      "2022-06-14 11:37:47,917 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.1210205894537078, which is worse than previous iterations.\n",
      "2022-06-14 11:37:47,918 - base - recpack - INFO - Evaluation at end of 7 took 5.95 s.\n",
      "2022-06-14 11:37:50,061 - base - recpack - INFO - Processed epoch 8 in 2.14 s.Batch Training Loss = 121.2273\n",
      "2022-06-14 11:37:55,282 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.12137692081165898, which is worse than previous iterations.\n",
      "2022-06-14 11:37:55,283 - base - recpack - INFO - Evaluation at end of 8 took 5.22 s.\n",
      "2022-06-14 11:37:57,547 - base - recpack - INFO - Processed epoch 9 in 2.26 s.Batch Training Loss = 117.8513\n",
      "2022-06-14 11:38:03,175 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.1175360655598515, which is worse than previous iterations.\n",
      "2022-06-14 11:38:03,176 - base - recpack - INFO - Evaluation at end of 9 took 5.63 s.\n",
      "2022-06-14 11:38:03,214 - base - recpack - INFO - Fitting NeuMF complete - Took 79.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-06-14 11:38:13,676 - base - recpack - INFO - Processed epoch 0 in 5.01 s.Batch Training Loss = 281.7143\n",
      "2022-06-14 11:38:29,564 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.06854066043060869, which is better than previous iterations.\n",
      "2022-06-14 11:38:29,565 - base - recpack - INFO - Model improved. Storing better model.\n",
      "2022-06-14 11:38:29,788 - base - recpack - INFO - Evaluation at end of 0 took 16.11 s.\n",
      "2022-06-14 11:38:34,544 - base - recpack - INFO - Processed epoch 1 in 4.75 s.Batch Training Loss = 150.6045\n",
      "2022-06-14 11:38:54,420 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.10127981458122304, which is better than previous iterations.\n",
      "2022-06-14 11:38:54,421 - base - recpack - INFO - Model improved. Storing better model.\n",
      "2022-06-14 11:38:54,594 - base - recpack - INFO - Evaluation at end of 1 took 20.05 s.\n",
      "2022-06-14 11:39:00,131 - base - recpack - INFO - Processed epoch 2 in 5.54 s.Batch Training Loss = 144.9262\n",
      "2022-06-14 11:39:12,754 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.12040281211375403, which is better than previous iterations.\n",
      "2022-06-14 11:39:12,755 - base - recpack - INFO - Model improved. Storing better model.\n",
      "2022-06-14 11:39:12,959 - base - recpack - INFO - Evaluation at end of 2 took 12.82 s.\n",
      "2022-06-14 11:39:17,754 - base - recpack - INFO - Processed epoch 3 in 4.79 s.Batch Training Loss = 141.7177\n",
      "2022-06-14 11:39:30,906 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.12263519703242622, which is better than previous iterations.\n",
      "2022-06-14 11:39:30,908 - base - recpack - INFO - Model improved. Storing better model.\n",
      "2022-06-14 11:39:31,149 - base - recpack - INFO - Evaluation at end of 3 took 13.39 s.\n",
      "2022-06-14 11:39:35,979 - base - recpack - INFO - Processed epoch 4 in 4.83 s.Batch Training Loss = 143.1375\n",
      "2022-06-14 11:39:50,672 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.12387389057723214, which is better than previous iterations.\n",
      "2022-06-14 11:39:50,673 - base - recpack - INFO - Model improved. Storing better model.\n",
      "2022-06-14 11:39:50,822 - base - recpack - INFO - Evaluation at end of 4 took 14.84 s.\n",
      "2022-06-14 11:39:55,723 - base - recpack - INFO - Processed epoch 5 in 4.90 s.Batch Training Loss = 140.1636\n",
      "2022-06-14 11:40:08,206 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.12045340571384894, which is worse than previous iterations.\n",
      "2022-06-14 11:40:08,207 - base - recpack - INFO - Evaluation at end of 5 took 12.48 s.\n",
      "2022-06-14 11:40:12,998 - base - recpack - INFO - Processed epoch 6 in 4.79 s.Batch Training Loss = 137.1790\n",
      "2022-06-14 11:40:26,330 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.11155474623206976, which is worse than previous iterations.\n",
      "2022-06-14 11:40:26,331 - base - recpack - INFO - Evaluation at end of 6 took 13.33 s.\n",
      "2022-06-14 11:40:31,196 - base - recpack - INFO - Processed epoch 7 in 4.86 s.Batch Training Loss = 136.4507\n",
      "2022-06-14 11:40:54,757 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.12066391680680144, which is worse than previous iterations.\n",
      "2022-06-14 11:40:54,759 - base - recpack - INFO - Evaluation at end of 7 took 23.56 s.\n",
      "2022-06-14 11:40:59,907 - base - recpack - INFO - Processed epoch 8 in 5.14 s.Batch Training Loss = 133.2792\n",
      "2022-06-14 11:41:11,607 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.12214315323659665, which is worse than previous iterations.\n",
      "2022-06-14 11:41:11,609 - base - recpack - INFO - Evaluation at end of 8 took 11.70 s.\n",
      "2022-06-14 11:41:16,489 - base - recpack - INFO - Processed epoch 9 in 4.88 s.Batch Training Loss = 130.3466\n",
      "2022-06-14 11:41:26,022 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.12427279573324175, which is better than previous iterations.\n",
      "2022-06-14 11:41:26,024 - base - recpack - INFO - Model improved. Storing better model.\n",
      "2022-06-14 11:41:26,242 - base - recpack - INFO - Evaluation at end of 9 took 9.75 s.\n",
      "2022-06-14 11:41:26,287 - base - recpack - INFO - Fitting NeuMF complete - Took 1.98e+02s\n",
      "2022-06-14 11:41:41,949 - base - recpack - INFO - Processed epoch 0 in 0.95 s.Batch Training Loss = 339.4119\n",
      "2022-06-14 11:41:45,316 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.09365425605733416, which is better than previous iterations.\n",
      "2022-06-14 11:41:45,317 - base - recpack - INFO - Model improved. Storing better model.\n",
      "2022-06-14 11:41:45,354 - base - recpack - INFO - Evaluation at end of 0 took 3.40 s.\n",
      "2022-06-14 11:41:46,272 - base - recpack - INFO - Processed epoch 1 in 0.92 s.Batch Training Loss = 212.8805\n",
      "2022-06-14 11:41:49,876 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.09542159846123212, which is better than previous iterations.\n",
      "2022-06-14 11:41:49,877 - base - recpack - INFO - Model improved. Storing better model.\n",
      "2022-06-14 11:41:49,914 - base - recpack - INFO - Evaluation at end of 1 took 3.64 s.\n",
      "2022-06-14 11:41:50,791 - base - recpack - INFO - Processed epoch 2 in 0.88 s.Batch Training Loss = 154.8706\n",
      "2022-06-14 11:46:17,768 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.0940302124699601, which is worse than previous iterations.\n",
      "2022-06-14 11:46:17,816 - base - recpack - INFO - Evaluation at end of 2 took 267.02 s.\n",
      "2022-06-14 11:46:19,071 - base - recpack - INFO - Processed epoch 3 in 1.23 s.Batch Training Loss = 133.1676\n",
      "2022-06-14 11:46:23,330 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.11952905607645124, which is better than previous iterations.\n",
      "2022-06-14 11:46:23,331 - base - recpack - INFO - Model improved. Storing better model.\n",
      "2022-06-14 11:46:23,375 - base - recpack - INFO - Evaluation at end of 3 took 4.30 s.\n",
      "2022-06-14 11:46:24,357 - base - recpack - INFO - Processed epoch 4 in 0.98 s.Batch Training Loss = 127.2827\n",
      "2022-06-14 11:46:28,697 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.1274632047843151, which is better than previous iterations.\n",
      "2022-06-14 11:46:28,701 - base - recpack - INFO - Model improved. Storing better model.\n",
      "2022-06-14 11:46:29,014 - base - recpack - INFO - Evaluation at end of 4 took 4.66 s.\n",
      "2022-06-14 13:46:31,917 - base - recpack - INFO - Processed epoch 5 in 7202.90 s.Batch Training Loss = 123.3641\n",
      "2022-06-14 13:46:35,737 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.13216286955223266, which is better than previous iterations.\n",
      "2022-06-14 13:46:35,738 - base - recpack - INFO - Model improved. Storing better model.\n",
      "2022-06-14 13:46:35,782 - base - recpack - INFO - Evaluation at end of 5 took 3.86 s.\n",
      "2022-06-14 13:46:36,689 - base - recpack - INFO - Processed epoch 6 in 0.91 s.Batch Training Loss = 120.8378\n",
      "2022-06-14 13:46:40,255 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.13070274601660825, which is worse than previous iterations.\n",
      "2022-06-14 13:46:40,256 - base - recpack - INFO - Evaluation at end of 6 took 3.57 s.\n",
      "2022-06-14 13:46:41,259 - base - recpack - INFO - Processed epoch 7 in 1.00 s.Batch Training Loss = 118.3888\n",
      "2022-06-14 13:52:42,242 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.13162820133821346, which is worse than previous iterations.\n",
      "2022-06-14 13:52:42,243 - base - recpack - INFO - Evaluation at end of 7 took 360.98 s.\n",
      "2022-06-14 13:52:43,281 - base - recpack - INFO - Processed epoch 8 in 1.04 s.Batch Training Loss = 117.7154\n",
      "2022-06-14 13:52:49,346 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.12526234232480338, which is worse than previous iterations.\n",
      "2022-06-14 13:52:49,347 - base - recpack - INFO - Evaluation at end of 8 took 6.06 s.\n",
      "2022-06-14 13:52:59,356 - base - recpack - INFO - Processed epoch 9 in 10.01 s.Batch Training Loss = 117.5669\n",
      "2022-06-14 13:53:37,542 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.12651018001839087, which is worse than previous iterations.\n",
      "2022-06-14 13:53:37,546 - base - recpack - INFO - Evaluation at end of 9 took 38.18 s.\n",
      "2022-06-14 13:53:37,573 - base - recpack - INFO - Fitting NeuMF complete - Took 7.92e+03s\n",
      "2022-06-14 13:53:44,885 - base - recpack - INFO - Fitting Popularity complete - Took 0.0218s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/robinverachtert/.virtualenvs/recsys_demo/lib/python3.9/site-packages/scipy/sparse/_index.py:146: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_arrayXarray(i, j, x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-06-14 13:53:45,297 - base - recpack - INFO - Fitting ItemKNN complete - Took 0.276s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/robinverachtert/.virtualenvs/recsys_demo/lib/python3.9/site-packages/recpack/algorithms/base.py:274: UserWarning: ItemKNN missing similar items for 2083 items.\n",
      "  warnings.warn(f\"{self.name} missing similar items for {missing} items.\")\n"
     ]
    }
   ],
   "source": [
    "pipeline.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8af63fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3a36b1d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>normalizeddiscountedcumulativegaink_10</th>\n",
       "      <th>coveragek_10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NeuMF(U=3,batch_size=512,dropout=0.01,exact_sampling=False,keep_last=False,learning_rate=0.01,max_epochs=10,max_iter_no_change=5,min_improvement=0.0,num_components=32,predict_topK=20,save_best_to_file=False,seed=1360846362,stop_early=False,stopping_criterion=&lt;recpack.algorithms.stopping_criterion.StoppingCriterion object at 0x129de83a0&gt;)</th>\n",
       "      <td>0.102188</td>\n",
       "      <td>0.003584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Popularity(K=20)</th>\n",
       "      <td>0.107707</td>\n",
       "      <td>0.003584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ItemKNN(K=200,normalize=False,normalize_X=False,normalize_sim=False,pop_discount=None,similarity=conditional_probability)</th>\n",
       "      <td>0.136076</td>\n",
       "      <td>0.079928</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    normalizeddiscountedcumulativegaink_10  \\\n",
       "NeuMF(U=3,batch_size=512,dropout=0.01,exact_sam...                                0.102188   \n",
       "Popularity(K=20)                                                                  0.107707   \n",
       "ItemKNN(K=200,normalize=False,normalize_X=False...                                0.136076   \n",
       "\n",
       "                                                    coveragek_10  \n",
       "NeuMF(U=3,batch_size=512,dropout=0.01,exact_sam...      0.003584  \n",
       "Popularity(K=20)                                        0.003584  \n",
       "ItemKNN(K=200,normalize=False,normalize_X=False...      0.079928  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame.from_dict(pipeline.get_metrics()).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "720b3479",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cbe6c68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a929f25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f6424f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa99149",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c6391a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4211ea3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b84adbb2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e51fe3f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bcc4d5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db3b2d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "7da6e734",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
