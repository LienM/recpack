{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "85c37828",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pytest\n",
    "import torch\n",
    "from torch import nn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "471f8043",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable, List, Optional, Union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "353239bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code used from https://github.com/facebookresearch/multimodal/blob/5dec8a/torchmultimodal/modules/layers/mlp.py\n",
    "# Another option is to use torchvision.ops.MLP \n",
    "# which is nearly identical in implementation, but is in torchvision and not in base torch\n",
    "class MLP(nn.Module):\n",
    "    \"\"\"A multi-layer perceptron module.\n",
    "    This module is a sequence of linear layers plus activation functions.\n",
    "    The user can optionally add normalization and/or dropout to each of the layers.\n",
    "    \n",
    "    Code used from https://github.com/facebookresearch/multimodal/blob/5dec8a/torchmultimodal/modules/layers/mlp.py\n",
    "    Args:\n",
    "        in_dim (int): Input dimension.\n",
    "        out_dim (int): Output dimension.\n",
    "        hidden_dims (Optional[List[int]]): Output dimension for each hidden layer.\n",
    "        dropout (float): Probability for dropout layer.\n",
    "        activation (Callable[..., nn.Module]): Which activation\n",
    "            function to use. Supports module type or partial.\n",
    "        normalization (Optional[Callable[..., nn.Module]]): Which\n",
    "            normalization layer to use (None for no normalization).\n",
    "            Supports module type or partial.\n",
    "    Inputs:\n",
    "        x (Tensor): Tensor containing a batch of input sequences.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_dim: int,\n",
    "        out_dim: int,\n",
    "        hidden_dims: Optional[Union[int, List[int]]] = None,\n",
    "        dropout: float = 0.5,\n",
    "        activation: Callable[..., nn.Module] = nn.ReLU,\n",
    "        normalization: Optional[Callable[..., nn.Module]] = None,\n",
    "        **kwargs,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        layers = nn.ModuleList()\n",
    "\n",
    "        if hidden_dims is None:\n",
    "            hidden_dims = []\n",
    "\n",
    "        if isinstance(hidden_dims, int):\n",
    "            hidden_dims = [hidden_dims]\n",
    "\n",
    "        for hidden_dim in hidden_dims:\n",
    "            layers.append(nn.Linear(in_dim, hidden_dim))\n",
    "            if normalization:\n",
    "                layers.append(normalization(hidden_dim))\n",
    "            layers.append(activation())\n",
    "            layers.append(nn.Dropout(dropout))\n",
    "            in_dim = hidden_dim\n",
    "        layers.append(nn.Linear(in_dim, out_dim))\n",
    "        self.model = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.model(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "83fcd62d",
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_SIZE = 3\n",
    "N_USERS = 5\n",
    "N_ITEMS = 10\n",
    "a = MLP(2*EMBEDDING_SIZE, N_ITEMS, [6, 4, 2], dropout=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cb2a3f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: add tests that check that the MLP works as expected.\n",
    "def test_MLP_shapes():\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "551d5c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NMFModule(nn.Module):\n",
    "    \"\"\"Model that encodes the Neural Matrix Factorization Network.\n",
    "\n",
    "    :param num_components: size of the embeddings\n",
    "    :type num_components: int\n",
    "    :param n_users: number of users in the network\n",
    "    :type n_users: int\n",
    "    :param n_items: number of items in the network\n",
    "    :type n_items: int\n",
    "    :param hidden_dims: dimensions of the MLP hidden layers.\n",
    "    :type hidden_dims: Union[int, List[int]]\n",
    "    :param dropout: Dropout chance between layers of the MLP\n",
    "    :type dropout: float\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, num_components: int, n_users: int, n_items: int, hidden_dims: Union[int, List[int]], dropout: float\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.user_embedding = nn.Embedding(n_users, num_components)\n",
    "        self.item_embedding = nn.Embedding(n_items, num_components)\n",
    "\n",
    "        # 2 x embedding size as input, since the user and item embedding are concatenated.\n",
    "        # Output is always 1, since we need a single score for u,i\n",
    "        self.mlp = MLP(2 * num_components, 1, hidden_dims, dropout=dropout)\n",
    "\n",
    "        # In order to interpret the output as a probability, the score should be between 0 and 1\n",
    "        # The papers mentions probit / logistic activation,\n",
    "        # but in pytorch sigmoid seems like the only one to give 0 to 1 values\n",
    "        self.final = nn.Sigmoid()\n",
    "\n",
    "        # weight initialization\n",
    "        self.user_embedding.weight.data.normal_(0, 1.0 / self.user_embedding.embedding_dim)\n",
    "        self.item_embedding.weight.data.normal_(0, 1.0 / self.item_embedding.embedding_dim)\n",
    "\n",
    "    def forward(self, users: torch.LongTensor, items: torch.LongTensor) -> torch.FloatTensor:\n",
    "        \"\"\"Predict scores for the user item pairs obtained when zipping together the two 1D tensors\n",
    "\n",
    "        :param users: 1D tensor with user ids\n",
    "        :type users: torch.LongTensor\n",
    "        :param items: 1D tensor with item ids\n",
    "        :type items: torch.LongTensor\n",
    "        :return: 1D tensor with on position i the prediction similarity between `users[i]` and `items[i]`\n",
    "        :rtype: torch.FloatTensor\n",
    "        \"\"\"\n",
    "\n",
    "        user_emb = self.user_embedding(users)\n",
    "        item_emb = self.item_embedding(items)\n",
    "\n",
    "        return self.final(self.mlp(torch.hstack([user_emb, item_emb])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b8bcb491",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_output_shapes_NMF(embedding_size, num_users, num_items, hidden_sizes):\n",
    "    \"\"\"Check that no mather the inner settings of the network, the output is always correct\"\"\"\n",
    "    mod = NMFModule(embedding_size, num_users, num_items, hidden_sizes, 0.0)\n",
    "    \n",
    "    user_tensor = torch.LongTensor([1, 2])\n",
    "    item_tensor = torch.LongTensor([1, 2])\n",
    "    \n",
    "    res = mod(user_tensor, item_tensor) # predict scores for items given the users\n",
    "    \n",
    "    assert res.shape == (2, 1)\n",
    "\n",
    "    assert (res.detach().numpy() <= 1).all()\n",
    "    assert (res.detach().numpy() >= 0).all()\n",
    "\n",
    "\n",
    "test_output_shapes_NMF(5, 10, 10, [10])\n",
    "test_output_shapes_NMF(5, 10, 10, [10, 5, 3])\n",
    "test_output_shapes_NMF(5, 3, 10, [10])\n",
    "test_output_shapes_NMF(1, 3, 3, [10])\n",
    "\n",
    "\n",
    "# def test_shape_input_check_NMF():\n",
    "#     \"\"\"Check that no mather the inner settings of the network, the output is always correct\"\"\"\n",
    "    \n",
    "#     mod = NMFModule(3, 3, 3, [6], 0.0)\n",
    "    \n",
    "#     user_tensor = torch.LongTensor([[1, 2]])\n",
    "#     item_tensor = torch.LongTensor([[1, 2]])\n",
    "    \n",
    "#     with pytest.raises(ValueError):\n",
    "#         mod(user_tensor, item_tensor)\n",
    "        \n",
    "#     user_tensor = torch.LongTensor([1, 2])\n",
    "#     item_tensor = torch.LongTensor([1, 2, 0])\n",
    "    \n",
    "#     with pytest.raises(ValueError):\n",
    "#         mod(user_tensor, item_tensor)\n",
    "\n",
    "#     user_tensor = torch.LongTensor([[1, 2]])\n",
    "#     item_tensor = torch.LongTensor([1, 2])\n",
    "\n",
    "#     with pytest.raises(ValueError):\n",
    "#         mod(user_tensor, item_tensor)\n",
    "\n",
    "\n",
    "# test_shape_input_check_NMF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3c07d570",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Union, Optional\n",
    "\n",
    "import pandas as pd\n",
    "from recpack.algorithms.base import TorchMLAlgorithm\n",
    "from recpack.algorithms.samplers import PositiveNegativeSampler\n",
    "from recpack.algorithms.util import get_users\n",
    "from recpack.data.matrix import InteractionMatrix\n",
    "from scipy.sparse import csr_matrix, lil_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b93dbaa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuMF(TorchMLAlgorithm):\n",
    "    \"\"\"Implementation of Neural Matrix Factoration.\n",
    "\n",
    "    Neural Matrix Factorization based on MLP architecture\n",
    "    as presented in Figure 2 in He, Xiangnan, et al. \"Neural collaborative filtering.\"\n",
    "    Proceedings of the 26th international conference on world wide web. 2017.\n",
    "\n",
    "    Represents the users and items using an embedding, and models similarity using a neural network.\n",
    "    An MLP is used with as input the concatenated embeddings of users and items.\n",
    "\n",
    "    As in the paper, the sum of square error is used as the loss function.\n",
    "    Positive items should get a prediction close to 1, while sampled negatives should get a value close to 0.\n",
    "    The MLP has 3 layers, whose dimensions are based on the `num_components` parameter.\n",
    "    Bottom layer has `num_components * 2`, middle layer `num_components`\n",
    "    and the top layer has `num_components / 2` dimensions.\n",
    "\n",
    "    :param num_components: Size of the embeddings, needs to be an even number.\n",
    "    :type num_components: int\n",
    "    :param batch_size: How many samples to use in each update step.\n",
    "        Higher batch sizes make each epoch more efficient,\n",
    "        but increases the amount of epochs needed to converge to the optimum,\n",
    "        by reducing the amount of updates per epoch.\n",
    "        Defaults to 512.\n",
    "    :type batch_size: Optional[int]\n",
    "    :param max_epochs: The max number of epochs to train.\n",
    "        If the stopping criterion uses early stopping, less epochs could be used.\n",
    "        Defaults to 10.\n",
    "    :type max_epochs: Optional[int]\n",
    "    :param learning_rate: How much to update the weights at each update. Defaults to 0.01\n",
    "    :type learning_rate: Optional[float]\n",
    "    :param stopping_criterion: Name of the stopping criterion to use for training.\n",
    "        For available values,\n",
    "        check :meth:`recpack.algorithms.stopping_criterion.StoppingCriterion.FUNCTIONS`\n",
    "        Defaults to 'ndcg'\n",
    "    :type stopping_criterion: Optional[str]\n",
    "    :param stop_early: If True, early stopping is enabled,\n",
    "        and after ``max_iter_no_change`` iterations where improvement of loss function\n",
    "        is below ``min_improvement`` the optimisation is stopped,\n",
    "        even if max_epochs is not reached.\n",
    "        Defaults to False\n",
    "    :type stop_early: bool, optional\n",
    "    :param max_iter_no_change: If early stopping is enabled,\n",
    "        stop after this amount of iterations without change.\n",
    "        Defaults to 5\n",
    "    :type max_iter_no_change: int, optional\n",
    "    :param min_improvement: If early stopping is enabled, no change is detected,\n",
    "        if the improvement is below this value.\n",
    "        Defaults to 0.01\n",
    "    :type min_improvement: float, optional\n",
    "    :param seed: Seed to the randomizers, useful for reproducible results,\n",
    "        defaults to None\n",
    "    :type seed: int, optional\n",
    "    :param save_best_to_file: If true, the best model will be saved after training,\n",
    "        defaults to False\n",
    "    :type save_best_to_file: bool, optional\n",
    "    :param keep_last: Retain last model, rather than best\n",
    "        (according to stopping criterion value on validation data), defaults to False\n",
    "    :type keep_last: bool, optional\n",
    "    :param predict_topK: The topK recommendations to keep per row in the matrix.\n",
    "        Use when the user x item output matrix would become too large for RAM.\n",
    "        Defaults to None, which results in no filtering.\n",
    "    :type predict_topK: int, optional\n",
    "    :param U: Amount of negatives to sample for each positive example, defaults to 1\n",
    "    :type U: int, optional\n",
    "    :param dropout: Dropout parameter used in MLP, defaults to 0.0\n",
    "    :type dropout: float, optional\n",
    "    :param exact_sampling: Enable or disable exact checks while sampling. \n",
    "        With exact sampling the sampled negatives are guaranteed to not have been visited by the user. \n",
    "        Non exact sampling assumes that the space for item selection is large enough, \n",
    "        such that most items are likely not seen before.\n",
    "        Defaults to False,\n",
    "    :type exact_sampling: bool, optional\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_components: int,\n",
    "        batch_size: Optional[int] = 512,\n",
    "        max_epochs: Optional[int] = 10,\n",
    "        learning_rate: Optional[float] = 0.01,\n",
    "        stopping_criterion: Optional[str] = \"ndcg\",\n",
    "        stop_early: Optional[bool] = False,\n",
    "        max_iter_no_change: Optional[int] = 5,\n",
    "        min_improvement: Optional[float] = 0.0,\n",
    "        seed: Optional[int] = None,\n",
    "        save_best_to_file: Optional[bool] = False,\n",
    "        keep_last: Optional[bool] = False,\n",
    "        predict_topK: Optional[int] = None,\n",
    "        U: Optional[int] = 1,\n",
    "        dropout: Optional[float] = 0.0,\n",
    "        exact_sampling: Optional[bool] = False,\n",
    "    ):\n",
    "        super().__init__(\n",
    "            batch_size,\n",
    "            max_epochs,\n",
    "            learning_rate,\n",
    "            stopping_criterion,\n",
    "            stop_early,\n",
    "            max_iter_no_change,\n",
    "            min_improvement,\n",
    "            seed,\n",
    "            save_best_to_file,\n",
    "            keep_last,\n",
    "            predict_topK,\n",
    "        )\n",
    "\n",
    "        self.num_components = num_components\n",
    "        if self.num_components % 2 != 0:\n",
    "            raise ValueError(\"Please use an even number of components for training the NeuMF model.\")\n",
    "\n",
    "        self.hidden_dims = [self.num_components * 2, self.num_components, self.num_components // 2]\n",
    "        self.U = U\n",
    "        self.dropout = dropout\n",
    "        self.exact_sampling = exact_sampling\n",
    "\n",
    "        self.sampler = PositiveNegativeSampler(\n",
    "            U=self.U, replace=False, exact=exact_sampling, batch_size=self.batch_size\n",
    "        )\n",
    "\n",
    "    def _init_model(self, X: csr_matrix):\n",
    "        num_users, num_items = X.shape\n",
    "        self.model_ = NMFModule(self.num_components, num_users, num_items, self.hidden_dims, self.dropout).to(\n",
    "            self.device\n",
    "        )\n",
    "        self.optimizer = torch.optim.Adam(self.model_.parameters(), lr=self.learning_rate)\n",
    "\n",
    "    def _compute_loss(\n",
    "        self, positive_scores: torch.FloatTensor, negative_scores: torch.FloatTensor\n",
    "    ) -> torch.FloatTensor:\n",
    "        \"\"\"Compute the Square Error loss given recommendations for positive items, and sampled negatives.\"\"\"\n",
    "        mse = nn.MSELoss(reduction=\"sum\")\n",
    "        return mse(positive_scores, torch.ones_like(positive_scores, dtype=torch.float)) + mse(\n",
    "            negative_scores, torch.zeros_like(negative_scores, dtype=torch.float)\n",
    "        )\n",
    "\n",
    "    def _train_epoch(self, X: csr_matrix) -> List[int]:\n",
    "        losses = []\n",
    "        for users, positives, negatives in self.sampler.sample(X):\n",
    "\n",
    "            self.optimizer.zero_grad()\n",
    "\n",
    "            # Predict for the positives\n",
    "            positive_scores = self.model_.forward(users.to(self.device), positives.to(self.device))\n",
    "            # Predict for the negatives\n",
    "            negative_scores = self.model_.forward(\n",
    "                *self._construct_negative_prediction_input(users.to(self.device), negatives.to(self.device))\n",
    "            )\n",
    "\n",
    "            loss = self._compute_loss(positive_scores, negative_scores)\n",
    "\n",
    "            # Backwards propagation of the loss\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "\n",
    "            losses.append(loss.item())\n",
    "\n",
    "        return losses\n",
    "\n",
    "    def _construct_negative_prediction_input(self, users, negatives):\n",
    "        \"\"\"Since negatives has shape batch x U, and users is a 1d vector,\n",
    "        these need to be turned into two 1d vectors of size batch*U\n",
    "\n",
    "        First the users as a row are stacked U times and transposed,\n",
    "        so that this is also a batch x U tensor\n",
    "\n",
    "        then both are reshaped to remove the 2nd dimension, resulting in a single long 1d vector\n",
    "        \"\"\"\n",
    "        return users.repeat(self.U, 1).T.reshape(-1), negatives.reshape(-1)\n",
    "\n",
    "    def _batch_predict(self, X: csr_matrix, users: List[int]) -> csr_matrix:\n",
    "        X_pred = lil_matrix(X.shape)\n",
    "        if users is None:\n",
    "            users = get_users(X)\n",
    "\n",
    "        _, n_items = X.shape\n",
    "        n_users = len(users)\n",
    "\n",
    "        # Turn the np arrays and lists to torch tensors\n",
    "        user_tensor = torch.LongTensor(users).repeat(n_items, 1).T.reshape(-1).to(self.device)\n",
    "        item_tensor = torch.arange(n_items).repeat(n_users).to(self.device)\n",
    "\n",
    "        X_pred[users] = self.model_(user_tensor, item_tensor).detach().cpu().numpy().reshape(n_users, n_items)\n",
    "        return X_pred.tocsr()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9ca8f574",
   "metadata": {},
   "outputs": [],
   "source": [
    "TIMESTAMP_IX = 'ts'\n",
    "ITEM_IX = 'iid'\n",
    "USER_IX = 'uid'\n",
    "\n",
    "data = {\n",
    "    TIMESTAMP_IX: [3, 2, 1, 4, 0, 1, 2, 4, 0, 1, 2],\n",
    "    ITEM_IX: [0, 1, 2, 3, 0, 1, 2, 4, 0, 1, 2],\n",
    "    USER_IX: [0, 0, 1, 1, 2, 2, 3, 3, 4, 4, 5],\n",
    "}\n",
    "df = pd.DataFrame.from_dict(data)\n",
    "\n",
    "mat = InteractionMatrix(df, ITEM_IX, USER_IX, timestamp_ix=TIMESTAMP_IX)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1cf3329d",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [18]\u001b[0m, in \u001b[0;36m<cell line: 20>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m     params \u001b[38;5;241m=\u001b[39m [np \u001b[38;5;28;01mfor\u001b[39;00m np \u001b[38;5;129;01min\u001b[39;00m a\u001b[38;5;241m.\u001b[39mmodel_\u001b[38;5;241m.\u001b[39mnamed_parameters() \u001b[38;5;28;01mif\u001b[39;00m np[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mrequires_grad]\n\u001b[1;32m     18\u001b[0m     assert_changed(params_before, params, device)\n\u001b[0;32m---> 20\u001b[0m \u001b[43mtest_training_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbinary_values\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [18]\u001b[0m, in \u001b[0;36mtest_training_epoch\u001b[0;34m(X)\u001b[0m\n\u001b[1;32m     16\u001b[0m     a\u001b[38;5;241m.\u001b[39m_train_epoch(X)\n\u001b[1;32m     17\u001b[0m params \u001b[38;5;241m=\u001b[39m [np \u001b[38;5;28;01mfor\u001b[39;00m np \u001b[38;5;129;01min\u001b[39;00m a\u001b[38;5;241m.\u001b[39mmodel_\u001b[38;5;241m.\u001b[39mnamed_parameters() \u001b[38;5;28;01mif\u001b[39;00m np[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mrequires_grad]\n\u001b[0;32m---> 18\u001b[0m \u001b[43massert_changed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams_before\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/dist-env/lib/python3.8/site-packages/recpack/tests/test_algorithms/util.py:8\u001b[0m, in \u001b[0;36massert_changed\u001b[0;34m(params_before, params_after, device)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21massert_changed\u001b[39m(params_before, params_after, device):\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;66;03m# check if variables have changed\u001b[39;00m\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m (_, p0), (_, p1) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(params_before, params_after):\n\u001b[0;32m----> 8\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mequal(p0\u001b[38;5;241m.\u001b[39mto(device), p1\u001b[38;5;241m.\u001b[39mto(device))\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from recpack.tests.test_algorithms.util import assert_changed, assert_same\n",
    "\n",
    "def test_training_epoch(X):\n",
    "    a = NeuMF(\n",
    "        num_components=4, \n",
    "        U=2,\n",
    "        exact_sampling=True\n",
    "    )\n",
    "    device = a.device\n",
    "    a._init_model(X)\n",
    "\n",
    "    # Each training epoch should update the parameters\n",
    "    params = [np for np in a.model_.named_parameters() if np[1].requires_grad]\n",
    "    params_before = [(name, p.clone()) for (name, p) in params]\n",
    "    for _ in range(5):\n",
    "        a._train_epoch(X)\n",
    "    params = [np for np in a.model_.named_parameters() if np[1].requires_grad]\n",
    "    assert_changed(params_before, params, device)\n",
    "\n",
    "test_training_epoch(mat.binary_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "814b0473",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-06-15 05:51:37,505 - base - recpack - INFO - Processed epoch 0 in 0.01 s.Batch Training Loss = 10.4516\n",
      "2022-06-15 05:51:37,517 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.6405398473870061, which is better than previous iterations.\n",
      "2022-06-15 05:51:37,517 - base - recpack - INFO - Model improved. Storing better model.\n",
      "2022-06-15 05:51:37,523 - base - recpack - INFO - Evaluation at end of 0 took 0.02 s.\n",
      "2022-06-15 05:51:37,533 - base - recpack - INFO - Processed epoch 1 in 0.01 s.Batch Training Loss = 10.3924\n",
      "2022-06-15 05:51:37,538 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.6028241164651866, which is worse than previous iterations.\n",
      "2022-06-15 05:51:37,538 - base - recpack - INFO - Evaluation at end of 1 took 0.00 s.\n",
      "2022-06-15 05:51:37,550 - base - recpack - INFO - Processed epoch 2 in 0.01 s.Batch Training Loss = 10.3358\n",
      "2022-06-15 05:51:37,555 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.6028241164651866, which is worse than previous iterations.\n",
      "2022-06-15 05:51:37,556 - base - recpack - INFO - Evaluation at end of 2 took 0.00 s.\n",
      "2022-06-15 05:51:37,571 - base - recpack - INFO - Processed epoch 3 in 0.01 s.Batch Training Loss = 10.2785\n",
      "2022-06-15 05:51:37,576 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.6028241164651866, which is worse than previous iterations.\n",
      "2022-06-15 05:51:37,576 - base - recpack - INFO - Evaluation at end of 3 took 0.00 s.\n",
      "2022-06-15 05:51:37,592 - base - recpack - INFO - Processed epoch 4 in 0.02 s.Batch Training Loss = 10.2206\n",
      "2022-06-15 05:51:37,597 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.6028241164651866, which is worse than previous iterations.\n",
      "2022-06-15 05:51:37,598 - base - recpack - INFO - Evaluation at end of 4 took 0.00 s.\n",
      "2022-06-15 05:51:37,611 - base - recpack - INFO - Processed epoch 5 in 0.01 s.Batch Training Loss = 10.1621\n",
      "2022-06-15 05:51:37,615 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.6028241164651866, which is worse than previous iterations.\n",
      "2022-06-15 05:51:37,616 - base - recpack - INFO - Evaluation at end of 5 took 0.00 s.\n",
      "2022-06-15 05:51:37,629 - base - recpack - INFO - Processed epoch 6 in 0.01 s.Batch Training Loss = 10.1032\n",
      "2022-06-15 05:51:37,634 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.6028241164651866, which is worse than previous iterations.\n",
      "2022-06-15 05:51:37,634 - base - recpack - INFO - Evaluation at end of 6 took 0.00 s.\n",
      "2022-06-15 05:51:37,650 - base - recpack - INFO - Processed epoch 7 in 0.01 s.Batch Training Loss = 10.0437\n",
      "2022-06-15 05:51:37,654 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.6028241164651866, which is worse than previous iterations.\n",
      "2022-06-15 05:51:37,655 - base - recpack - INFO - Evaluation at end of 7 took 0.00 s.\n",
      "2022-06-15 05:51:37,665 - base - recpack - INFO - Processed epoch 8 in 0.01 s.Batch Training Loss = 9.9837\n",
      "2022-06-15 05:51:37,670 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.6028241164651866, which is worse than previous iterations.\n",
      "2022-06-15 05:51:37,671 - base - recpack - INFO - Evaluation at end of 8 took 0.00 s.\n",
      "2022-06-15 05:51:37,681 - base - recpack - INFO - Processed epoch 9 in 0.01 s.Batch Training Loss = 9.9233\n",
      "2022-06-15 05:51:37,686 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.6028241164651866, which is worse than previous iterations.\n",
      "2022-06-15 05:51:37,687 - base - recpack - INFO - Evaluation at end of 9 took 0.00 s.\n",
      "2022-06-15 05:51:37,690 - base - recpack - INFO - Fitting NeuMF complete - Took 0.205s\n",
      "2022-06-15 05:51:37,709 - base - recpack - INFO - Processed epoch 0 in 0.01 s.Batch Training Loss = 9.9468\n",
      "2022-06-15 05:51:37,714 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.7737582122087544, which is better than previous iterations.\n",
      "2022-06-15 05:51:37,715 - base - recpack - INFO - Model improved. Storing better model.\n",
      "2022-06-15 05:51:37,718 - base - recpack - INFO - Evaluation at end of 0 took 0.01 s.\n",
      "2022-06-15 05:51:37,734 - base - recpack - INFO - Processed epoch 1 in 0.02 s.Batch Training Loss = 9.8602\n",
      "2022-06-15 05:51:37,739 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.7372530491956414, which is worse than previous iterations.\n",
      "2022-06-15 05:51:37,740 - base - recpack - INFO - Evaluation at end of 1 took 0.00 s.\n",
      "2022-06-15 05:51:37,754 - base - recpack - INFO - Processed epoch 2 in 0.01 s.Batch Training Loss = 9.8002\n",
      "2022-06-15 05:51:37,759 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.7301688035606183, which is worse than previous iterations.\n",
      "2022-06-15 05:51:37,760 - base - recpack - INFO - Evaluation at end of 2 took 0.00 s.\n",
      "2022-06-15 05:51:37,771 - base - recpack - INFO - Processed epoch 3 in 0.01 s.Batch Training Loss = 9.7273\n",
      "2022-06-15 05:51:37,776 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.7301688035606183, which is worse than previous iterations.\n",
      "2022-06-15 05:51:37,776 - base - recpack - INFO - Evaluation at end of 3 took 0.00 s.\n",
      "2022-06-15 05:51:37,790 - base - recpack - INFO - Processed epoch 4 in 0.01 s.Batch Training Loss = 9.6632\n",
      "2022-06-15 05:51:37,795 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.7443372948306645, which is worse than previous iterations.\n",
      "2022-06-15 05:51:37,796 - base - recpack - INFO - Evaluation at end of 4 took 0.00 s.\n",
      "2022-06-15 05:51:37,807 - base - recpack - INFO - Processed epoch 5 in 0.01 s.Batch Training Loss = 9.5924\n",
      "2022-06-15 05:51:37,812 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.7372530491956414, which is worse than previous iterations.\n",
      "2022-06-15 05:51:37,813 - base - recpack - INFO - Evaluation at end of 5 took 0.00 s.\n",
      "2022-06-15 05:51:37,825 - base - recpack - INFO - Processed epoch 6 in 0.01 s.Batch Training Loss = 9.5142\n",
      "2022-06-15 05:51:37,829 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.7372530491956414, which is worse than previous iterations.\n",
      "2022-06-15 05:51:37,830 - base - recpack - INFO - Evaluation at end of 6 took 0.00 s.\n",
      "2022-06-15 05:51:37,842 - base - recpack - INFO - Processed epoch 7 in 0.01 s.Batch Training Loss = 9.4398\n",
      "2022-06-15 05:51:37,847 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.7372530491956414, which is worse than previous iterations.\n",
      "2022-06-15 05:51:37,847 - base - recpack - INFO - Evaluation at end of 7 took 0.00 s.\n",
      "2022-06-15 05:51:37,867 - base - recpack - INFO - Processed epoch 8 in 0.02 s.Batch Training Loss = 9.3403\n",
      "2022-06-15 05:51:37,872 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.7372530491956414, which is worse than previous iterations.\n",
      "2022-06-15 05:51:37,873 - base - recpack - INFO - Evaluation at end of 8 took 0.01 s.\n",
      "2022-06-15 05:51:37,885 - base - recpack - INFO - Processed epoch 9 in 0.01 s.Batch Training Loss = 9.2433\n",
      "2022-06-15 05:51:37,890 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.7372530491956414, which is worse than previous iterations.\n",
      "2022-06-15 05:51:37,890 - base - recpack - INFO - Evaluation at end of 9 took 0.01 s.\n",
      "2022-06-15 05:51:37,894 - base - recpack - INFO - Fitting NeuMF complete - Took 0.198s\n",
      "2022-06-15 05:51:37,910 - base - recpack - INFO - Processed epoch 0 in 0.01 s.Batch Training Loss = 9.6960\n",
      "2022-06-15 05:51:37,915 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.7837146108282446, which is better than previous iterations.\n",
      "2022-06-15 05:51:37,916 - base - recpack - INFO - Model improved. Storing better model.\n",
      "2022-06-15 05:51:37,919 - base - recpack - INFO - Evaluation at end of 0 took 0.01 s.\n",
      "2022-06-15 05:51:37,930 - base - recpack - INFO - Processed epoch 1 in 0.01 s.Batch Training Loss = 9.5650\n",
      "2022-06-15 05:51:37,935 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.7863204548293853, which is better than previous iterations.\n",
      "2022-06-15 05:51:37,936 - base - recpack - INFO - Model improved. Storing better model.\n",
      "2022-06-15 05:51:37,938 - base - recpack - INFO - Evaluation at end of 1 took 0.01 s.\n",
      "2022-06-15 05:51:37,958 - base - recpack - INFO - Processed epoch 2 in 0.02 s.Batch Training Loss = 9.4404\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-06-15 05:51:37,963 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.7838062179781108, which is worse than previous iterations.\n",
      "2022-06-15 05:51:37,964 - base - recpack - INFO - Evaluation at end of 2 took 0.00 s.\n",
      "2022-06-15 05:51:37,973 - base - recpack - INFO - Processed epoch 3 in 0.01 s.Batch Training Loss = 9.3179\n",
      "2022-06-15 05:51:37,978 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.7659479478689263, which is worse than previous iterations.\n",
      "2022-06-15 05:51:37,979 - base - recpack - INFO - Evaluation at end of 3 took 0.01 s.\n",
      "2022-06-15 05:51:37,990 - base - recpack - INFO - Processed epoch 4 in 0.01 s.Batch Training Loss = 9.2018\n",
      "2022-06-15 05:51:37,995 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.8524021713512242, which is better than previous iterations.\n",
      "2022-06-15 05:51:37,996 - base - recpack - INFO - Model improved. Storing better model.\n",
      "2022-06-15 05:51:37,999 - base - recpack - INFO - Evaluation at end of 4 took 0.01 s.\n",
      "2022-06-15 05:51:38,018 - base - recpack - INFO - Processed epoch 5 in 0.02 s.Batch Training Loss = 9.0883\n",
      "2022-06-15 05:51:38,023 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.8319380572408991, which is worse than previous iterations.\n",
      "2022-06-15 05:51:38,023 - base - recpack - INFO - Evaluation at end of 5 took 0.00 s.\n",
      "2022-06-15 05:51:38,044 - base - recpack - INFO - Processed epoch 6 in 0.02 s.Batch Training Loss = 8.9781\n",
      "2022-06-15 05:51:38,048 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.6988666359953621, which is worse than previous iterations.\n",
      "2022-06-15 05:51:38,049 - base - recpack - INFO - Evaluation at end of 6 took 0.00 s.\n",
      "2022-06-15 05:51:38,061 - base - recpack - INFO - Processed epoch 7 in 0.01 s.Batch Training Loss = 8.8724\n",
      "2022-06-15 05:51:38,066 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.6610039614973312, which is worse than previous iterations.\n",
      "2022-06-15 05:51:38,067 - base - recpack - INFO - Evaluation at end of 7 took 0.00 s.\n",
      "2022-06-15 05:51:38,077 - base - recpack - INFO - Processed epoch 8 in 0.01 s.Batch Training Loss = 8.7675\n",
      "2022-06-15 05:51:38,082 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.6232882305755117, which is worse than previous iterations.\n",
      "2022-06-15 05:51:38,083 - base - recpack - INFO - Evaluation at end of 8 took 0.00 s.\n",
      "2022-06-15 05:51:38,097 - base - recpack - INFO - Processed epoch 9 in 0.01 s.Batch Training Loss = 8.6667\n",
      "2022-06-15 05:51:38,101 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.6246457420604296, which is worse than previous iterations.\n",
      "2022-06-15 05:51:38,102 - base - recpack - INFO - Evaluation at end of 9 took 0.00 s.\n",
      "2022-06-15 05:51:38,105 - base - recpack - INFO - Fitting NeuMF complete - Took 0.208s\n"
     ]
    }
   ],
   "source": [
    "def test_batch_predict(mat, users):\n",
    "    a = NeuMF(\n",
    "        num_components=4, \n",
    "        U=2,\n",
    "        exact_sampling=True\n",
    "    )\n",
    "    device = a.device\n",
    "    a.fit(mat, (mat, mat))\n",
    "    params = [np for np in a.model_.named_parameters() if np[1].requires_grad]\n",
    "    params_before = [(name, p.clone()) for (name, p) in params]\n",
    "\n",
    "    pred = a._batch_predict(mat.users_in(users), users=users)\n",
    "\n",
    "    assert pred.shape == mat.shape\n",
    "    np.testing.assert_array_equal(pred.sum(axis=1).nonzero()[0], users)\n",
    "\n",
    "    params = [np for np in a.model_.named_parameters() if np[1].requires_grad]\n",
    "    assert_same(params_before, params, device)\n",
    "\n",
    "    \n",
    "\n",
    "test_batch_predict(mat, [0, 1])\n",
    "test_batch_predict(mat, [0])\n",
    "test_batch_predict(mat, [0, 1, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ed4d2e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_negative_input_construction(users, negatives, U):\n",
    "    \n",
    "    a = NeuMF(\n",
    "        num_components=8, \n",
    "        U=U\n",
    "    )\n",
    "    \n",
    "    num_users = users.shape[0]\n",
    "    users_input, negatives_input = a._construct_negative_prediction_input(users, negatives)\n",
    "    assert users_input.shape == negatives_input.shape\n",
    "    assert len(users_input.shape) == 1 # 1d vectors\n",
    "    \n",
    "    # Check that both are in the right order (each user is repeated U times before the next user is present)\n",
    "    for ix in range(users_input.shape[0]):\n",
    "        assert users_input[ix] == users[ix // U]\n",
    "        assert negatives_input[ix] == negatives[ix // U, ix % U]\n",
    "\n",
    "test_negative_input_construction(torch.LongTensor([4, 5, 6]), torch.LongTensor([[1, 2], [1, 2], [1, 2]]), U=2)\n",
    "test_negative_input_construction(torch.LongTensor([4, 5, 6]), torch.LongTensor([[1], [1], [1]]), U=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a7cb45e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7f31c898",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-06-15 05:51:41,253 - base - recpack - INFO - Processed epoch 0 in 0.04 s.Batch Training Loss = 0.5015\n",
      "2022-06-15 05:51:41,265 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.7633421038677857, which is better than previous iterations.\n",
      "2022-06-15 05:51:41,266 - base - recpack - INFO - Model improved. Storing better model.\n",
      "2022-06-15 05:51:41,269 - base - recpack - INFO - Evaluation at end of 0 took 0.02 s.\n",
      "2022-06-15 05:51:41,317 - base - recpack - INFO - Processed epoch 1 in 0.05 s.Batch Training Loss = 0.5001\n",
      "2022-06-15 05:51:41,328 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.7819889967717142, which is better than previous iterations.\n",
      "2022-06-15 05:51:41,329 - base - recpack - INFO - Model improved. Storing better model.\n",
      "2022-06-15 05:51:41,332 - base - recpack - INFO - Evaluation at end of 1 took 0.01 s.\n",
      "2022-06-15 05:51:41,380 - base - recpack - INFO - Processed epoch 2 in 0.05 s.Batch Training Loss = 0.4998\n",
      "2022-06-15 05:51:41,394 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.7908904636131339, which is better than previous iterations.\n",
      "2022-06-15 05:51:41,394 - base - recpack - INFO - Model improved. Storing better model.\n",
      "2022-06-15 05:51:41,398 - base - recpack - INFO - Evaluation at end of 2 took 0.02 s.\n",
      "2022-06-15 05:51:41,446 - base - recpack - INFO - Processed epoch 3 in 0.05 s.Batch Training Loss = 0.4977\n",
      "2022-06-15 05:51:41,458 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.7690688380178908, which is worse than previous iterations.\n",
      "2022-06-15 05:51:41,459 - base - recpack - INFO - Evaluation at end of 3 took 0.01 s.\n",
      "2022-06-15 05:51:41,504 - base - recpack - INFO - Processed epoch 4 in 0.04 s.Batch Training Loss = 0.4829\n",
      "2022-06-15 05:51:41,516 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.7690688380178909, which is worse than previous iterations.\n",
      "2022-06-15 05:51:41,516 - base - recpack - INFO - Evaluation at end of 4 took 0.01 s.\n",
      "2022-06-15 05:51:41,565 - base - recpack - INFO - Processed epoch 5 in 0.05 s.Batch Training Loss = 0.4504\n",
      "2022-06-15 05:51:41,577 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.7690688380178909, which is worse than previous iterations.\n",
      "2022-06-15 05:51:41,578 - base - recpack - INFO - Evaluation at end of 5 took 0.01 s.\n",
      "2022-06-15 05:51:41,627 - base - recpack - INFO - Processed epoch 6 in 0.05 s.Batch Training Loss = 0.4387\n",
      "2022-06-15 05:51:41,639 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.743126726921958, which is worse than previous iterations.\n",
      "2022-06-15 05:51:41,639 - base - recpack - INFO - Evaluation at end of 6 took 0.01 s.\n",
      "2022-06-15 05:51:41,691 - base - recpack - INFO - Processed epoch 7 in 0.05 s.Batch Training Loss = 0.3989\n",
      "2022-06-15 05:51:41,703 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.9545933701454672, which is better than previous iterations.\n",
      "2022-06-15 05:51:41,704 - base - recpack - INFO - Model improved. Storing better model.\n",
      "2022-06-15 05:51:41,707 - base - recpack - INFO - Evaluation at end of 7 took 0.02 s.\n",
      "2022-06-15 05:51:41,756 - base - recpack - INFO - Processed epoch 8 in 0.05 s.Batch Training Loss = 0.3235\n",
      "2022-06-15 05:51:41,768 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.9750574842557924, which is better than previous iterations.\n",
      "2022-06-15 05:51:41,769 - base - recpack - INFO - Model improved. Storing better model.\n",
      "2022-06-15 05:51:41,772 - base - recpack - INFO - Evaluation at end of 8 took 0.01 s.\n",
      "2022-06-15 05:51:41,824 - base - recpack - INFO - Processed epoch 9 in 0.05 s.Batch Training Loss = 0.3258\n",
      "2022-06-15 05:51:41,836 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.9999999999999999, which is better than previous iterations.\n",
      "2022-06-15 05:51:41,837 - base - recpack - INFO - Model improved. Storing better model.\n",
      "2022-06-15 05:51:41,840 - base - recpack - INFO - Evaluation at end of 9 took 0.02 s.\n",
      "2022-06-15 05:51:41,890 - base - recpack - INFO - Processed epoch 10 in 0.05 s.Batch Training Loss = 0.2526\n",
      "2022-06-15 05:51:41,902 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.9489044006028783, which is worse than previous iterations.\n",
      "2022-06-15 05:51:41,903 - base - recpack - INFO - Evaluation at end of 10 took 0.01 s.\n",
      "2022-06-15 05:51:41,951 - base - recpack - INFO - Processed epoch 11 in 0.05 s.Batch Training Loss = 0.1978\n",
      "2022-06-15 05:51:41,965 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.9355245321275762, which is worse than previous iterations.\n",
      "2022-06-15 05:51:41,965 - base - recpack - INFO - Evaluation at end of 11 took 0.01 s.\n",
      "2022-06-15 05:51:42,017 - base - recpack - INFO - Processed epoch 12 in 0.05 s.Batch Training Loss = 0.1661\n",
      "2022-06-15 05:51:42,030 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.9251084237866075, which is worse than previous iterations.\n",
      "2022-06-15 05:51:42,031 - base - recpack - INFO - Evaluation at end of 12 took 0.01 s.\n",
      "2022-06-15 05:51:42,079 - base - recpack - INFO - Processed epoch 13 in 0.05 s.Batch Training Loss = 0.2142\n",
      "2022-06-15 05:51:42,092 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.9866201315246979, which is worse than previous iterations.\n",
      "2022-06-15 05:51:42,092 - base - recpack - INFO - Evaluation at end of 13 took 0.01 s.\n",
      "2022-06-15 05:51:42,139 - base - recpack - INFO - Processed epoch 14 in 0.05 s.Batch Training Loss = 0.1242\n",
      "2022-06-15 05:51:42,152 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.9251084237866075, which is worse than previous iterations.\n",
      "2022-06-15 05:51:42,152 - base - recpack - INFO - Evaluation at end of 14 took 0.01 s.\n",
      "2022-06-15 05:51:42,200 - base - recpack - INFO - Processed epoch 15 in 0.05 s.Batch Training Loss = 0.0991\n",
      "2022-06-15 05:51:42,212 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.9866201315246979, which is worse than previous iterations.\n",
      "2022-06-15 05:51:42,213 - base - recpack - INFO - Evaluation at end of 15 took 0.01 s.\n",
      "2022-06-15 05:51:42,270 - base - recpack - INFO - Processed epoch 16 in 0.06 s.Batch Training Loss = 0.1188\n",
      "2022-06-15 05:51:42,282 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.9866201315246979, which is worse than previous iterations.\n",
      "2022-06-15 05:51:42,283 - base - recpack - INFO - Evaluation at end of 16 took 0.01 s.\n",
      "2022-06-15 05:51:42,333 - base - recpack - INFO - Processed epoch 17 in 0.05 s.Batch Training Loss = 0.1588\n",
      "2022-06-15 05:51:42,345 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.9489044006028784, which is worse than previous iterations.\n",
      "2022-06-15 05:51:42,345 - base - recpack - INFO - Evaluation at end of 17 took 0.01 s.\n",
      "2022-06-15 05:51:42,397 - base - recpack - INFO - Processed epoch 18 in 0.05 s.Batch Training Loss = 0.0280\n",
      "2022-06-15 05:51:42,410 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.9866201315246979, which is worse than previous iterations.\n",
      "2022-06-15 05:51:42,411 - base - recpack - INFO - Evaluation at end of 18 took 0.01 s.\n",
      "2022-06-15 05:51:42,458 - base - recpack - INFO - Processed epoch 19 in 0.05 s.Batch Training Loss = 0.0902\n",
      "2022-06-15 05:51:42,470 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.9866201315246979, which is worse than previous iterations.\n",
      "2022-06-15 05:51:42,471 - base - recpack - INFO - Evaluation at end of 19 took 0.01 s.\n",
      "2022-06-15 05:51:42,474 - base - recpack - INFO - Fitting NeuMF complete - Took 1.27s\n"
     ]
    }
   ],
   "source": [
    "def test_overfit(mat):\n",
    "    m = NeuMF(\n",
    "        num_components=10,\n",
    "        batch_size=1,\n",
    "        max_epochs=20,\n",
    "        learning_rate=0.02,\n",
    "        stopping_criterion=\"ndcg\",\n",
    "        U=1,\n",
    "    )\n",
    "\n",
    "    # set sampler to exact sampling\n",
    "    m.sampler.exact = True\n",
    "    m.fit(mat, (mat, mat))\n",
    "    bin_mat = mat.binary_values\n",
    "    pred = m.predict(mat.binary_values).toarray()\n",
    "    for user in mat.active_users:\n",
    "        # The model should have overfitted, so that the visited items have the highest similarities\n",
    "        positives = bin_mat[user].nonzero()[1]\n",
    "        negatives = list(set(range(mat.shape[1])) - set(positives))\n",
    "\n",
    "        for item in positives:\n",
    "            assert (pred[user][negatives] < pred[user, item]).all()\n",
    "            \n",
    "test_overfit(mat)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b414610",
   "metadata": {},
   "source": [
    "## Running experiment using pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f3225456",
   "metadata": {},
   "outputs": [],
   "source": [
    "from recpack.pipelines import PipelineBuilder\n",
    "from recpack.data.datasets import AdressaOneWeek, MovieLens25M\n",
    "from recpack.splitters.scenarios import WeakGeneralization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "345019f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3584dc7b71340c294b4edc4cc0bcddf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24552674 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66f3fd732cc34d5197e612322f250633",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24552674 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = MovieLens25M(\n",
    "    path='/home/robinverachtert/datasets',\n",
    ")\n",
    "data = dataset.load_interaction_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6a8be5e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(162520, 31906)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd69c256",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "47169d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subsample to 1000 users to make it faster\n",
    "# import numpy as np\n",
    "\n",
    "# users = np.random.choice(list(data.active_users), 1000)\n",
    "# data = data.users_in(users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a5a8b9ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4be0a8bdc3ec4c28a25abaddc6541d0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56d792a3baa0401a8ebf67e7966540ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scenario = WeakGeneralization(frac_data_in=0.8, validation=True)\n",
    "scenario.split(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ba6aa1bc",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'key NeuMF already registered'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[0;32mIn [39]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mrecpack\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpipelines\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ALGORITHM_REGISTRY\n\u001b[0;32m----> 2\u001b[0m \u001b[43mALGORITHM_REGISTRY\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mregister\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mNeuMF\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mNeuMF\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/dist-env/lib/python3.8/site-packages/recpack/pipelines/registries.py:66\u001b[0m, in \u001b[0;36mRegistry.register\u001b[0;34m(self, key, c)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;124;03m\"\"\"Register a new Python type (most often a class).\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \n\u001b[1;32m     58\u001b[0m \u001b[38;5;124;03mAfter registration, the key can be used to fetch the Python type from the registry.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;124;03m:type c: type\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m---> 66\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkey \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m already registered\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mregistered[key] \u001b[38;5;241m=\u001b[39m c\n",
      "\u001b[0;31mKeyError\u001b[0m: 'key NeuMF already registered'"
     ]
    }
   ],
   "source": [
    "from recpack.pipelines import ALGORITHM_REGISTRY\n",
    "ALGORITHM_REGISTRY.register('NeuMF', NeuMF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2c46caa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "builder = PipelineBuilder()\n",
    "builder.set_data_from_scenario(scenario)\n",
    "builder.set_optimisation_metric('NormalizedDiscountedCumulativeGainK', K=10)\n",
    "builder.add_metric('NormalizedDiscountedCumulativeGainK', K=10)\n",
    "builder.add_metric('CoverageK', K=10)\n",
    "\n",
    "builder.add_algorithm(\n",
    "    algorithm = 'NeuMF', \n",
    "    params = {\n",
    "        'batch_size': 128,\n",
    "        'max_epochs': 10,\n",
    "        'learning_rate': 0.01,\n",
    "        'stopping_criterion': 'ndcg',\n",
    "        'predict_topK': 20,\n",
    "        'U': 3,\n",
    "        'dropout': 0.01\n",
    "    },\n",
    "    grid = {\n",
    "        'num_components': [16, 32, 64],\n",
    "    }\n",
    ")\n",
    "\n",
    "builder.add_algorithm('Popularity', params={'K': 20})\n",
    "builder.add_algorithm('ItemKNN', grid={'similarity': ['conditional_probability', 'cosine']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "05c0a518",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = builder.build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3314c304",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0706b29894234a87afa3f13e2be1fd46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-06-15 06:35:24,819 - base - recpack - INFO - Processed epoch 0 in 494.97 s.Batch Training Loss = 34.3716\n",
      "2022-06-15 07:14:02,984 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.08098079182569473, which is better than previous iterations.\n",
      "2022-06-15 07:14:02,985 - base - recpack - INFO - Model improved. Storing better model.\n",
      "2022-06-15 07:14:03,006 - base - recpack - INFO - Evaluation at end of 0 took 2318.19 s.\n",
      "2022-06-15 07:22:18,172 - base - recpack - INFO - Processed epoch 1 in 495.16 s.Batch Training Loss = 29.6567\n",
      "2022-06-15 08:01:30,075 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.08498456229376744, which is better than previous iterations.\n",
      "2022-06-15 08:01:30,076 - base - recpack - INFO - Model improved. Storing better model.\n",
      "2022-06-15 08:01:30,100 - base - recpack - INFO - Evaluation at end of 1 took 2351.93 s.\n",
      "2022-06-15 08:09:48,116 - base - recpack - INFO - Processed epoch 2 in 498.01 s.Batch Training Loss = 28.6461\n",
      "2022-06-15 08:49:19,316 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.09197297670850743, which is better than previous iterations.\n",
      "2022-06-15 08:49:19,317 - base - recpack - INFO - Model improved. Storing better model.\n",
      "2022-06-15 08:49:19,340 - base - recpack - INFO - Evaluation at end of 2 took 2371.22 s.\n",
      "2022-06-15 08:57:38,037 - base - recpack - INFO - Processed epoch 3 in 498.69 s.Batch Training Loss = 28.0308\n",
      "2022-06-15 09:37:53,888 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.08559611504267729, which is worse than previous iterations.\n",
      "2022-06-15 09:37:53,889 - base - recpack - INFO - Evaluation at end of 3 took 2415.85 s.\n",
      "2022-06-15 09:46:05,265 - base - recpack - INFO - Processed epoch 4 in 491.37 s.Batch Training Loss = 27.5345\n",
      "2022-06-15 10:25:03,679 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.08759302877270317, which is worse than previous iterations.\n",
      "2022-06-15 10:25:03,680 - base - recpack - INFO - Evaluation at end of 4 took 2338.41 s.\n",
      "2022-06-15 10:33:16,393 - base - recpack - INFO - Processed epoch 5 in 492.71 s.Batch Training Loss = 27.1362\n",
      "2022-06-15 11:11:46,595 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.0874118213840824, which is worse than previous iterations.\n",
      "2022-06-15 11:11:46,596 - base - recpack - INFO - Evaluation at end of 5 took 2310.20 s.\n",
      "2022-06-15 11:19:53,901 - base - recpack - INFO - Processed epoch 6 in 487.30 s.Batch Training Loss = 26.8042\n",
      "2022-06-15 11:59:11,728 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.08561812185582184, which is worse than previous iterations.\n",
      "2022-06-15 11:59:11,729 - base - recpack - INFO - Evaluation at end of 6 took 2357.83 s.\n",
      "2022-06-15 12:07:26,814 - base - recpack - INFO - Processed epoch 7 in 495.08 s.Batch Training Loss = 26.5912\n",
      "2022-06-15 12:47:33,351 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.09090779227759263, which is worse than previous iterations.\n",
      "2022-06-15 12:47:33,353 - base - recpack - INFO - Evaluation at end of 7 took 2406.54 s.\n",
      "2022-06-15 12:55:46,148 - base - recpack - INFO - Processed epoch 8 in 492.79 s.Batch Training Loss = 26.3973\n",
      "2022-06-15 13:35:45,774 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.08397258749112704, which is worse than previous iterations.\n",
      "2022-06-15 13:35:45,776 - base - recpack - INFO - Evaluation at end of 8 took 2399.63 s.\n",
      "2022-06-15 13:43:57,982 - base - recpack - INFO - Processed epoch 9 in 492.20 s.Batch Training Loss = 26.2929\n",
      "2022-06-15 14:23:34,407 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.08976968933028731, which is worse than previous iterations.\n",
      "2022-06-15 14:23:34,409 - base - recpack - INFO - Evaluation at end of 9 took 2376.43 s.\n",
      "2022-06-15 14:23:34,421 - base - recpack - INFO - Fitting NeuMF complete - Took 2.86e+04s\n",
      "2022-06-15 15:13:42,030 - base - recpack - INFO - Processed epoch 0 in 679.16 s.Batch Training Loss = 34.8242\n",
      "2022-06-15 15:54:02,449 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.08084150294272156, which is better than previous iterations.\n",
      "2022-06-15 15:54:02,449 - base - recpack - INFO - Model improved. Storing better model.\n",
      "2022-06-15 15:54:02,489 - base - recpack - INFO - Evaluation at end of 0 took 2420.46 s.\n",
      "2022-06-15 16:05:23,944 - base - recpack - INFO - Processed epoch 1 in 681.45 s.Batch Training Loss = 30.8581\n",
      "2022-06-15 16:35:56,356 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.08315575480126193, which is better than previous iterations.\n",
      "2022-06-15 16:35:56,357 - base - recpack - INFO - Model improved. Storing better model.\n",
      "2022-06-15 16:35:56,400 - base - recpack - INFO - Evaluation at end of 1 took 1832.46 s.\n",
      "2022-06-15 16:47:19,309 - base - recpack - INFO - Processed epoch 2 in 682.90 s.Batch Training Loss = 31.6647\n",
      "2022-06-15 17:17:39,531 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.08496767842023471, which is better than previous iterations.\n",
      "2022-06-15 17:17:39,532 - base - recpack - INFO - Model improved. Storing better model.\n",
      "2022-06-15 17:17:39,573 - base - recpack - INFO - Evaluation at end of 2 took 1820.26 s.\n",
      "2022-06-15 17:29:01,841 - base - recpack - INFO - Processed epoch 3 in 682.26 s.Batch Training Loss = 31.5660\n",
      "2022-06-15 17:59:12,038 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.08968784738356625, which is better than previous iterations.\n",
      "2022-06-15 17:59:12,039 - base - recpack - INFO - Model improved. Storing better model.\n",
      "2022-06-15 17:59:12,083 - base - recpack - INFO - Evaluation at end of 3 took 1810.24 s.\n",
      "2022-06-15 18:10:30,675 - base - recpack - INFO - Processed epoch 4 in 678.58 s.Batch Training Loss = 32.0441\n",
      "2022-06-15 18:39:49,027 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.0855364542911806, which is worse than previous iterations.\n",
      "2022-06-15 18:39:49,029 - base - recpack - INFO - Evaluation at end of 4 took 1758.35 s.\n",
      "2022-06-15 18:51:04,234 - base - recpack - INFO - Processed epoch 5 in 675.20 s.Batch Training Loss = 41.8893\n",
      "2022-06-15 19:20:08,628 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.08509129482194867, which is worse than previous iterations.\n",
      "2022-06-15 19:20:08,629 - base - recpack - INFO - Evaluation at end of 5 took 1744.39 s.\n",
      "2022-06-15 19:31:19,002 - base - recpack - INFO - Processed epoch 6 in 670.37 s.Batch Training Loss = 32.3746\n",
      "2022-06-15 20:00:42,291 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.027030131162751485, which is worse than previous iterations.\n",
      "2022-06-15 20:00:42,293 - base - recpack - INFO - Evaluation at end of 6 took 1763.29 s.\n",
      "2022-06-15 20:11:55,715 - base - recpack - INFO - Processed epoch 7 in 673.41 s.Batch Training Loss = 34.9569\n",
      "2022-06-15 20:41:11,758 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.020750219545088277, which is worse than previous iterations.\n",
      "2022-06-15 20:41:11,760 - base - recpack - INFO - Evaluation at end of 7 took 1756.04 s.\n",
      "2022-06-15 20:52:24,313 - base - recpack - INFO - Processed epoch 8 in 672.55 s.Batch Training Loss = 36.4821\n",
      "2022-06-15 21:21:53,264 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.012300467698771009, which is worse than previous iterations.\n",
      "2022-06-15 21:21:53,266 - base - recpack - INFO - Evaluation at end of 8 took 1768.95 s.\n",
      "2022-06-15 21:33:06,922 - base - recpack - INFO - Processed epoch 9 in 673.65 s.Batch Training Loss = 40.5475\n",
      "2022-06-15 22:02:24,372 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.0128943838126462, which is worse than previous iterations.\n",
      "2022-06-15 22:02:24,374 - base - recpack - INFO - Evaluation at end of 9 took 1757.45 s.\n",
      "2022-06-15 22:02:24,393 - base - recpack - INFO - Fitting NeuMF complete - Took 2.52e+04s\n",
      "2022-06-15 22:47:50,536 - base - recpack - INFO - Processed epoch 0 in 1033.30 s.Batch Training Loss = 36.5534\n",
      "2022-06-15 23:19:32,433 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.08207414461287382, which is better than previous iterations.\n",
      "2022-06-15 23:19:32,434 - base - recpack - INFO - Model improved. Storing better model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-06-15 23:19:32,512 - base - recpack - INFO - Evaluation at end of 0 took 1901.97 s.\n",
      "2022-06-15 23:36:46,288 - base - recpack - INFO - Processed epoch 1 in 1033.77 s.Batch Training Loss = 34.8841\n",
      "2022-06-16 00:08:22,144 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.016820435356538987, which is worse than previous iterations.\n",
      "2022-06-16 00:08:22,145 - base - recpack - INFO - Evaluation at end of 1 took 1895.86 s.\n",
      "2022-06-16 00:25:33,703 - base - recpack - INFO - Processed epoch 2 in 1031.55 s.Batch Training Loss = 49.3086\n",
      "2022-06-16 00:57:12,222 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.019952507258523974, which is worse than previous iterations.\n",
      "2022-06-16 00:57:12,224 - base - recpack - INFO - Evaluation at end of 2 took 1898.52 s.\n",
      "2022-06-16 01:14:27,522 - base - recpack - INFO - Processed epoch 3 in 1035.29 s.Batch Training Loss = 43.7914\n",
      "2022-06-16 01:45:57,922 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.013950901586331336, which is worse than previous iterations.\n",
      "2022-06-16 01:45:57,923 - base - recpack - INFO - Evaluation at end of 3 took 1890.40 s.\n",
      "2022-06-16 02:03:13,035 - base - recpack - INFO - Processed epoch 4 in 1035.10 s.Batch Training Loss = 66.9058\n",
      "2022-06-16 02:34:47,315 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.010873944142251266, which is worse than previous iterations.\n",
      "2022-06-16 02:34:47,316 - base - recpack - INFO - Evaluation at end of 4 took 1894.28 s.\n",
      "2022-06-16 02:52:03,319 - base - recpack - INFO - Processed epoch 5 in 1035.99 s.Batch Training Loss = 42.2020\n",
      "2022-06-16 03:23:41,896 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.009876389680190794, which is worse than previous iterations.\n",
      "2022-06-16 03:23:41,898 - base - recpack - INFO - Evaluation at end of 5 took 1898.58 s.\n",
      "2022-06-16 03:40:58,706 - base - recpack - INFO - Processed epoch 6 in 1036.80 s.Batch Training Loss = 41.6841\n",
      "2022-06-16 04:12:34,179 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.012165661767016363, which is worse than previous iterations.\n",
      "2022-06-16 04:12:34,180 - base - recpack - INFO - Evaluation at end of 6 took 1895.47 s.\n",
      "2022-06-16 04:29:45,871 - base - recpack - INFO - Processed epoch 7 in 1031.68 s.Batch Training Loss = 40.9009\n",
      "2022-06-16 05:02:08,998 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.0071517136142810874, which is worse than previous iterations.\n",
      "2022-06-16 05:02:08,999 - base - recpack - INFO - Evaluation at end of 7 took 1943.13 s.\n",
      "2022-06-16 05:19:22,014 - base - recpack - INFO - Processed epoch 8 in 1033.01 s.Batch Training Loss = 45.5613\n",
      "2022-06-16 05:51:15,520 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.013573717408627416, which is worse than previous iterations.\n",
      "2022-06-16 05:51:15,521 - base - recpack - INFO - Evaluation at end of 8 took 1913.51 s.\n",
      "2022-06-16 06:08:27,854 - base - recpack - INFO - Processed epoch 9 in 1032.33 s.Batch Training Loss = 41.8714\n",
      "2022-06-16 06:39:49,045 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.008489497092389687, which is worse than previous iterations.\n",
      "2022-06-16 06:39:49,047 - base - recpack - INFO - Evaluation at end of 9 took 1881.19 s.\n",
      "2022-06-16 06:39:49,079 - base - recpack - INFO - Fitting NeuMF complete - Took 2.94e+04s\n",
      "2022-06-16 07:19:28,070 - base - recpack - INFO - Processed epoch 0 in 483.40 s.Batch Training Loss = 35.1290\n",
      "2022-06-16 07:58:15,199 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.034901703510858084, which is better than previous iterations.\n",
      "2022-06-16 07:58:15,200 - base - recpack - INFO - Model improved. Storing better model.\n",
      "2022-06-16 07:58:15,221 - base - recpack - INFO - Evaluation at end of 0 took 2327.15 s.\n",
      "2022-06-16 08:06:22,251 - base - recpack - INFO - Processed epoch 1 in 487.02 s.Batch Training Loss = 30.3454\n",
      "2022-06-16 08:45:05,813 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.03205059813936343, which is worse than previous iterations.\n",
      "2022-06-16 08:45:05,815 - base - recpack - INFO - Evaluation at end of 1 took 2323.56 s.\n",
      "2022-06-16 08:53:15,278 - base - recpack - INFO - Processed epoch 2 in 489.46 s.Batch Training Loss = 29.1253\n",
      "2022-06-16 09:32:18,997 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.030603384690768374, which is worse than previous iterations.\n",
      "2022-06-16 09:32:18,998 - base - recpack - INFO - Evaluation at end of 2 took 2343.72 s.\n",
      "2022-06-16 09:40:28,420 - base - recpack - INFO - Processed epoch 3 in 489.41 s.Batch Training Loss = 28.4542\n",
      "2022-06-16 10:19:42,862 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.031809037429649176, which is worse than previous iterations.\n",
      "2022-06-16 10:19:42,864 - base - recpack - INFO - Evaluation at end of 3 took 2354.44 s.\n",
      "2022-06-16 10:27:51,606 - base - recpack - INFO - Processed epoch 4 in 488.73 s.Batch Training Loss = 28.0836\n",
      "2022-06-16 11:06:03,599 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.026874878989349225, which is worse than previous iterations.\n",
      "2022-06-16 11:06:03,600 - base - recpack - INFO - Evaluation at end of 4 took 2291.99 s.\n",
      "2022-06-16 11:14:08,516 - base - recpack - INFO - Processed epoch 5 in 484.91 s.Batch Training Loss = 27.7254\n",
      "2022-06-16 11:53:00,221 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.026679740427533398, which is worse than previous iterations.\n",
      "2022-06-16 11:53:00,223 - base - recpack - INFO - Evaluation at end of 5 took 2331.71 s.\n",
      "2022-06-16 12:01:12,617 - base - recpack - INFO - Processed epoch 6 in 492.39 s.Batch Training Loss = 27.4668\n",
      "2022-06-16 12:38:56,334 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.028190025391976795, which is worse than previous iterations.\n",
      "2022-06-16 12:38:56,336 - base - recpack - INFO - Evaluation at end of 6 took 2263.72 s.\n",
      "2022-06-16 12:46:53,481 - base - recpack - INFO - Processed epoch 7 in 477.14 s.Batch Training Loss = 27.2134\n",
      "2022-06-16 13:24:31,906 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.02698406660372085, which is worse than previous iterations.\n",
      "2022-06-16 13:24:31,907 - base - recpack - INFO - Evaluation at end of 7 took 2258.43 s.\n",
      "2022-06-16 13:32:34,363 - base - recpack - INFO - Processed epoch 8 in 482.45 s.Batch Training Loss = 27.0140\n",
      "2022-06-16 14:10:28,524 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.029020783139315873, which is worse than previous iterations.\n",
      "2022-06-16 14:10:28,526 - base - recpack - INFO - Evaluation at end of 8 took 2274.16 s.\n",
      "2022-06-16 14:18:32,604 - base - recpack - INFO - Processed epoch 9 in 484.07 s.Batch Training Loss = 26.8622\n",
      "2022-06-16 14:56:16,971 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.02755323275195566, which is worse than previous iterations.\n",
      "2022-06-16 14:56:16,973 - base - recpack - INFO - Evaluation at end of 9 took 2264.37 s.\n",
      "2022-06-16 14:56:16,986 - base - recpack - INFO - Fitting NeuMF complete - Took 2.79e+04s\n",
      "2022-06-16 15:33:52,402 - base - recpack - INFO - Fitting Popularity complete - Took 5.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/robinverachtert/dist-env/lib/python3.8/site-packages/scipy/sparse/_index.py:146: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_arrayXarray(i, j, x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-06-16 15:35:19,657 - base - recpack - INFO - Fitting ItemKNN complete - Took 75.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/robinverachtert/dist-env/lib/python3.8/site-packages/recpack/algorithms/base.py:274: UserWarning: ItemKNN missing similar items for 1 items.\n",
      "  warnings.warn(f\"{self.name} missing similar items for {missing} items.\")\n",
      "/home/robinverachtert/dist-env/lib/python3.8/site-packages/scipy/sparse/_index.py:146: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_arrayXarray(i, j, x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-06-16 15:36:40,274 - base - recpack - INFO - Fitting ItemKNN complete - Took 55.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/robinverachtert/dist-env/lib/python3.8/site-packages/recpack/algorithms/base.py:274: UserWarning: ItemKNN missing similar items for 1 items.\n",
      "  warnings.warn(f\"{self.name} missing similar items for {missing} items.\")\n",
      "/home/robinverachtert/dist-env/lib/python3.8/site-packages/scipy/sparse/_index.py:146: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_arrayXarray(i, j, x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-06-16 15:38:30,229 - base - recpack - INFO - Fitting ItemKNN complete - Took 56.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/robinverachtert/dist-env/lib/python3.8/site-packages/recpack/algorithms/base.py:274: UserWarning: ItemKNN missing similar items for 1 items.\n",
      "  warnings.warn(f\"{self.name} missing similar items for {missing} items.\")\n"
     ]
    }
   ],
   "source": [
    "pipeline.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8af63fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3a36b1d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>normalizeddiscountedcumulativegaink_10</th>\n",
       "      <th>coveragek_10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NeuMF(U=3,batch_size=128,dropout=0.01,exact_sampling=False,keep_last=False,learning_rate=0.01,max_epochs=10,max_iter_no_change=5,min_improvement=0.0,num_components=16,predict_topK=20,save_best_to_file=False,seed=2404017312,stop_early=False,stopping_criterion=&lt;recpack.algorithms.stopping_criterion.StoppingCriterion object at 0x7fa205cd3c40&gt;)</th>\n",
       "      <td>0.045246</td>\n",
       "      <td>0.038300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Popularity(K=20)</th>\n",
       "      <td>0.094183</td>\n",
       "      <td>0.000313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ItemKNN(K=200,normalize=False,normalize_X=False,normalize_sim=False,pop_discount=None,similarity=cosine)</th>\n",
       "      <td>0.153369</td>\n",
       "      <td>0.083840</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    normalizeddiscountedcumulativegaink_10  coveragek_10\n",
       "NeuMF(U=3,batch_size=128,dropout=0.01,exact_sam...                                0.045246      0.038300\n",
       "Popularity(K=20)                                                                  0.094183      0.000313\n",
       "ItemKNN(K=200,normalize=False,normalize_X=False...                                0.153369      0.083840"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame.from_dict(pipeline.get_metrics()).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "720b3479",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cbe6c68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a929f25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f6424f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa99149",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c6391a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4211ea3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b84adbb2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e51fe3f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bcc4d5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db3b2d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "7da6e734",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
