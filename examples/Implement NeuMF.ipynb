{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "85c37828",
      "metadata": {
        "slideshow": {
          "slide_type": "skip"
        }
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pytest\n",
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "from typing import Callable, List, Optional, Union"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c196de69",
      "metadata": {
        "slideshow": {
          "slide_type": "slide"
        }
      },
      "source": [
        "### Implementing MLP network\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "743b93a9",
      "metadata": {
        "slideshow": {
          "slide_type": "skip"
        }
      },
      "outputs": [],
      "source": [
        "class MLP(nn.Module):\n",
        "    \"\"\"A multi-layer perceptron module.\n",
        "    This module is a sequence of linear layers plus activation functions.\n",
        "    The user can optionally add normalization and/or dropout to each of the layers.\n",
        "    \n",
        "    Code used from https://github.com/facebookresearch/multimodal/blob/5dec8a/torchmultimodal/modules/layers/mlp.py\n",
        "    \n",
        "    :param in_dim: Input dimension.\n",
        "    :type in_dim: int\n",
        "    :param out_dim: Output dimension.\n",
        "    :type out_dim: int\n",
        "    :param hidden_dims: Output dimension for each hidden layer.\n",
        "    :type hidden_dims: Optional[Union[int, List[int]]] \n",
        "    :param dropout: Probability for dropout layers between each hidden layer.\n",
        "    :type dropout: float\n",
        "    :param activation: Which activation function to use. \n",
        "        Supports module type or partial.\n",
        "    :type activation: Callable[..., nn.Module]\n",
        "    \"\"\"\n",
        "    def __init__(\n",
        "        self, \n",
        "        in_dim: int, \n",
        "        out_dim: int,\n",
        "        hidden_dims: Optional[Union[int, List[int]]] = None,\n",
        "        dropout: float = 0.5,\n",
        "        activation: Callable[..., nn.Module] = nn.ReLU,\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "        layers = nn.ModuleList()\n",
        "\n",
        "        if hidden_dims is None:\n",
        "            hidden_dims = []\n",
        "\n",
        "        if isinstance(hidden_dims, int):\n",
        "            hidden_dims = [hidden_dims]\n",
        "\n",
        "        for hidden_dim in hidden_dims:\n",
        "            layers.append(nn.Linear(in_dim, hidden_dim))\n",
        "            layers.append(activation())\n",
        "            layers.append(nn.Dropout(dropout))\n",
        "            in_dim = hidden_dim\n",
        "        layers.append(nn.Linear(in_dim, out_dim))\n",
        "        self.model = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        return self.model(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "83fcd62d",
      "metadata": {
        "slideshow": {
          "slide_type": "skip"
        }
      },
      "outputs": [],
      "source": [
        "EMBEDDING_SIZE = 3\n",
        "N_USERS = 5\n",
        "N_ITEMS = 10\n",
        "a = MLP(2*EMBEDDING_SIZE, N_ITEMS, [6, 4, 2], dropout=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cea26454",
      "metadata": {
        "slideshow": {
          "slide_type": "slide"
        }
      },
      "source": [
        "## Implementing the Neural Architecture\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "34a78b55",
      "metadata": {
        "slideshow": {
          "slide_type": "skip"
        }
      },
      "outputs": [],
      "source": [
        "class NMFModule(nn.Module):\n",
        "    \"\"\"Model that encodes the Neural Matrix Factorization Network.\n",
        "    \n",
        "    Implements the 3 tiered network defined in the He et al. paper.\n",
        "\n",
        "    :param predictive_powers: size of the last hidden layer in MLP.\n",
        "        Embedding sizes computed as 2 * predictive powers.\n",
        "    :type predictive_powers: int\n",
        "    :param n_users: number of users in the network\n",
        "    :type n_users: int\n",
        "    :param n_items: number of items in the network\n",
        "    :type n_items: int\n",
        "    :param hidden_dims: dimensions of the MLP hidden layers.\n",
        "    :type hidden_dims: Union[int, List[int]]\n",
        "    :param dropout: Dropout chance between layers of the MLP\n",
        "    :type dropout: float\n",
        "    \"\"\"\n",
        "    def __init__(\n",
        "        self, predictive_powers: int, n_users: int, n_items: int, dropout: float\n",
        "    ):\n",
        "        super().__init__()\n",
        "        num_components = 2 * predictive_powers\n",
        "        \n",
        "        self.user_embedding = nn.Embedding(n_users, num_components)\n",
        "        self.item_embedding = nn.Embedding(n_items, num_components)\n",
        "\n",
        "        # we use a three tiered MLP as described in the experiments of the paper.\n",
        "        hidden_dims = [\n",
        "            4 * predictive_powers, \n",
        "            2 * predictive_powers, \n",
        "            predictive_powers\n",
        "        ]\n",
        "\n",
        "        # Output is always 1, since we need a single score for u,i\n",
        "        self.mlp = MLP(4 * predictive_powers, 1, \n",
        "                       hidden_dims, dropout=dropout)\n",
        "\n",
        "        self.final = nn.Sigmoid()\n",
        "\n",
        "        # weight initialization\n",
        "        self.user_embedding.weight.data.normal_(0, \n",
        "            1.0 / self.user_embedding.embedding_dim)\n",
        "        self.item_embedding.weight.data.normal_(0, \n",
        "            1.0 / self.item_embedding.embedding_dim)\n",
        "        \n",
        "    def forward(self, users: torch.LongTensor, items: torch.LongTensor) -> torch.FloatTensor:\n",
        "        \"\"\"Predict scores for the user item pairs obtained \n",
        "        by zipping together the two inputs\n",
        "\n",
        "        :param users: 1D tensor with user ids\n",
        "        :type users: torch.LongTensor\n",
        "        :param items: 1D tensor with item ids\n",
        "        :type items: torch.LongTensor\n",
        "        :return: 1D tensor with predicted similarities.\n",
        "            Position i is the similarity between \n",
        "            `users[i]` and `items[i]`\n",
        "        :rtype: torch.FloatTensor\n",
        "        \"\"\"\n",
        "\n",
        "        # Embedding lookups\n",
        "        user_emb = self.user_embedding(users)\n",
        "        item_emb = self.item_embedding(items)\n",
        "\n",
        "        # Pass concatenated through MLP and apply sigmoid\n",
        "        return self.final(\n",
        "            self.mlp(\n",
        "                torch.hstack([user_emb, item_emb])\n",
        "            )\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "b8bcb491",
      "metadata": {
        "slideshow": {
          "slide_type": "skip"
        }
      },
      "outputs": [],
      "source": [
        "def test_output_shapes_NMF(\n",
        "    predictive_factors, num_users, num_items\n",
        "):\n",
        "    \"\"\"Check that no mather the inner settings of the network, the output is always correct\"\"\"\n",
        "    mod = NMFModule(predictive_factors, num_users, num_items, 0.0)\n",
        "    \n",
        "    user_tensor = torch.LongTensor([1, 2])\n",
        "    item_tensor = torch.LongTensor([1, 2])\n",
        "    \n",
        "    res = mod(user_tensor, item_tensor) # predict scores for items given the users\n",
        "    \n",
        "    assert res.shape == (2, 1)\n",
        "\n",
        "    assert (res.detach().numpy() <= 1).all()\n",
        "    assert (res.detach().numpy() >= 0).all()\n",
        "\n",
        "\n",
        "test_output_shapes_NMF(5, 10, 10)\n",
        "test_output_shapes_NMF(5, 3, 10)\n",
        "test_output_shapes_NMF(1, 3, 3)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "3c07d570",
      "metadata": {
        "slideshow": {
          "slide_type": "skip"
        }
      },
      "outputs": [],
      "source": [
        "from typing import List, Union, Optional\n",
        "\n",
        "import pandas as pd\n",
        "from recpack.algorithms.base import TorchMLAlgorithm\n",
        "from recpack.algorithms.samplers import PositiveNegativeSampler\n",
        "from recpack.algorithms.util import get_users\n",
        "from recpack.matrix import InteractionMatrix\n",
        "from scipy.sparse import csr_matrix, lil_matrix\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "217f8d30",
      "metadata": {
        "slideshow": {
          "slide_type": "slide"
        }
      },
      "source": [
        "## Implementing the algorithm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "e359a201",
      "metadata": {
        "slideshow": {
          "slide_type": "skip"
        }
      },
      "outputs": [],
      "source": [
        "class NeuMF(TorchMLAlgorithm):\n",
        "    \"\"\"Implementation of Neural Matrix Factoration.\n",
        "\n",
        "    Neural Matrix Factorization based on MLP architecture\n",
        "    as presented in Figure 2 in He, Xiangnan, et al. \n",
        "    \"Neural collaborative filtering.\"\n",
        "    In Proceedings of the 26th international conference on world wide web. 2017.\n",
        "\n",
        "    Represents the users and items using an embedding, \n",
        "    similarity between the two is modelled using a neural network.\n",
        "\n",
        "    The network consists of an embedding for both users and items.\n",
        "    To compute similarity those two embeddings are \n",
        "    concatenated and passed through the MLP\n",
        "    Finally the similarity is transformed to the [0,1] domain\n",
        "    using a sigmoid function.\n",
        "\n",
        "    As in the paper, the sum of square errors is used as loss function.\n",
        "    Positive items should get a prediction close to 1, \n",
        "    while sampled negatives should get a value close to 0.\n",
        "\n",
        "    The MLP has 3 layers, as suggested in the experiments section.\n",
        "    Bottom layer has dimension `4 * predictive_powers`, \n",
        "    middle layer `2 * predictive_powers`\n",
        "    and the top layer has `predictive_powers`.\n",
        "\n",
        "    :param predictive_powers: Size of the last hidden layer in the MLP network.\n",
        "        Embedding size is 2 * predictive_powers\n",
        "    :type predictive_powers: int\n",
        "    :param batch_size: How many samples to use in each update step.\n",
        "        Higher batch sizes make each epoch more efficient,\n",
        "        but increases the amount of epochs needed to converge to the optimum,\n",
        "        by reducing the amount of updates per epoch.\n",
        "        Defaults to 512.\n",
        "    :type batch_size: Optional[int]\n",
        "    :param max_epochs: The max number of epochs to train.\n",
        "        If the stopping criterion uses early stopping, less epochs could be used.\n",
        "        Defaults to 10.\n",
        "    :type max_epochs: Optional[int]\n",
        "    :param learning_rate: How much to update the weights at each update. Defaults to 0.01\n",
        "    :type learning_rate: Optional[float]\n",
        "    :param stopping_criterion: Name of the stopping criterion to use for training.\n",
        "        For available values,\n",
        "        check :meth:`recpack.algorithms.stopping_criterion.StoppingCriterion.FUNCTIONS`\n",
        "        Defaults to 'ndcg'\n",
        "    :type stopping_criterion: Optional[str]\n",
        "    :param stop_early: If True, early stopping is enabled,\n",
        "        and after ``max_iter_no_change`` iterations where improvement of loss function\n",
        "        is below ``min_improvement`` the optimisation is stopped,\n",
        "        even if max_epochs is not reached.\n",
        "        Defaults to False\n",
        "    :type stop_early: bool, optional\n",
        "    :param max_iter_no_change: If early stopping is enabled,\n",
        "        stop after this amount of iterations without change.\n",
        "        Defaults to 5\n",
        "    :type max_iter_no_change: int, optional\n",
        "    :param min_improvement: If early stopping is enabled, no change is detected,\n",
        "        if the improvement is below this value.\n",
        "        Defaults to 0.01\n",
        "    :type min_improvement: float, optional\n",
        "    :param seed: Seed to the randomizers, useful for reproducible results,\n",
        "        defaults to None\n",
        "    :type seed: int, optional\n",
        "    :param save_best_to_file: If true, the best model will be saved after training,\n",
        "        defaults to False\n",
        "    :type save_best_to_file: bool, optional\n",
        "    :param keep_last: Retain last model, rather than best\n",
        "        (according to stopping criterion value on validation data), defaults to False\n",
        "    :type keep_last: bool, optional\n",
        "    :param predict_topK: The topK recommendations to keep per row in the matrix.\n",
        "        Use when the user x item output matrix would become too large for RAM.\n",
        "        Defaults to None, which results in no filtering.\n",
        "    :type predict_topK: int, optional\n",
        "    :param n_negatives_per_positive: Amount of negatives to sample for each positive example, defaults to 1\n",
        "    :type n_negatives_per_positive: int, optional\n",
        "    :param dropout: Dropout parameter used in MLP, defaults to 0.0\n",
        "    :type dropout: float, optional\n",
        "    :param exact_sampling: Enable or disable exact checks while sampling. \n",
        "        With exact sampling the sampled negatives are guaranteed to not have been visited by the user. \n",
        "        Non exact sampling assumes that the space for item selection is large enough, \n",
        "        such that most items are likely not seen before.\n",
        "        Defaults to False,\n",
        "    :type exact_sampling: bool, optional\n",
        "    \"\"\"\n",
        "    def __init__(\n",
        "        self,\n",
        "        predictive_factors: int,\n",
        "        batch_size: Optional[int] = 512,\n",
        "        max_epochs: Optional[int] = 10,\n",
        "        learning_rate: Optional[float] = 0.01,\n",
        "        stopping_criterion: Optional[str] = \"ndcg\",\n",
        "        stop_early: Optional[bool] = False,\n",
        "        max_iter_no_change: Optional[int] = 5,\n",
        "        min_improvement: Optional[float] = 0.0,\n",
        "        seed: Optional[int] = None,\n",
        "        save_best_to_file: Optional[bool] = False,\n",
        "        keep_last: Optional[bool] = False,\n",
        "        predict_topK: Optional[int] = None,\n",
        "        n_negatives_per_positive: Optional[int] = 1,\n",
        "        exact_sampling: Optional[bool] = False,\n",
        "        dropout: Optional[float] = 0.0,\n",
        "    ):\n",
        "        print(batch_size, max_epochs, learning_rate, stopping_criterion)\n",
        "        super().__init__(batch_size, max_epochs, learning_rate,\n",
        "            stopping_criterion, stop_early, max_iter_no_change,\n",
        "            min_improvement, seed, save_best_to_file, keep_last,\n",
        "            predict_topK,\n",
        "        )\n",
        "\n",
        "        self.predictive_factors = predictive_factors\n",
        "\n",
        "        self.n_negatives_per_positive = n_negatives_per_positive\n",
        "        self.dropout = dropout\n",
        "        self.exact_sampling = exact_sampling\n",
        "\n",
        "        self.sampler = PositiveNegativeSampler(\n",
        "            U=self.n_negatives_per_positive, replace=False, exact=exact_sampling, \n",
        "            batch_size=self.batch_size\n",
        "        )\n",
        "\n",
        "    def _init_model(self, X: csr_matrix):\n",
        "        num_users, num_items = X.shape\n",
        "        self.model_ = NMFModule(\n",
        "            self.predictive_factors, num_users, num_items, self.dropout\n",
        "        ).to(self.device)\n",
        "\n",
        "        self.optimizer = torch.optim.Adam(\n",
        "            self.model_.parameters(), lr=self.learning_rate\n",
        "        )\n",
        "        \n",
        "    def _train_epoch(self, X: csr_matrix) -> List[int]:\n",
        "        losses = []\n",
        "        for users, positives, negatives in self.sampler.sample(X):\n",
        "\n",
        "            self.optimizer.zero_grad()\n",
        "\n",
        "            # Predict for the positives\n",
        "            positive_scores = self.model_(\n",
        "                users.to(self.device), positives.to(self.device))\n",
        "            # Predict for the negatives\n",
        "            negative_scores = self.model_(\n",
        "                *self._construct_negative_prediction_input(\n",
        "                    users.to(self.device), negatives.to(self.device))\n",
        "            )\n",
        "\n",
        "            loss = self._compute_loss(\n",
        "                positive_scores, negative_scores)\n",
        "\n",
        "            # Backwards propagation of the loss\n",
        "            loss.backward()\n",
        "            self.optimizer.step()\n",
        "\n",
        "            losses.append(loss.item())\n",
        "\n",
        "        return losses\n",
        "\n",
        "    def _compute_loss(\n",
        "        self, positive_scores: torch.FloatTensor, negative_scores: torch.FloatTensor\n",
        "    ) -> torch.FloatTensor:\n",
        "        \"\"\"Compute the Square Error loss given recommendations \n",
        "        for positive items, and sampled negatives.\n",
        "        \"\"\"\n",
        "\n",
        "        mse = nn.MSELoss(reduction=\"sum\")\n",
        "        return mse(positive_scores, torch.ones_like(positive_scores, dtype=torch.float)) + mse(\n",
        "            negative_scores, torch.zeros_like(negative_scores, dtype=torch.float)\n",
        "        )\n",
        "\n",
        "    def _construct_negative_prediction_input(self, users, negatives):\n",
        "        \"\"\"Construct the prediction input given a 1D user tensor and a 2D negatives tensor.\n",
        "        \n",
        "        Since negatives has shape |batch| x U, and users is a 1d vector,\n",
        "        these need to be turned into two 1D vectors of shape |batch| * U\n",
        "\n",
        "        First the users as a row are stacked U times and transposed,\n",
        "        so that this is also a batch x U tensor.\n",
        "        Then both are reshaped to remove the 2nd dimension, \n",
        "        resulting in a single long 1d vector.\n",
        "        \"\"\"\n",
        "        return (\n",
        "            users.repeat(self.n_negatives_per_positive, 1).T.reshape(-1), \n",
        "            negatives.reshape(-1)\n",
        "        )\n",
        "    \n",
        "    def _batch_predict(\n",
        "        self, X: csr_matrix, users: List[int]\n",
        "    ) -> csr_matrix:\n",
        "        \"\"\"Generate recommendations for each of the users.\"\"\"\n",
        "\n",
        "        X_pred = lil_matrix(X.shape)\n",
        "        if users is None:\n",
        "            users = get_users(X)\n",
        "\n",
        "        _, n_items = X.shape\n",
        "        n_users = len(users)\n",
        "\n",
        "        # Create tensors such that each user, item pair gets a score.\n",
        "        # The user tensor contains the users in order \n",
        "        # (eg. [1, 1, 2, 2]), \n",
        "        # item indices are repeated (eg. [0, 1, 2, 0, 1, 2]).\n",
        "        user_tensor = torch.LongTensor(users).repeat(\n",
        "            n_items, 1).T.reshape(-1).to(self.device)\n",
        "        item_tensor = torch.arange(n_items).repeat(\n",
        "            n_users).to(self.device)\n",
        "\n",
        "        X_pred[users] = self.model_(\n",
        "            user_tensor, item_tensor\n",
        "        ).detach().cpu().numpy().reshape(n_users, n_items)\n",
        "        return X_pred.tocsr()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "9ca8f574",
      "metadata": {
        "slideshow": {
          "slide_type": "skip"
        }
      },
      "outputs": [],
      "source": [
        "TIMESTAMP_IX = 'ts'\n",
        "ITEM_IX = 'iid'\n",
        "USER_IX = 'uid'\n",
        "\n",
        "data = {\n",
        "    TIMESTAMP_IX: [3, 2, 1, 4, 0, 1, 2, 4, 0, 1, 2],\n",
        "    ITEM_IX: [0, 1, 2, 3, 0, 1, 2, 4, 0, 1, 2],\n",
        "    USER_IX: [0, 0, 1, 1, 2, 2, 3, 3, 4, 4, 5],\n",
        "}\n",
        "df = pd.DataFrame.from_dict(data)\n",
        "\n",
        "mat = InteractionMatrix(df, ITEM_IX, USER_IX, timestamp_ix=TIMESTAMP_IX)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ed4d2e7d",
      "metadata": {
        "slideshow": {
          "slide_type": "skip"
        }
      },
      "outputs": [],
      "source": [
        "def test_negative_input_construction(users, negatives, U):\n",
        "    \n",
        "    a = NeuMF(\n",
        "        predictive_factors=8, \n",
        "        n_negatives_per_positive=U\n",
        "    )\n",
        "    \n",
        "    num_users = users.shape[0]\n",
        "    users_input, negatives_input = a._construct_negative_prediction_input(users, negatives)\n",
        "    assert users_input.shape == negatives_input.shape\n",
        "    assert len(users_input.shape) == 1 # 1d vectors\n",
        "    \n",
        "    # Check that both are in the right order (each user is repeated U times before the next user is present)\n",
        "    for ix in range(users_input.shape[0]):\n",
        "        assert users_input[ix] == users[ix // U]\n",
        "        assert negatives_input[ix] == negatives[ix // U, ix % U]\n",
        "\n",
        "test_negative_input_construction(torch.LongTensor([4, 5, 6]), torch.LongTensor([[1, 2], [1, 2], [1, 2]]), U=2)\n",
        "test_negative_input_construction(torch.LongTensor([4, 5, 6]), torch.LongTensor([[1], [1], [1]]), U=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7f31c898",
      "metadata": {
        "scrolled": true,
        "slideshow": {
          "slide_type": "skip"
        }
      },
      "outputs": [],
      "source": [
        "def test_overfit(mat):\n",
        "    m = NeuMF(\n",
        "        predictive_factors=5,\n",
        "        batch_size=1,\n",
        "        max_epochs=20,\n",
        "        learning_rate=0.02,\n",
        "        stopping_criterion=\"ndcg\",\n",
        "        n_negatives_per_positive=1,\n",
        "    )\n",
        "\n",
        "    # set sampler to exact sampling\n",
        "    m.sampler.exact = True\n",
        "    m.fit(mat, (mat, mat))\n",
        "    bin_mat = mat.binary_values\n",
        "    pred = m.predict(mat.binary_values).toarray()\n",
        "    for user in mat.active_users:\n",
        "        # The model should have overfitted, so that the visited items have the highest similarities\n",
        "        positives = bin_mat[user].nonzero()[1]\n",
        "        negatives = list(set(range(mat.shape[1])) - set(positives))\n",
        "\n",
        "        for item in positives:\n",
        "            assert (pred[user][negatives] < pred[user, item]).all()\n",
        "            \n",
        "test_overfit(mat)\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4b414610",
      "metadata": {
        "slideshow": {
          "slide_type": "slide"
        }
      },
      "source": [
        "## Experiment\n",
        "\n",
        "Use RecPack Pipeline to compare the newly implemented algorithm to frequently used baselines"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "f3225456",
      "metadata": {
        "slideshow": {
          "slide_type": "subslide"
        }
      },
      "outputs": [],
      "source": [
        "from recpack.pipelines import PipelineBuilder\n",
        "from recpack.datasets import MovieLens25M\n",
        "from recpack.scenarios import WeakGeneralization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "8bb256ed",
      "metadata": {
        "slideshow": {
          "slide_type": "skip"
        }
      },
      "outputs": [],
      "source": [
        "DATASET_PATH = '/home/robinverachtert/datasets'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "345019f0",
      "metadata": {
        "slideshow": {
          "slide_type": "subslide"
        }
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3033eee191d045018bf39779783828d8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/12415224 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "671980f87d224e52b62fc06ac2cf92ab",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/12415224 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "dataset = MovieLens25M(\n",
        "    path=DATASET_PATH\n",
        ")\n",
        "data = dataset.load()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "47169d75",
      "metadata": {
        "slideshow": {
          "slide_type": "skip"
        }
      },
      "outputs": [],
      "source": [
        "# Subsample to 1000 users to make it faster\n",
        "# import numpy as np\n",
        "\n",
        "# users = np.random.choice(list(data.active_users), 1000)\n",
        "# data = data.users_in(users)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "a5a8b9ab",
      "metadata": {
        "slideshow": {
          "slide_type": "subslide"
        }
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "76f6d490111d4d92ad3ab20993048f27",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c3c6a2d3120a498985f05b2ae3fd6fdc",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "scenario = WeakGeneralization(frac_data_in=0.8, validation=True)\n",
        "scenario.split(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "ba6aa1bc",
      "metadata": {
        "slideshow": {
          "slide_type": "subslide"
        }
      },
      "outputs": [],
      "source": [
        "from recpack.pipelines import ALGORITHM_REGISTRY\n",
        "ALGORITHM_REGISTRY.register('NeuMF', NeuMF)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "2c46caa2",
      "metadata": {
        "slideshow": {
          "slide_type": "subslide"
        }
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0da9d6248145485fa5aed4180e0676ec",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/3 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-07-01 16:02:50,165 - base - recpack - INFO - Processed epoch 0 in 228.77 s.Batch Training Loss = 43.9709\n",
            "2022-07-01 16:31:45,497 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.13242382393503446, which is better than previous iterations.\n",
            "2022-07-01 16:31:45,498 - base - recpack - INFO - Model improved. Storing better model.\n",
            "2022-07-01 16:31:45,518 - base - recpack - INFO - Evaluation at end of 0 took 1735.35 s.\n",
            "2022-07-01 16:35:34,852 - base - recpack - INFO - Processed epoch 1 in 229.33 s.Batch Training Loss = 36.0092\n",
            "2022-07-01 17:05:18,048 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.14472784895769647, which is better than previous iterations.\n",
            "2022-07-01 17:05:18,049 - base - recpack - INFO - Model improved. Storing better model.\n",
            "2022-07-01 17:05:18,070 - base - recpack - INFO - Evaluation at end of 1 took 1783.22 s.\n",
            "2022-07-01 17:09:10,961 - base - recpack - INFO - Processed epoch 2 in 232.89 s.Batch Training Loss = 33.9820\n",
            "2022-07-01 17:39:32,106 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.15259597866638144, which is better than previous iterations.\n",
            "2022-07-01 17:39:32,107 - base - recpack - INFO - Model improved. Storing better model.\n",
            "2022-07-01 17:39:32,129 - base - recpack - INFO - Evaluation at end of 2 took 1821.17 s.\n",
            "2022-07-01 17:43:26,066 - base - recpack - INFO - Processed epoch 3 in 233.93 s.Batch Training Loss = 32.4562\n",
            "2022-07-01 18:14:02,382 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.15896122882142133, which is better than previous iterations.\n",
            "2022-07-01 18:14:02,383 - base - recpack - INFO - Model improved. Storing better model.\n",
            "2022-07-01 18:14:02,405 - base - recpack - INFO - Evaluation at end of 3 took 1836.34 s.\n",
            "2022-07-01 18:17:56,201 - base - recpack - INFO - Processed epoch 4 in 233.79 s.Batch Training Loss = 31.5039\n",
            "2022-07-01 18:47:01,825 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.16187348644886707, which is better than previous iterations.\n",
            "2022-07-01 18:47:01,826 - base - recpack - INFO - Model improved. Storing better model.\n",
            "2022-07-01 18:47:01,848 - base - recpack - INFO - Evaluation at end of 4 took 1745.65 s.\n",
            "2022-07-01 18:50:50,033 - base - recpack - INFO - Processed epoch 5 in 228.18 s.Batch Training Loss = 30.9173\n",
            "2022-07-01 19:19:43,218 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.1625257974141069, which is better than previous iterations.\n",
            "2022-07-01 19:19:43,219 - base - recpack - INFO - Model improved. Storing better model.\n",
            "2022-07-01 19:19:43,240 - base - recpack - INFO - Evaluation at end of 5 took 1733.21 s.\n",
            "2022-07-01 19:23:29,586 - base - recpack - INFO - Processed epoch 6 in 226.34 s.Batch Training Loss = 30.4453\n",
            "2022-07-01 19:52:22,509 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.1640332321804022, which is better than previous iterations.\n",
            "2022-07-01 19:52:22,510 - base - recpack - INFO - Model improved. Storing better model.\n",
            "2022-07-01 19:52:22,530 - base - recpack - INFO - Evaluation at end of 6 took 1732.94 s.\n",
            "2022-07-01 19:56:10,088 - base - recpack - INFO - Processed epoch 7 in 227.55 s.Batch Training Loss = 30.0698\n",
            "2022-07-01 20:26:37,842 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.16669054872242786, which is better than previous iterations.\n",
            "2022-07-01 20:26:37,843 - base - recpack - INFO - Model improved. Storing better model.\n",
            "2022-07-01 20:26:37,865 - base - recpack - INFO - Evaluation at end of 7 took 1827.78 s.\n",
            "2022-07-01 20:30:32,443 - base - recpack - INFO - Processed epoch 8 in 234.57 s.Batch Training Loss = 29.7743\n",
            "2022-07-01 21:01:25,079 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.16872641335717006, which is better than previous iterations.\n",
            "2022-07-01 21:01:25,080 - base - recpack - INFO - Model improved. Storing better model.\n",
            "2022-07-01 21:01:25,101 - base - recpack - INFO - Evaluation at end of 8 took 1852.66 s.\n",
            "2022-07-01 21:05:17,253 - base - recpack - INFO - Processed epoch 9 in 232.15 s.Batch Training Loss = 29.4650\n",
            "2022-07-01 21:35:38,915 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.17024539162603164, which is better than previous iterations.\n",
            "2022-07-01 21:35:38,916 - base - recpack - INFO - Model improved. Storing better model.\n",
            "2022-07-01 21:35:38,938 - base - recpack - INFO - Evaluation at end of 9 took 1821.68 s.\n",
            "2022-07-01 21:35:38,948 - base - recpack - INFO - Fitting NeuMFMLPOnly complete - Took 2.02e+04s\n",
            "2022-07-01 22:10:54,477 - base - recpack - INFO - Processed epoch 0 in 311.61 s.Batch Training Loss = 41.7896\n",
            "2022-07-01 22:40:11,888 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.14053704662823363, which is better than previous iterations.\n",
            "2022-07-01 22:40:11,889 - base - recpack - INFO - Model improved. Storing better model.\n",
            "2022-07-01 22:40:11,923 - base - recpack - INFO - Evaluation at end of 0 took 1757.45 s.\n",
            "2022-07-01 22:45:21,292 - base - recpack - INFO - Processed epoch 1 in 309.36 s.Batch Training Loss = 34.5792\n",
            "2022-07-01 23:14:37,987 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.15456084934994604, which is better than previous iterations.\n",
            "2022-07-01 23:14:37,988 - base - recpack - INFO - Model improved. Storing better model.\n",
            "2022-07-01 23:14:38,026 - base - recpack - INFO - Evaluation at end of 1 took 1756.73 s.\n",
            "2022-07-01 23:19:47,130 - base - recpack - INFO - Processed epoch 2 in 309.10 s.Batch Training Loss = 32.4403\n",
            "2022-07-01 23:49:11,202 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.15958764930208724, which is better than previous iterations.\n",
            "2022-07-01 23:49:11,203 - base - recpack - INFO - Model improved. Storing better model.\n",
            "2022-07-01 23:49:11,241 - base - recpack - INFO - Evaluation at end of 2 took 1764.11 s.\n",
            "2022-07-01 23:54:21,366 - base - recpack - INFO - Processed epoch 3 in 310.12 s.Batch Training Loss = 31.2002\n",
            "2022-07-02 00:25:27,438 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.16301896768783797, which is better than previous iterations.\n",
            "2022-07-02 00:25:27,439 - base - recpack - INFO - Model improved. Storing better model.\n",
            "2022-07-02 00:25:27,477 - base - recpack - INFO - Evaluation at end of 3 took 1866.11 s.\n",
            "2022-07-02 00:30:42,695 - base - recpack - INFO - Processed epoch 4 in 315.21 s.Batch Training Loss = 30.2915\n",
            "2022-07-02 01:01:49,869 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.16754233167394456, which is better than previous iterations.\n",
            "2022-07-02 01:01:49,870 - base - recpack - INFO - Model improved. Storing better model.\n",
            "2022-07-02 01:01:49,909 - base - recpack - INFO - Evaluation at end of 4 took 1867.21 s.\n",
            "2022-07-02 01:07:05,930 - base - recpack - INFO - Processed epoch 5 in 316.02 s.Batch Training Loss = 29.5478\n",
            "2022-07-02 01:38:24,874 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.17033803725693497, which is better than previous iterations.\n",
            "2022-07-02 01:38:24,875 - base - recpack - INFO - Model improved. Storing better model.\n",
            "2022-07-02 01:38:24,916 - base - recpack - INFO - Evaluation at end of 5 took 1878.98 s.\n",
            "2022-07-02 01:43:41,578 - base - recpack - INFO - Processed epoch 6 in 316.66 s.Batch Training Loss = 28.9116\n",
            "2022-07-02 02:14:57,221 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.17246281235512972, which is better than previous iterations.\n",
            "2022-07-02 02:14:57,222 - base - recpack - INFO - Model improved. Storing better model.\n",
            "2022-07-02 02:14:57,261 - base - recpack - INFO - Evaluation at end of 6 took 1875.68 s.\n",
            "2022-07-02 02:20:12,799 - base - recpack - INFO - Processed epoch 7 in 315.53 s.Batch Training Loss = 28.3943\n",
            "2022-07-02 02:51:10,153 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.17518846371776792, which is better than previous iterations.\n",
            "2022-07-02 02:51:10,154 - base - recpack - INFO - Model improved. Storing better model.\n",
            "2022-07-02 02:51:10,192 - base - recpack - INFO - Evaluation at end of 7 took 1857.39 s.\n",
            "2022-07-02 02:56:21,574 - base - recpack - INFO - Processed epoch 8 in 311.38 s.Batch Training Loss = 27.9894\n",
            "2022-07-02 03:26:00,474 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.17634254726007406, which is better than previous iterations.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-07-02 03:26:00,475 - base - recpack - INFO - Model improved. Storing better model.\n",
            "2022-07-02 03:26:00,512 - base - recpack - INFO - Evaluation at end of 8 took 1778.94 s.\n",
            "2022-07-02 03:31:11,043 - base - recpack - INFO - Processed epoch 9 in 310.53 s.Batch Training Loss = 27.6428\n",
            "2022-07-02 04:00:46,243 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.1783149841683678, which is better than previous iterations.\n",
            "2022-07-02 04:00:46,244 - base - recpack - INFO - Model improved. Storing better model.\n",
            "2022-07-02 04:00:46,281 - base - recpack - INFO - Evaluation at end of 9 took 1775.24 s.\n",
            "2022-07-02 04:00:46,299 - base - recpack - INFO - Fitting NeuMFMLPOnly complete - Took 2.13e+04s\n",
            "2022-07-02 04:40:27,948 - base - recpack - INFO - Processed epoch 0 in 492.59 s.Batch Training Loss = 40.9445\n",
            "2022-07-02 05:12:24,653 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.13997920180943083, which is better than previous iterations.\n",
            "2022-07-02 05:12:24,654 - base - recpack - INFO - Model improved. Storing better model.\n",
            "2022-07-02 05:12:24,728 - base - recpack - INFO - Evaluation at end of 0 took 1916.78 s.\n",
            "2022-07-02 05:20:37,858 - base - recpack - INFO - Processed epoch 1 in 493.13 s.Batch Training Loss = 33.7950\n",
            "2022-07-02 05:52:49,425 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.15570742995355125, which is better than previous iterations.\n",
            "2022-07-02 05:52:49,426 - base - recpack - INFO - Model improved. Storing better model.\n",
            "2022-07-02 05:52:49,505 - base - recpack - INFO - Evaluation at end of 1 took 1931.65 s.\n",
            "2022-07-02 06:01:04,195 - base - recpack - INFO - Processed epoch 2 in 494.69 s.Batch Training Loss = 31.4152\n",
            "2022-07-02 06:32:37,581 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.16549119616907446, which is better than previous iterations.\n",
            "2022-07-02 06:32:37,582 - base - recpack - INFO - Model improved. Storing better model.\n",
            "2022-07-02 06:32:37,658 - base - recpack - INFO - Evaluation at end of 2 took 1893.46 s.\n",
            "2022-07-02 06:40:43,820 - base - recpack - INFO - Processed epoch 3 in 486.16 s.Batch Training Loss = 29.9892\n",
            "2022-07-02 07:11:50,606 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.16928643583029634, which is better than previous iterations.\n",
            "2022-07-02 07:11:50,607 - base - recpack - INFO - Model improved. Storing better model.\n",
            "2022-07-02 07:11:50,685 - base - recpack - INFO - Evaluation at end of 3 took 1866.86 s.\n",
            "2022-07-02 07:19:58,011 - base - recpack - INFO - Processed epoch 4 in 487.32 s.Batch Training Loss = 28.8836\n",
            "2022-07-02 07:50:31,577 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.1733610829505318, which is better than previous iterations.\n",
            "2022-07-02 07:50:31,578 - base - recpack - INFO - Model improved. Storing better model.\n",
            "2022-07-02 07:50:31,654 - base - recpack - INFO - Evaluation at end of 4 took 1833.64 s.\n",
            "2022-07-02 07:58:37,964 - base - recpack - INFO - Processed epoch 5 in 486.31 s.Batch Training Loss = 28.0552\n",
            "2022-07-02 08:30:54,945 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.17673831984105645, which is better than previous iterations.\n",
            "2022-07-02 08:30:54,946 - base - recpack - INFO - Model improved. Storing better model.\n",
            "2022-07-02 08:30:55,025 - base - recpack - INFO - Evaluation at end of 5 took 1937.06 s.\n",
            "2022-07-02 08:39:08,483 - base - recpack - INFO - Processed epoch 6 in 493.45 s.Batch Training Loss = 27.3413\n",
            "2022-07-02 09:11:27,474 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.17538097694160054, which is worse than previous iterations.\n",
            "2022-07-02 09:11:27,475 - base - recpack - INFO - Evaluation at end of 6 took 1938.99 s.\n",
            "2022-07-02 09:19:42,058 - base - recpack - INFO - Processed epoch 7 in 494.58 s.Batch Training Loss = 26.7862\n",
            "2022-07-02 09:52:03,672 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.17754275135270559, which is better than previous iterations.\n",
            "2022-07-02 09:52:03,674 - base - recpack - INFO - Model improved. Storing better model.\n",
            "2022-07-02 09:52:03,750 - base - recpack - INFO - Evaluation at end of 7 took 1941.69 s.\n",
            "2022-07-02 10:00:10,719 - base - recpack - INFO - Processed epoch 8 in 486.96 s.Batch Training Loss = 26.2612\n",
            "2022-07-02 10:30:43,735 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.17833474541043648, which is better than previous iterations.\n",
            "2022-07-02 10:30:43,736 - base - recpack - INFO - Model improved. Storing better model.\n",
            "2022-07-02 10:30:43,811 - base - recpack - INFO - Evaluation at end of 8 took 1833.09 s.\n",
            "2022-07-02 10:38:50,165 - base - recpack - INFO - Processed epoch 9 in 486.35 s.Batch Training Loss = 25.8082\n",
            "2022-07-02 11:09:29,955 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.1801172814887319, which is better than previous iterations.\n",
            "2022-07-02 11:09:29,957 - base - recpack - INFO - Model improved. Storing better model.\n",
            "2022-07-02 11:09:30,036 - base - recpack - INFO - Evaluation at end of 9 took 1839.87 s.\n",
            "2022-07-02 11:09:30,068 - base - recpack - INFO - Fitting NeuMFMLPOnly complete - Took 2.38e+04s\n",
            "2022-07-02 11:47:26,257 - base - recpack - INFO - Processed epoch 0 in 315.64 s.Batch Training Loss = 41.5675\n",
            "2022-07-02 12:18:33,618 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.140752055301352, which is better than previous iterations.\n",
            "2022-07-02 12:18:33,619 - base - recpack - INFO - Model improved. Storing better model.\n",
            "2022-07-02 12:18:33,657 - base - recpack - INFO - Evaluation at end of 0 took 1867.40 s.\n",
            "2022-07-02 12:23:51,085 - base - recpack - INFO - Processed epoch 1 in 317.42 s.Batch Training Loss = 34.3723\n",
            "2022-07-02 12:55:07,869 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.15277743491093515, which is better than previous iterations.\n",
            "2022-07-02 12:55:07,870 - base - recpack - INFO - Model improved. Storing better model.\n",
            "2022-07-02 12:55:07,911 - base - recpack - INFO - Evaluation at end of 1 took 1876.82 s.\n",
            "2022-07-02 13:00:25,381 - base - recpack - INFO - Processed epoch 2 in 317.46 s.Batch Training Loss = 32.1367\n",
            "2022-07-02 13:31:57,457 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.16038290547191192, which is better than previous iterations.\n",
            "2022-07-02 13:31:57,458 - base - recpack - INFO - Model improved. Storing better model.\n",
            "2022-07-02 13:31:57,498 - base - recpack - INFO - Evaluation at end of 2 took 1892.12 s.\n",
            "2022-07-02 13:37:10,182 - base - recpack - INFO - Processed epoch 3 in 312.68 s.Batch Training Loss = 30.8782\n",
            "2022-07-02 14:07:00,046 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.1668776374909479, which is better than previous iterations.\n",
            "2022-07-02 14:07:00,047 - base - recpack - INFO - Model improved. Storing better model.\n",
            "2022-07-02 14:07:00,087 - base - recpack - INFO - Evaluation at end of 3 took 1789.90 s.\n",
            "2022-07-02 14:12:11,516 - base - recpack - INFO - Processed epoch 4 in 311.43 s.Batch Training Loss = 29.9859\n",
            "2022-07-02 14:41:54,500 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.17058241569022134, which is better than previous iterations.\n",
            "2022-07-02 14:41:54,501 - base - recpack - INFO - Model improved. Storing better model.\n",
            "2022-07-02 14:41:54,541 - base - recpack - INFO - Evaluation at end of 4 took 1783.02 s.\n",
            "2022-07-02 14:47:05,862 - base - recpack - INFO - Processed epoch 5 in 311.32 s.Batch Training Loss = 29.2818\n",
            "2022-07-02 15:17:33,989 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.1745818319040097, which is better than previous iterations.\n",
            "2022-07-02 15:17:33,991 - base - recpack - INFO - Model improved. Storing better model.\n",
            "2022-07-02 15:17:34,030 - base - recpack - INFO - Evaluation at end of 5 took 1828.17 s.\n",
            "2022-07-02 15:22:50,463 - base - recpack - INFO - Processed epoch 6 in 316.43 s.Batch Training Loss = 28.6982\n",
            "2022-07-02 15:54:05,018 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.17569729842562898, which is better than previous iterations.\n",
            "2022-07-02 15:54:05,019 - base - recpack - INFO - Model improved. Storing better model.\n",
            "2022-07-02 15:54:05,059 - base - recpack - INFO - Evaluation at end of 6 took 1874.60 s.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-07-02 15:59:22,012 - base - recpack - INFO - Processed epoch 7 in 316.95 s.Batch Training Loss = 28.2006\n",
            "2022-07-02 16:30:47,891 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.17964142990428575, which is better than previous iterations.\n",
            "2022-07-02 16:30:47,892 - base - recpack - INFO - Model improved. Storing better model.\n",
            "2022-07-02 16:30:47,933 - base - recpack - INFO - Evaluation at end of 7 took 1885.92 s.\n",
            "2022-07-02 16:36:04,405 - base - recpack - INFO - Processed epoch 8 in 316.47 s.Batch Training Loss = 27.7895\n",
            "2022-07-02 17:06:36,013 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.18007371065396469, which is better than previous iterations.\n",
            "2022-07-02 17:06:36,014 - base - recpack - INFO - Model improved. Storing better model.\n",
            "2022-07-02 17:06:36,053 - base - recpack - INFO - Evaluation at end of 8 took 1831.65 s.\n",
            "2022-07-02 17:11:46,899 - base - recpack - INFO - Processed epoch 9 in 310.84 s.Batch Training Loss = 27.4160\n",
            "2022-07-02 17:41:13,676 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.1803656469798214, which is better than previous iterations.\n",
            "2022-07-02 17:41:13,677 - base - recpack - INFO - Model improved. Storing better model.\n",
            "2022-07-02 17:41:13,718 - base - recpack - INFO - Evaluation at end of 9 took 1766.82 s.\n",
            "2022-07-02 17:41:13,736 - base - recpack - INFO - Fitting NeuMFMLPOnly complete - Took 2.15e+04s\n",
            "2022-07-02 18:11:30,942 - base - recpack - INFO - Fitting Popularity complete - Took 2.52s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/robinverachtert/dist-env/lib/python3.8/site-packages/scipy/sparse/_index.py:146: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
            "  self._set_arrayXarray(i, j, x)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-07-02 18:11:58,956 - base - recpack - INFO - Fitting ItemKNN complete - Took 16.9s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/robinverachtert/dist-env/lib/python3.8/site-packages/recpack/algorithms/base.py:274: UserWarning: ItemKNN missing similar items for 11 items.\n",
            "  warnings.warn(f\"{self.name} missing similar items for {missing} items.\")\n",
            "/home/robinverachtert/dist-env/lib/python3.8/site-packages/scipy/sparse/_index.py:146: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
            "  self._set_arrayXarray(i, j, x)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-07-02 18:12:32,603 - base - recpack - INFO - Fitting ItemKNN complete - Took 13.7s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/robinverachtert/dist-env/lib/python3.8/site-packages/recpack/algorithms/base.py:274: UserWarning: ItemKNN missing similar items for 11 items.\n",
            "  warnings.warn(f\"{self.name} missing similar items for {missing} items.\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-07-02 18:13:29,405 - base - recpack - INFO - Fitting ItemKNN complete - Took 16.6s\n"
          ]
        }
      ],
      "source": [
        "builder = PipelineBuilder()\n",
        "builder.set_data_from_scenario(scenario)\n",
        "\n",
        "builder.add_metric('NDCGK', K=10)\n",
        "builder.add_metric('CoverageK', K=10)\n",
        "\n",
        "builder.add_algorithm(\n",
        "    algorithm = 'NeuMFMLPOnly', \n",
        "    params = {\n",
        "        'batch_size': 128,\n",
        "        'max_epochs': 10,\n",
        "        'learning_rate': 0.001,\n",
        "        'stopping_criterion': 'ndcg',\n",
        "        'predict_topK': 50,\n",
        "        'n_negatives_per_positive': 4,\n",
        "        'dropout': 0.0\n",
        "    },\n",
        "    grid = {\n",
        "        'predictive_factors': [8, 16, 32],\n",
        "    }\n",
        ")\n",
        "\n",
        "builder.add_algorithm('Popularity', params={'K': 50})\n",
        "builder.add_algorithm(\n",
        "    'ItemKNN', \n",
        "    grid={'similarity': ['conditional_probability', 'cosine']}\n",
        ")\n",
        "builder.set_optimisation_metric('NDCGK', K=10)\n",
        "\n",
        "pipeline = builder.build()\n",
        "\n",
        "pipeline.run()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "3a36b1d0",
      "metadata": {
        "slideshow": {
          "slide_type": "skip"
        }
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ndcgk_10</th>\n",
              "      <th>coveragek_10</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>NeuMFMLPOnly</th>\n",
              "      <td>0.115335</td>\n",
              "      <td>0.176857</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Popularity</th>\n",
              "      <td>0.084736</td>\n",
              "      <td>0.000502</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ItemKNN</th>\n",
              "      <td>0.160481</td>\n",
              "      <td>0.147765</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              ndcgk_10  coveragek_10\n",
              "NeuMFMLPOnly  0.115335      0.176857\n",
              "Popularity    0.084736      0.000502\n",
              "ItemKNN       0.160481      0.147765"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pipeline.get_metrics(short=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "bbf22a9c",
      "metadata": {
        "slideshow": {
          "slide_type": "subslide"
        }
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>identifier</th>\n",
              "      <th>params</th>\n",
              "      <th>NDCGK</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>NeuMFMLPOnly(batch_size=128,dropout=0.0,exact_...</td>\n",
              "      <td>{'predictive_factors': 8, 'batch_size': 128, '...</td>\n",
              "      <td>0.095286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>NeuMFMLPOnly(batch_size=128,dropout=0.0,exact_...</td>\n",
              "      <td>{'predictive_factors': 16, 'batch_size': 128, ...</td>\n",
              "      <td>0.099083</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>NeuMFMLPOnly(batch_size=128,dropout=0.0,exact_...</td>\n",
              "      <td>{'predictive_factors': 32, 'batch_size': 128, ...</td>\n",
              "      <td>0.097915</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ItemKNN(K=200,normalize=False,normalize_X=Fals...</td>\n",
              "      <td>{'similarity': 'conditional_probability'}</td>\n",
              "      <td>0.100922</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ItemKNN(K=200,normalize=False,normalize_X=Fals...</td>\n",
              "      <td>{'similarity': 'cosine'}</td>\n",
              "      <td>0.136519</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                          identifier  \\\n",
              "0  NeuMFMLPOnly(batch_size=128,dropout=0.0,exact_...   \n",
              "1  NeuMFMLPOnly(batch_size=128,dropout=0.0,exact_...   \n",
              "2  NeuMFMLPOnly(batch_size=128,dropout=0.0,exact_...   \n",
              "3  ItemKNN(K=200,normalize=False,normalize_X=Fals...   \n",
              "4  ItemKNN(K=200,normalize=False,normalize_X=Fals...   \n",
              "\n",
              "                                              params     NDCGK  \n",
              "0  {'predictive_factors': 8, 'batch_size': 128, '...  0.095286  \n",
              "1  {'predictive_factors': 16, 'batch_size': 128, ...  0.099083  \n",
              "2  {'predictive_factors': 32, 'batch_size': 128, ...  0.097915  \n",
              "3          {'similarity': 'conditional_probability'}  0.100922  \n",
              "4                           {'similarity': 'cosine'}  0.136519  "
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pipeline.optimisation_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a6cd85cd",
      "metadata": {},
      "outputs": [],
      "source": [
        "builder = PipelineBuilder()\n",
        "builder.set_data_from_scenario(scenario)\n",
        "\n",
        "builder.add_metric('NDCGK', K=10)\n",
        "builder.add_metric('CoverageK', K=10)\n",
        "\n",
        "builder.add_algorithm(\n",
        "    algorithm = 'NMF', \n",
        "    grid = {\n",
        "        'num_components': [16, 32, 64, 128],\n",
        "    }\n",
        ")\n",
        "\n",
        "builder.set_optimisation_metric('NDCGK', K=10)\n",
        "\n",
        "pipeline = builder.build()\n",
        "\n",
        "pipeline.run()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d0e3c55c",
      "metadata": {},
      "outputs": [],
      "source": [
        "pipeline.get_metrics(short=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6446dcc6",
      "metadata": {},
      "outputs": [],
      "source": [
        "pipeline.optimisation_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "066d5f64",
      "metadata": {},
      "outputs": [],
      "source": [
        "builder = PipelineBuilder()\n",
        "builder.set_data_from_scenario(scenario)\n",
        "\n",
        "builder.add_metric('NDCGK', K=10)\n",
        "builder.add_metric('CoverageK', K=10)\n",
        "\n",
        "builder.add_algorithm(\n",
        "    algorithm = 'BPRMF', \n",
        "    params = {\n",
        "        'batch_size': 128,\n",
        "        'max_epochs': 10,\n",
        "        'learning_rate': 0.001,\n",
        "        'stopping_criterion': 'ndcg',\n",
        "        'predict_topK': 50,\n",
        "        'lambda_h': 0.1,\n",
        "        'lambda_w': 0.1,\n",
        "    },\n",
        "    grid = {\n",
        "        'num_components': [16, 32, 64, 128],\n",
        "    }\n",
        ")\n",
        "\n",
        "builder.set_optimisation_metric('NDCGK', K=10)\n",
        "\n",
        "pipeline = builder.build()\n",
        "\n",
        "pipeline.run()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "54afe508",
      "metadata": {},
      "outputs": [],
      "source": [
        "pipeline.get_metrics(short=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0abc7d2e",
      "metadata": {},
      "outputs": [],
      "source": [
        "pipeline.optimisation_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ac7e332e",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "celltoolbar": "Slideshow",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}