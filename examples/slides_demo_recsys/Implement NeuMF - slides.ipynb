{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85c37828",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pytest\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "from typing import Callable, List, Optional, Union"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c225f899",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "NOTE: this is used as slideshow, and should not to be run."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "649de821",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# RecPack: An Experimental Toolkit for Recommendation Algorithms\n",
    "\n",
    "by Lien Michiels and Robin Verachtert"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "478837d4",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## What is Recpack?\n",
    "- Python library for recommendation algorithm implementation and evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccf1660c",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## What is Recpack?\n",
    "- Python library for recommendation algorithm implementation and evaluation\n",
    "- Focus on being easily extendable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d8cbaac",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## What is Recpack?\n",
    "### Architecture\n",
    "![pipeline](RecpackPipeline.png)\n",
    "\n",
    "This image has been designed using resources from Flaticon.com"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "671379b0",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "TODO: include scenarios!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab307a0",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## This Demo\n",
    "- Demonstrate implementation of new algorithm using \"Neural Matrix Factorization (He et al. 2017)\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47c6c8a6",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## This Demo\n",
    "- Demonstrate implementation of new algorithm using \"Neural Matrix Factorization (He et al. 2017)\"\n",
    "- Run experiment to compare performance of new algorithm to baselines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d08a2c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Neural Matrix Factorization\n",
    "- Users and items are represented by embedding fectors\n",
    "- Similarity is modeled using an MLP network, rather than computing <u,i> as in traditional matrix factorization embedding techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c196de69",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "### Implementing MLP network\n",
    "\n",
    "![MLPArchitecture](MLPArchitecture.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "743b93a9",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    \"\"\"A multi-layer perceptron module.\n",
    "    This module is a sequence of linear layers plus activation functions.\n",
    "    The user can optionally add normalization and/or dropout to each of the layers.\n",
    "    \n",
    "    Code used from https://github.com/facebookresearch/multimodal/blob/5dec8a/torchmultimodal/modules/layers/mlp.py\n",
    "    \n",
    "    :param in_dim: Input dimension.\n",
    "    :type in_dim: int\n",
    "    :param out_dim: Output dimension.\n",
    "    :type out_dim: int\n",
    "    :param hidden_dims: Output dimension for each hidden layer.\n",
    "    :type hidden_dims: Optional[Union[int, List[int]]] \n",
    "    :param dropout: Probability for dropout layers between each hidden layer.\n",
    "    :type dropout: float\n",
    "    :param activation: Which activation function to use. \n",
    "        Supports module type or partial.\n",
    "    :type activation: Callable[..., nn.Module]\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self, \n",
    "        in_dim: int, \n",
    "        out_dim: int,\n",
    "        hidden_dims: Optional[Union[int, List[int]]] = None,\n",
    "        dropout: float = 0.5,\n",
    "        activation: Callable[..., nn.Module] = nn.ReLU,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        layers = nn.ModuleList()\n",
    "\n",
    "        if hidden_dims is None:\n",
    "            hidden_dims = []\n",
    "\n",
    "        if isinstance(hidden_dims, int):\n",
    "            hidden_dims = [hidden_dims]\n",
    "\n",
    "        for hidden_dim in hidden_dims:\n",
    "            layers.append(nn.Linear(in_dim, hidden_dim))\n",
    "            layers.append(activation())\n",
    "            layers.append(nn.Dropout(dropout))\n",
    "            in_dim = hidden_dim\n",
    "        layers.append(nn.Linear(in_dim, out_dim))\n",
    "        self.model = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea26454",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Implementing the Neural Architecture\n",
    "\n",
    "![Architecture](NeuMFArchitecture.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "34a78b55",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "class NMFModule(nn.Module):\n",
    "    \"\"\"Model that encodes the Neural Matrix Factorization Network.\n",
    "    \n",
    "    Implements the 3 tiered network defined in the He et al. paper.\n",
    "\n",
    "    :param predictive_powers: size of the last hidden layer in MLP.\n",
    "        Embedding sizes computed as 2 * predictive powers.\n",
    "    :type predictive_powers: int\n",
    "    :param n_users: number of users in the network\n",
    "    :type n_users: int\n",
    "    :param n_items: number of items in the network\n",
    "    :type n_items: int\n",
    "    :param hidden_dims: dimensions of the MLP hidden layers.\n",
    "    :type hidden_dims: Union[int, List[int]]\n",
    "    :param dropout: Dropout chance between layers of the MLP\n",
    "    :type dropout: float\n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "63e439d5",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "class NMFModule(NMFModule):\n",
    "    def __init__(\n",
    "        self, predictive_powers: int, n_users: int, n_items: int, dropout: float\n",
    "    ):\n",
    "        super().__init__()\n",
    "        num_components = 2 * predictive_powers\n",
    "        \n",
    "        self.user_embedding = nn.Embedding(n_users, num_components)\n",
    "        self.item_embedding = nn.Embedding(n_items, num_components)\n",
    "\n",
    "        # we use a three tiered MLP as described in the experiments of the paper.\n",
    "        hidden_dims = [\n",
    "            4 * predictive_powers, \n",
    "            2 * predictive_powers, \n",
    "            predictive_powers\n",
    "        ]\n",
    "\n",
    "        # Output is always 1, since we need a single score for u,i\n",
    "        self.mlp = MLP(4 * predictive_powers, 1, \n",
    "                       hidden_dims, dropout=dropout)\n",
    "\n",
    "        self.final = nn.Sigmoid()\n",
    "\n",
    "        # weight initialization\n",
    "        self.user_embedding.weight.data.normal_(0, \n",
    "            1.0 / self.user_embedding.embedding_dim)\n",
    "        self.item_embedding.weight.data.normal_(0, \n",
    "            1.0 / self.item_embedding.embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "551d5c5b",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "class NMFModule(NMFModule):\n",
    "    def forward(self, users: torch.LongTensor, items: torch.LongTensor) -> torch.FloatTensor:\n",
    "        \"\"\"Predict scores for the user item pairs obtained \n",
    "        by zipping together the two inputs\n",
    "\n",
    "        :param users: 1D tensor with user ids\n",
    "        :type users: torch.LongTensor\n",
    "        :param items: 1D tensor with item ids\n",
    "        :type items: torch.LongTensor\n",
    "        :return: 1D tensor with predicted similarities.\n",
    "            Position i is the similarity between \n",
    "            `users[i]` and `items[i]`\n",
    "        :rtype: torch.FloatTensor\n",
    "        \"\"\"\n",
    "\n",
    "        # Embedding lookups\n",
    "        user_emb = self.user_embedding(users)\n",
    "        item_emb = self.item_embedding(items)\n",
    "\n",
    "        # Pass concatenated through MLP and apply sigmoid\n",
    "        return self.final(\n",
    "            self.mlp(\n",
    "                torch.hstack([user_emb, item_emb])\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b8bcb491",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def test_output_shapes_NMF(\n",
    "    predictive_factors, num_users, num_items\n",
    "):\n",
    "    \"\"\"Check that no mather the inner settings of the network, the output is always correct\"\"\"\n",
    "    mod = NMFModule(predictive_factors, num_users, num_items, 0.0)\n",
    "    \n",
    "    user_tensor = torch.LongTensor([1, 2])\n",
    "    item_tensor = torch.LongTensor([1, 2])\n",
    "    \n",
    "    res = mod(user_tensor, item_tensor) # predict scores for items given the users\n",
    "    \n",
    "    assert res.shape == (2, 1)\n",
    "\n",
    "    assert (res.detach().numpy() <= 1).all()\n",
    "    assert (res.detach().numpy() >= 0).all()\n",
    "\n",
    "\n",
    "test_output_shapes_NMF(5, 10, 10)\n",
    "test_output_shapes_NMF(5, 3, 10)\n",
    "test_output_shapes_NMF(1, 3, 3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3c07d570",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from typing import List, Union, Optional\n",
    "\n",
    "import pandas as pd\n",
    "from recpack.algorithms.base import TorchMLAlgorithm\n",
    "from recpack.algorithms.samplers import PositiveNegativeSampler\n",
    "from recpack.algorithms.util import get_users\n",
    "from recpack.matrix import InteractionMatrix\n",
    "from scipy.sparse import csr_matrix, lil_matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "217f8d30",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Implementing the algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "689f9c7d",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Choosing the right baseclass\n",
    "`Algorithm`\n",
    "\n",
    "Follows the sklearn interface\n",
    "- `__init__(...)`: sets the (hyper)parameters of the algorithm\n",
    "- `fit(X)`: train the algorithm, and build a model that can be used for prediction\n",
    "- `predict(X)`: Given a matrix of user histories, recommend items for these users."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c86675d",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Choosing the right baseclass\n",
    "![algorithm baseclasses](AlgorithmBaseclasses.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d79dab",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Choosing the right baseclass\n",
    "`TorchMLAlgorithm`\n",
    "- `__init__`\n",
    "    - Adds standard parameters (learning rate, batch_size, num_epochs, keep_last, ...)\n",
    "- `fit(X, validation_data)`:\n",
    "    - Epoch loop -> Implement training single epoch\n",
    "    - Early stopping\n",
    "    - Keep best/last model\n",
    "    - Progress logs\n",
    "- `_predict`\n",
    "    - Batched prediction loop -> Implement prediction for single batch\n",
    "    - Prune recommendations \n",
    "- `save` + `load`\n",
    "\n",
    "TODO: Need a better way to indicate what remains to be implemented?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef306ba",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Choosing the right baseclass\n",
    "`TorchMLAlgorithm`\n",
    "\n",
    "We need to implement:\n",
    "\n",
    "- `__init__`: Add hyperparameters\n",
    "- `_init_model`: Initialise the model during training\n",
    "- `_train_epoch`: train for a single epoch\n",
    "- `_predict_batch`: predict for a batch of users\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e359a201",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "class NeuMF(TorchMLAlgorithm):\n",
    "    \"\"\"Implementation of Neural Matrix Factoration.\n",
    "\n",
    "    Neural Matrix Factorization based on MLP architecture\n",
    "    as presented in Figure 2 in He, Xiangnan, et al. \n",
    "    \"Neural collaborative filtering.\"\n",
    "    In Proceedings of the 26th international conference on world wide web. 2017.\n",
    "\n",
    "    Represents the users and items using an embedding, \n",
    "    similarity between the two is modelled using a neural network.\n",
    "\n",
    "    The network consists of an embedding for both users and items.\n",
    "    To compute similarity those two embeddings are \n",
    "    concatenated and passed through the MLP\n",
    "    Finally the similarity is transformed to the [0,1] domain\n",
    "    using a sigmoid function.\n",
    "\n",
    "    As in the paper, the sum of square errors is used as loss function.\n",
    "    Positive items should get a prediction close to 1, \n",
    "    while sampled negatives should get a value close to 0.\n",
    "\n",
    "    The MLP has 3 layers, as suggested in the experiments section.\n",
    "    Bottom layer has dimension `4 * predictive_powers`, \n",
    "    middle layer `2 * predictive_powers`\n",
    "    and the top layer has `predictive_powers`.\n",
    "\n",
    "    :param predictive_powers: Size of the last hidden layer in the MLP network.\n",
    "        Embedding size is 2 * predictive_powers\n",
    "    :type predictive_powers: int\n",
    "    :param batch_size: How many samples to use in each update step.\n",
    "        Higher batch sizes make each epoch more efficient,\n",
    "        but increases the amount of epochs needed to converge to the optimum,\n",
    "        by reducing the amount of updates per epoch.\n",
    "        Defaults to 512.\n",
    "    :type batch_size: Optional[int]\n",
    "    :param max_epochs: The max number of epochs to train.\n",
    "        If the stopping criterion uses early stopping, less epochs could be used.\n",
    "        Defaults to 10.\n",
    "    :type max_epochs: Optional[int]\n",
    "    :param learning_rate: How much to update the weights at each update. Defaults to 0.01\n",
    "    :type learning_rate: Optional[float]\n",
    "    :param stopping_criterion: Name of the stopping criterion to use for training.\n",
    "        For available values,\n",
    "        check :meth:`recpack.algorithms.stopping_criterion.StoppingCriterion.FUNCTIONS`\n",
    "        Defaults to 'ndcg'\n",
    "    :type stopping_criterion: Optional[str]\n",
    "    :param stop_early: If True, early stopping is enabled,\n",
    "        and after ``max_iter_no_change`` iterations where improvement of loss function\n",
    "        is below ``min_improvement`` the optimisation is stopped,\n",
    "        even if max_epochs is not reached.\n",
    "        Defaults to False\n",
    "    :type stop_early: bool, optional\n",
    "    :param max_iter_no_change: If early stopping is enabled,\n",
    "        stop after this amount of iterations without change.\n",
    "        Defaults to 5\n",
    "    :type max_iter_no_change: int, optional\n",
    "    :param min_improvement: If early stopping is enabled, no change is detected,\n",
    "        if the improvement is below this value.\n",
    "        Defaults to 0.01\n",
    "    :type min_improvement: float, optional\n",
    "    :param seed: Seed to the randomizers, useful for reproducible results,\n",
    "        defaults to None\n",
    "    :type seed: int, optional\n",
    "    :param save_best_to_file: If true, the best model will be saved after training,\n",
    "        defaults to False\n",
    "    :type save_best_to_file: bool, optional\n",
    "    :param keep_last: Retain last model, rather than best\n",
    "        (according to stopping criterion value on validation data), defaults to False\n",
    "    :type keep_last: bool, optional\n",
    "    :param predict_topK: The topK recommendations to keep per row in the matrix.\n",
    "        Use when the user x item output matrix would become too large for RAM.\n",
    "        Defaults to None, which results in no filtering.\n",
    "    :type predict_topK: int, optional\n",
    "    :param n_negatives_per_positive: Amount of negatives to sample for each positive example, defaults to 1\n",
    "    :type n_negatives_per_positive: int, optional\n",
    "    :param dropout: Dropout parameter used in MLP, defaults to 0.0\n",
    "    :type dropout: float, optional\n",
    "    :param exact_sampling: Enable or disable exact checks while sampling. \n",
    "        With exact sampling the sampled negatives are guaranteed to not have been visited by the user. \n",
    "        Non exact sampling assumes that the space for item selection is large enough, \n",
    "        such that most items are likely not seen before.\n",
    "        Defaults to False,\n",
    "    :type exact_sampling: bool, optional\n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f85a3147",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "class NeuMF(NeuMF):\n",
    "    def __init__(\n",
    "        self,\n",
    "        predictive_factors: int,\n",
    "        n_negatives_per_positive: Optional[int] = 1,\n",
    "        dropout: Optional[float] = 0.0,\n",
    "        #Â baseclass parameters \n",
    "        # ...\n",
    "    ):\n",
    "        super().__init__(batch_size, max_epochs, learning_rate,\n",
    "            stopping_criterion, stop_early, max_iter_no_change,\n",
    "            min_improvement, seed, save_best_to_file, keep_last,\n",
    "            predict_topK,\n",
    "        )\n",
    "\n",
    "        self.predictive_factors = predictive_factors\n",
    "\n",
    "        self.n_negatives_per_positive = n_negatives_per_positive\n",
    "        self.dropout = dropout\n",
    "\n",
    "        self.sampler = PositiveNegativeSampler(\n",
    "            U=self.n_negatives_per_positive, replace=False, \n",
    "            batch_size=self.batch_size\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a7002850",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "class NeuMF(NeuMF):\n",
    "    def _init_model(self, X: csr_matrix):\n",
    "        num_users, num_items = X.shape\n",
    "        self.model_ = NMFModule(\n",
    "            self.predictive_factors, num_users, num_items, self.dropout\n",
    "        ).to(self.device)\n",
    "\n",
    "        self.optimizer = torch.optim.Adam(\n",
    "            self.model_.parameters(), lr=self.learning_rate\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ee655a20",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "class NeuMF(NeuMF):\n",
    "    def _train_epoch(self, X: csr_matrix) -> List[int]:\n",
    "        losses = []\n",
    "        for users, positives, negatives in self.sampler.sample(X):\n",
    "\n",
    "            self.optimizer.zero_grad()\n",
    "\n",
    "            # Predict for the positives\n",
    "            positive_scores = self.model_(\n",
    "                users.to(self.device), positives.to(self.device))\n",
    "            # Predict for the negatives\n",
    "            negative_scores = self.model_(\n",
    "                *self._construct_negative_prediction_input(\n",
    "                    users.to(self.device), negatives.to(self.device))\n",
    "            )\n",
    "\n",
    "            loss = self._compute_loss(\n",
    "                positive_scores, negative_scores)\n",
    "\n",
    "            # Backwards propagation of the loss\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "\n",
    "            losses.append(loss.item())\n",
    "\n",
    "        return losses\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b0cda7c5",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "class NeuMF(NeuMF):\n",
    "    def _compute_loss(\n",
    "        self, positive_scores: torch.FloatTensor, negative_scores: torch.FloatTensor\n",
    "    ) -> torch.FloatTensor:\n",
    "        \"\"\"Compute the Square Error loss given recommendations \n",
    "        for positive items, and sampled negatives.\n",
    "        \"\"\"\n",
    "\n",
    "        mse = nn.MSELoss(reduction=\"sum\")\n",
    "        return mse(positive_scores, torch.ones_like(positive_scores, dtype=torch.float)) + mse(\n",
    "            negative_scores, torch.zeros_like(negative_scores, dtype=torch.float)\n",
    "        )\n",
    "\n",
    "    def _construct_negative_prediction_input(self, users, negatives):\n",
    "        \"\"\"Construct the prediction input given a 1D user tensor and a 2D negatives tensor.\n",
    "        \n",
    "        Since negatives has shape |batch| x U, and users is a 1d vector,\n",
    "        these need to be turned into two 1D vectors of shape |batch| * U\n",
    "\n",
    "        First the users as a row are stacked U times and transposed,\n",
    "        so that this is also a batch x U tensor.\n",
    "        Then both are reshaped to remove the 2nd dimension, \n",
    "        resulting in a single long 1d vector.\n",
    "        \"\"\"\n",
    "        return (\n",
    "            users.repeat(self.n_negatives_per_positive, 1).T.reshape(-1), \n",
    "            negatives.reshape(-1)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b93dbaa3",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "class NeuMF(NeuMF):\n",
    "    def _batch_predict(\n",
    "        self, X: csr_matrix, users: List[int]\n",
    "    ) -> csr_matrix:\n",
    "        \"\"\"Generate recommendations for each of the users.\"\"\"\n",
    "\n",
    "        X_pred = lil_matrix(X.shape)\n",
    "        if users is None:\n",
    "            users = get_users(X)\n",
    "\n",
    "        _, n_items = X.shape\n",
    "        n_users = len(users)\n",
    "\n",
    "        # Create tensors such that each user, item pair gets a score.\n",
    "        # The user tensor contains the users in order \n",
    "        # (eg. [1, 1, 2, 2]), \n",
    "        # item indices are repeated (eg. [0, 1, 2, 0, 1, 2]).\n",
    "        user_tensor = torch.LongTensor(users).repeat(\n",
    "            n_items, 1).T.reshape(-1).to(self.device)\n",
    "        item_tensor = torch.arange(n_items).repeat(\n",
    "            n_users).to(self.device)\n",
    "\n",
    "        X_pred[users] = self.model_(\n",
    "            user_tensor, item_tensor\n",
    "        ).detach().cpu().numpy().reshape(n_users, n_items)\n",
    "        return X_pred.tocsr()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b414610",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Experiment\n",
    "\n",
    "Use RecPack Pipeline to compare the newly implemented algorithm to frequently used baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f3225456",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from recpack.pipelines import PipelineBuilder\n",
    "from recpack.datasets import MovieLens25M\n",
    "from recpack.scenarios import WeakGeneralization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8bb256ed",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "DATASET_PATH = '/home/robinverachtert/datasets'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "345019f0",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "902bdc7c7f584ef6a958d9d84c460a62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12415224 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cd05c1547ee4b9fae9a177ac4e4df5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12415224 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = MovieLens25M(\n",
    "    path=DATASET_PATH\n",
    ")\n",
    "data = dataset.load_interaction_matrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0452e6d",
   "metadata": {},
   "source": [
    "### Choosing the right scenario\n",
    "\n",
    "- LastItemPrediction\n",
    "- StrongGeneralization\n",
    "- StrongGeneralizationTimed\n",
    "- StrongGeneralizationTimedMostRecent\n",
    "- Timed\n",
    "- WeakGeneralization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a5a8b9ab",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b60c748c292f46f9b1f4b88483b936c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "403e41b3b91e46a0a90c663fd66ca7a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scenario = WeakGeneralization(frac_data_in=0.8, validation=True)\n",
    "scenario.split(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ba6aa1bc",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from recpack.pipelines import ALGORITHM_REGISTRY\n",
    "ALGORITHM_REGISTRY.register('NeuMF', NeuMF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2c46caa2",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "builder = PipelineBuilder()\n",
    "builder.set_data_from_scenario(scenario)\n",
    "\n",
    "builder.add_metric('NDCGK', K=10)\n",
    "builder.add_metric('CoverageK', K=10)\n",
    "\n",
    "builder.add_algorithm(\n",
    "    algorithm = 'NeuMF', \n",
    "    params = {\n",
    "        'batch_size': 128,\n",
    "        'max_epochs': 10,\n",
    "        'learning_rate': 0.01,\n",
    "        'stopping_criterion': 'ndcg',\n",
    "        'predict_topK': 20,\n",
    "        'n_negatives_per_positive': 3,\n",
    "        'dropout': 0.01\n",
    "    },\n",
    "    grid = {\n",
    "        'predictive_factors': [8, 16, 32],\n",
    "    }\n",
    ")\n",
    "\n",
    "builder.add_algorithm('Popularity', params={'K': 20})\n",
    "builder.add_algorithm(\n",
    "    'ItemKNN', \n",
    "    grid={'similarity': ['conditional_probability', 'cosine']}\n",
    ")\n",
    "builder.set_optimisation_metric('NDCGK', K=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "05c0a518",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "pipeline = builder.build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3314c304",
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3f8117d364d4e119d4bcce17acfb868",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128 10 0.01 ndcg\n",
      "2022-06-22 19:34:27,322 - base - recpack - INFO - Processed epoch 0 in 245.66 s.Batch Training Loss = 39.9801\n",
      "2022-06-22 20:03:52,854 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.0807752474141612, which is better than previous iterations.\n",
      "2022-06-22 20:03:52,855 - base - recpack - INFO - Model improved. Storing better model.\n",
      "2022-06-22 20:03:52,876 - base - recpack - INFO - Evaluation at end of 0 took 1765.55 s.\n",
      "2022-06-22 20:07:56,205 - base - recpack - INFO - Processed epoch 1 in 243.32 s.Batch Training Loss = 33.0413\n",
      "2022-06-22 20:37:07,710 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.08761402269236272, which is better than previous iterations.\n",
      "2022-06-22 20:37:07,711 - base - recpack - INFO - Model improved. Storing better model.\n",
      "2022-06-22 20:37:07,733 - base - recpack - INFO - Evaluation at end of 1 took 1751.53 s.\n",
      "2022-06-22 20:41:10,411 - base - recpack - INFO - Processed epoch 2 in 242.67 s.Batch Training Loss = 31.0265\n",
      "2022-06-22 21:08:58,321 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.09020461206240907, which is better than previous iterations.\n",
      "2022-06-22 21:08:58,322 - base - recpack - INFO - Model improved. Storing better model.\n",
      "2022-06-22 21:08:58,342 - base - recpack - INFO - Evaluation at end of 2 took 1667.93 s.\n",
      "2022-06-22 21:12:56,631 - base - recpack - INFO - Processed epoch 3 in 238.28 s.Batch Training Loss = 30.0155\n",
      "2022-06-22 21:40:06,768 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.09515308926992498, which is better than previous iterations.\n",
      "2022-06-22 21:40:06,769 - base - recpack - INFO - Model improved. Storing better model.\n",
      "2022-06-22 21:40:06,789 - base - recpack - INFO - Evaluation at end of 3 took 1630.16 s.\n",
      "2022-06-22 21:44:04,325 - base - recpack - INFO - Processed epoch 4 in 237.53 s.Batch Training Loss = 29.1366\n",
      "2022-06-22 22:11:55,894 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.09116380007015186, which is worse than previous iterations.\n",
      "2022-06-22 22:11:55,896 - base - recpack - INFO - Evaluation at end of 4 took 1671.57 s.\n",
      "2022-06-22 22:16:02,100 - base - recpack - INFO - Processed epoch 5 in 246.20 s.Batch Training Loss = 28.5276\n",
      "2022-06-22 22:46:10,269 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.0969775874251478, which is better than previous iterations.\n",
      "2022-06-22 22:46:10,270 - base - recpack - INFO - Model improved. Storing better model.\n",
      "2022-06-22 22:46:10,291 - base - recpack - INFO - Evaluation at end of 5 took 1808.19 s.\n",
      "2022-06-22 22:50:17,526 - base - recpack - INFO - Processed epoch 6 in 247.23 s.Batch Training Loss = 28.0716\n",
      "2022-06-22 23:20:03,414 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.09724975037252163, which is better than previous iterations.\n",
      "2022-06-22 23:20:03,415 - base - recpack - INFO - Model improved. Storing better model.\n",
      "2022-06-22 23:20:03,436 - base - recpack - INFO - Evaluation at end of 6 took 1785.91 s.\n",
      "2022-06-22 23:24:07,652 - base - recpack - INFO - Processed epoch 7 in 244.21 s.Batch Training Loss = 27.7030\n",
      "2022-06-22 23:52:35,934 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.09861493778883344, which is better than previous iterations.\n",
      "2022-06-22 23:52:35,936 - base - recpack - INFO - Model improved. Storing better model.\n",
      "2022-06-22 23:52:35,956 - base - recpack - INFO - Evaluation at end of 7 took 1708.30 s.\n",
      "2022-06-22 23:56:32,927 - base - recpack - INFO - Processed epoch 8 in 236.97 s.Batch Training Loss = 27.3997\n",
      "2022-06-23 00:23:58,193 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.09459366063534502, which is worse than previous iterations.\n",
      "2022-06-23 00:23:58,196 - base - recpack - INFO - Evaluation at end of 8 took 1645.27 s.\n",
      "2022-06-23 00:27:54,936 - base - recpack - INFO - Processed epoch 9 in 236.74 s.Batch Training Loss = 27.1639\n",
      "2022-06-23 00:55:03,867 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.09953214052288922, which is better than previous iterations.\n",
      "2022-06-23 00:55:03,869 - base - recpack - INFO - Model improved. Storing better model.\n",
      "2022-06-23 00:55:03,893 - base - recpack - INFO - Evaluation at end of 9 took 1628.96 s.\n",
      "2022-06-23 00:55:03,904 - base - recpack - INFO - Fitting NeuMF complete - Took 1.95e+04s\n",
      "128 10 0.01 ndcg\n",
      "2022-06-23 01:30:04,548 - base - recpack - INFO - Processed epoch 0 in 328.21 s.Batch Training Loss = 38.9921\n",
      "2022-06-23 02:00:32,234 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.08503753709991231, which is better than previous iterations.\n",
      "2022-06-23 02:00:32,235 - base - recpack - INFO - Model improved. Storing better model.\n",
      "2022-06-23 02:00:32,279 - base - recpack - INFO - Evaluation at end of 0 took 1827.73 s.\n",
      "2022-06-23 02:05:57,837 - base - recpack - INFO - Processed epoch 1 in 325.55 s.Batch Training Loss = 32.5183\n",
      "2022-06-23 02:35:37,037 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.0876874728901237, which is better than previous iterations.\n",
      "2022-06-23 02:35:37,038 - base - recpack - INFO - Model improved. Storing better model.\n",
      "2022-06-23 02:35:37,081 - base - recpack - INFO - Evaluation at end of 1 took 1779.24 s.\n",
      "2022-06-23 02:40:58,152 - base - recpack - INFO - Processed epoch 2 in 321.07 s.Batch Training Loss = 30.4448\n",
      "2022-06-23 03:07:08,261 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.09376696992773687, which is better than previous iterations.\n",
      "2022-06-23 03:07:08,262 - base - recpack - INFO - Model improved. Storing better model.\n",
      "2022-06-23 03:07:08,305 - base - recpack - INFO - Evaluation at end of 2 took 1570.15 s.\n",
      "2022-06-23 03:12:27,845 - base - recpack - INFO - Processed epoch 3 in 319.54 s.Batch Training Loss = 29.2488\n",
      "2022-06-23 03:40:12,298 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.09785262253730144, which is better than previous iterations.\n",
      "2022-06-23 03:40:12,299 - base - recpack - INFO - Model improved. Storing better model.\n",
      "2022-06-23 03:40:12,335 - base - recpack - INFO - Evaluation at end of 3 took 1664.49 s.\n",
      "2022-06-23 03:45:31,027 - base - recpack - INFO - Processed epoch 4 in 318.69 s.Batch Training Loss = 28.4492\n",
      "2022-06-23 04:14:16,928 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.09534398466632851, which is worse than previous iterations.\n",
      "2022-06-23 04:14:16,929 - base - recpack - INFO - Evaluation at end of 4 took 1725.90 s.\n",
      "2022-06-23 04:19:47,100 - base - recpack - INFO - Processed epoch 5 in 330.17 s.Batch Training Loss = 27.9003\n",
      "2022-06-23 04:49:28,499 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.09994501514677542, which is better than previous iterations.\n",
      "2022-06-23 04:49:28,500 - base - recpack - INFO - Model improved. Storing better model.\n",
      "2022-06-23 04:49:28,539 - base - recpack - INFO - Evaluation at end of 5 took 1781.44 s.\n",
      "2022-06-23 04:54:54,511 - base - recpack - INFO - Processed epoch 6 in 325.97 s.Batch Training Loss = 27.4033\n",
      "2022-06-23 05:24:27,834 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.10456761059909804, which is better than previous iterations.\n",
      "2022-06-23 05:24:27,835 - base - recpack - INFO - Model improved. Storing better model.\n",
      "2022-06-23 05:24:27,875 - base - recpack - INFO - Evaluation at end of 6 took 1773.36 s.\n",
      "2022-06-23 05:29:52,889 - base - recpack - INFO - Processed epoch 7 in 325.01 s.Batch Training Loss = 26.9981\n",
      "2022-06-23 05:58:26,231 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.10423341988925663, which is worse than previous iterations.\n",
      "2022-06-23 05:58:26,232 - base - recpack - INFO - Evaluation at end of 7 took 1713.34 s.\n",
      "2022-06-23 06:03:48,270 - base - recpack - INFO - Processed epoch 8 in 322.03 s.Batch Training Loss = 27.2013\n",
      "2022-06-23 06:32:38,761 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.029343878599265686, which is worse than previous iterations.\n",
      "2022-06-23 06:32:38,762 - base - recpack - INFO - Evaluation at end of 8 took 1730.49 s.\n",
      "2022-06-23 06:38:00,630 - base - recpack - INFO - Processed epoch 9 in 321.86 s.Batch Training Loss = 32.6222\n",
      "2022-06-23 07:01:36,644 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.02108832435436341, which is worse than previous iterations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-06-23 07:01:36,645 - base - recpack - INFO - Evaluation at end of 9 took 1416.01 s.\n",
      "2022-06-23 07:01:36,665 - base - recpack - INFO - Fitting NeuMF complete - Took 2.02e+04s\n",
      "128 10 0.01 ndcg\n",
      "2022-06-23 07:40:50,696 - base - recpack - INFO - Processed epoch 0 in 509.58 s.Batch Training Loss = 38.9571\n",
      "2022-06-23 08:12:34,783 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.08408753015707665, which is better than previous iterations.\n",
      "2022-06-23 08:12:34,784 - base - recpack - INFO - Model improved. Storing better model.\n",
      "2022-06-23 08:12:34,861 - base - recpack - INFO - Evaluation at end of 0 took 1904.16 s.\n",
      "2022-06-23 08:21:03,305 - base - recpack - INFO - Processed epoch 1 in 508.44 s.Batch Training Loss = 32.6848\n",
      "2022-06-23 08:48:31,171 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.0898314980420112, which is better than previous iterations.\n",
      "2022-06-23 08:48:31,172 - base - recpack - INFO - Model improved. Storing better model.\n",
      "2022-06-23 08:48:31,257 - base - recpack - INFO - Evaluation at end of 1 took 1647.95 s.\n",
      "2022-06-23 08:56:57,651 - base - recpack - INFO - Processed epoch 2 in 506.39 s.Batch Training Loss = 32.1921\n",
      "2022-06-23 09:22:22,394 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.09901336060470675, which is better than previous iterations.\n",
      "2022-06-23 09:22:22,395 - base - recpack - INFO - Model improved. Storing better model.\n",
      "2022-06-23 09:22:22,482 - base - recpack - INFO - Evaluation at end of 2 took 1524.83 s.\n",
      "2022-06-23 09:30:49,982 - base - recpack - INFO - Processed epoch 3 in 507.50 s.Batch Training Loss = 37.1867\n",
      "2022-06-23 09:55:51,330 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.014172773438036794, which is worse than previous iterations.\n",
      "2022-06-23 09:55:51,331 - base - recpack - INFO - Evaluation at end of 3 took 1501.35 s.\n",
      "2022-06-23 10:04:11,969 - base - recpack - INFO - Processed epoch 4 in 500.63 s.Batch Training Loss = 40.0429\n",
      "2022-06-23 10:28:56,195 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.009715459199457818, which is worse than previous iterations.\n",
      "2022-06-23 10:28:56,197 - base - recpack - INFO - Evaluation at end of 4 took 1484.23 s.\n",
      "2022-06-23 10:37:17,523 - base - recpack - INFO - Processed epoch 5 in 501.32 s.Batch Training Loss = 40.8707\n",
      "2022-06-23 11:02:34,938 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.009117473940428476, which is worse than previous iterations.\n",
      "2022-06-23 11:02:34,940 - base - recpack - INFO - Evaluation at end of 5 took 1517.42 s.\n",
      "2022-06-23 11:11:09,419 - base - recpack - INFO - Processed epoch 6 in 514.47 s.Batch Training Loss = 41.5459\n",
      "2022-06-23 11:37:32,146 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.01108954018010079, which is worse than previous iterations.\n",
      "2022-06-23 11:37:32,147 - base - recpack - INFO - Evaluation at end of 6 took 1582.73 s.\n",
      "2022-06-23 11:46:05,304 - base - recpack - INFO - Processed epoch 7 in 513.15 s.Batch Training Loss = 40.8286\n",
      "2022-06-23 12:12:31,054 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.011325359132667596, which is worse than previous iterations.\n",
      "2022-06-23 12:12:31,055 - base - recpack - INFO - Evaluation at end of 7 took 1585.75 s.\n",
      "2022-06-23 12:21:06,111 - base - recpack - INFO - Processed epoch 8 in 515.05 s.Batch Training Loss = 40.2088\n",
      "2022-06-23 12:47:25,952 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.007727047050919747, which is worse than previous iterations.\n",
      "2022-06-23 12:47:25,954 - base - recpack - INFO - Evaluation at end of 8 took 1579.84 s.\n",
      "2022-06-23 12:55:47,621 - base - recpack - INFO - Processed epoch 9 in 501.66 s.Batch Training Loss = 41.8032\n",
      "2022-06-23 13:21:09,693 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.012638527761507708, which is worse than previous iterations.\n",
      "2022-06-23 13:21:09,694 - base - recpack - INFO - Evaluation at end of 9 took 1522.07 s.\n",
      "2022-06-23 13:21:09,730 - base - recpack - INFO - Fitting NeuMF complete - Took 2.09e+04s\n",
      "128 10 0.01 ndcg\n",
      "2022-06-23 13:52:56,522 - base - recpack - INFO - Processed epoch 0 in 330.45 s.Batch Training Loss = 39.8566\n",
      "2022-06-23 14:23:55,765 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.0831714927494918, which is better than previous iterations.\n",
      "2022-06-23 14:23:55,766 - base - recpack - INFO - Model improved. Storing better model.\n",
      "2022-06-23 14:23:55,801 - base - recpack - INFO - Evaluation at end of 0 took 1859.28 s.\n",
      "2022-06-23 14:29:21,252 - base - recpack - INFO - Processed epoch 1 in 325.45 s.Batch Training Loss = 33.0599\n",
      "2022-06-23 14:59:34,534 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.094375020540076, which is better than previous iterations.\n",
      "2022-06-23 14:59:34,535 - base - recpack - INFO - Model improved. Storing better model.\n",
      "2022-06-23 14:59:34,573 - base - recpack - INFO - Evaluation at end of 1 took 1813.32 s.\n",
      "2022-06-23 15:04:59,677 - base - recpack - INFO - Processed epoch 2 in 325.10 s.Batch Training Loss = 31.1564\n",
      "2022-06-23 15:35:39,205 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.09799131604644282, which is better than previous iterations.\n",
      "2022-06-23 15:35:39,206 - base - recpack - INFO - Model improved. Storing better model.\n",
      "2022-06-23 15:35:39,244 - base - recpack - INFO - Evaluation at end of 2 took 1839.57 s.\n",
      "2022-06-23 15:41:04,033 - base - recpack - INFO - Processed epoch 3 in 324.78 s.Batch Training Loss = 29.8762\n",
      "2022-06-23 16:11:09,505 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.09760060687109678, which is worse than previous iterations.\n",
      "2022-06-23 16:11:09,506 - base - recpack - INFO - Evaluation at end of 3 took 1805.47 s.\n",
      "2022-06-23 16:16:33,221 - base - recpack - INFO - Processed epoch 4 in 323.71 s.Batch Training Loss = 28.8791\n",
      "2022-06-23 16:46:01,753 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.09933050429957442, which is better than previous iterations.\n",
      "2022-06-23 16:46:01,755 - base - recpack - INFO - Model improved. Storing better model.\n",
      "2022-06-23 16:46:01,792 - base - recpack - INFO - Evaluation at end of 4 took 1768.57 s.\n",
      "2022-06-23 16:51:24,714 - base - recpack - INFO - Processed epoch 5 in 322.92 s.Batch Training Loss = 28.1065\n",
      "2022-06-23 17:20:24,621 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.10359780023920352, which is better than previous iterations.\n",
      "2022-06-23 17:20:24,622 - base - recpack - INFO - Model improved. Storing better model.\n",
      "2022-06-23 17:20:24,660 - base - recpack - INFO - Evaluation at end of 5 took 1739.95 s.\n",
      "2022-06-23 17:25:47,549 - base - recpack - INFO - Processed epoch 6 in 322.88 s.Batch Training Loss = 27.6001\n",
      "2022-06-23 17:55:09,341 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.10393113937071141, which is better than previous iterations.\n",
      "2022-06-23 17:55:09,342 - base - recpack - INFO - Model improved. Storing better model.\n",
      "2022-06-23 17:55:09,380 - base - recpack - INFO - Evaluation at end of 6 took 1761.83 s.\n",
      "2022-06-23 18:00:32,645 - base - recpack - INFO - Processed epoch 7 in 323.26 s.Batch Training Loss = 27.1415\n",
      "2022-06-23 18:29:24,673 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.1027690961025639, which is worse than previous iterations.\n",
      "2022-06-23 18:29:24,674 - base - recpack - INFO - Evaluation at end of 7 took 1732.03 s.\n",
      "2022-06-23 18:34:47,231 - base - recpack - INFO - Processed epoch 8 in 322.55 s.Batch Training Loss = 26.8028\n",
      "2022-06-23 19:03:27,439 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.10629352624714494, which is better than previous iterations.\n",
      "2022-06-23 19:03:27,440 - base - recpack - INFO - Model improved. Storing better model.\n",
      "2022-06-23 19:03:27,479 - base - recpack - INFO - Evaluation at end of 8 took 1720.25 s.\n",
      "2022-06-23 19:08:48,994 - base - recpack - INFO - Processed epoch 9 in 321.51 s.Batch Training Loss = 26.5110\n",
      "2022-06-23 19:37:32,079 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.10920286993810616, which is better than previous iterations.\n",
      "2022-06-23 19:37:32,080 - base - recpack - INFO - Model improved. Storing better model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-06-23 19:37:32,117 - base - recpack - INFO - Evaluation at end of 9 took 1723.12 s.\n",
      "2022-06-23 19:37:32,134 - base - recpack - INFO - Fitting NeuMF complete - Took 2.1e+04s\n",
      "2022-06-23 20:06:31,710 - base - recpack - INFO - Fitting Popularity complete - Took 2.55s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/robinverachtert/dist-env/lib/python3.8/site-packages/scipy/sparse/_index.py:146: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_arrayXarray(i, j, x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-06-23 20:06:58,574 - base - recpack - INFO - Fitting ItemKNN complete - Took 17.5s\n",
      "2022-06-23 20:07:33,150 - base - recpack - INFO - Fitting ItemKNN complete - Took 15.6s\n",
      "2022-06-23 20:08:26,023 - base - recpack - INFO - Fitting ItemKNN complete - Took 15.6s\n"
     ]
    }
   ],
   "source": [
    "pipeline.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3a36b1d0",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ndcgk_10</th>\n",
       "      <th>coveragek_10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NeuMF(batch_size=128,dropout=0.01,exact_sampling=False,keep_last=False,learning_rate=0.01,max_epochs=10,max_iter_no_change=5,min_improvement=0.0,n_negatives_per_positive=3,predict_topK=20,predictive_factors=16,save_best_to_file=False,seed=3337940912,stop_early=False,stopping_criterion=&lt;recpack.algorithms.stopping_criterion.StoppingCriterion object at 0x7feb478a0340&gt;)</th>\n",
       "      <td>0.104866</td>\n",
       "      <td>0.122034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Popularity(K=20)</th>\n",
       "      <td>0.085165</td>\n",
       "      <td>0.000502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ItemKNN(K=200,normalize=False,normalize_X=False,normalize_sim=False,pop_discount=None,similarity=cosine)</th>\n",
       "      <td>0.162156</td>\n",
       "      <td>0.147565</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    ndcgk_10  coveragek_10\n",
       "NeuMF(batch_size=128,dropout=0.01,exact_samplin...  0.104866      0.122034\n",
       "Popularity(K=20)                                    0.085165      0.000502\n",
       "ItemKNN(K=200,normalize=False,normalize_X=False...  0.162156      0.147565"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.get_metrics_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bbf22a9c",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>identifier</th>\n",
       "      <th>params</th>\n",
       "      <th>NDCGK</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NeuMF(batch_size=128,dropout=0.01,exact_sampli...</td>\n",
       "      <td>{'predictive_factors': 8, 'batch_size': 128, '...</td>\n",
       "      <td>0.083669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NeuMF(batch_size=128,dropout=0.01,exact_sampli...</td>\n",
       "      <td>{'predictive_factors': 16, 'batch_size': 128, ...</td>\n",
       "      <td>0.087949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NeuMF(batch_size=128,dropout=0.01,exact_sampli...</td>\n",
       "      <td>{'predictive_factors': 32, 'batch_size': 128, ...</td>\n",
       "      <td>0.082559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ItemKNN(K=200,normalize=False,normalize_X=Fals...</td>\n",
       "      <td>{'similarity': 'conditional_probability'}</td>\n",
       "      <td>0.103835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ItemKNN(K=200,normalize=False,normalize_X=Fals...</td>\n",
       "      <td>{'similarity': 'cosine'}</td>\n",
       "      <td>0.138635</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          identifier  \\\n",
       "0  NeuMF(batch_size=128,dropout=0.01,exact_sampli...   \n",
       "1  NeuMF(batch_size=128,dropout=0.01,exact_sampli...   \n",
       "2  NeuMF(batch_size=128,dropout=0.01,exact_sampli...   \n",
       "3  ItemKNN(K=200,normalize=False,normalize_X=Fals...   \n",
       "4  ItemKNN(K=200,normalize=False,normalize_X=Fals...   \n",
       "\n",
       "                                              params     NDCGK  \n",
       "0  {'predictive_factors': 8, 'batch_size': 128, '...  0.083669  \n",
       "1  {'predictive_factors': 16, 'batch_size': 128, ...  0.087949  \n",
       "2  {'predictive_factors': 32, 'batch_size': 128, ...  0.082559  \n",
       "3          {'similarity': 'conditional_probability'}  0.103835  \n",
       "4                           {'similarity': 'cosine'}  0.138635  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.optimisation_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "720b3479",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ndcgk_10</th>\n",
       "      <th>coveragek_10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NeuMF</th>\n",
       "      <td>0.104866</td>\n",
       "      <td>0.122034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Popularity</th>\n",
       "      <td>0.085165</td>\n",
       "      <td>0.000502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ItemKNN</th>\n",
       "      <td>0.162156</td>\n",
       "      <td>0.147565</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            ndcgk_10  coveragek_10\n",
       "NeuMF       0.104866      0.122034\n",
       "Popularity  0.085165      0.000502\n",
       "ItemKNN     0.162156      0.147565"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.get_metrics_dataframe(short=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b2d607",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Check it out!\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"Recpack Demo - QR codes(3).png\" alt=\"codes\"/>\n",
    "</div>\n",
    "\n",
    "### Reach out to us\n",
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"Recpack Demo - Contact Info(2).png\" alt=\"drawing\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7e332e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
